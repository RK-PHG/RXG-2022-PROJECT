## Pitch
Change input args type from `std::tuple` to `std::vector` to reduce the compilation time.

## Description
`std::tie()` takes quite a long time during the compilation when the input args number grows.

For example, for a graph from the `PegasusForConditionalGeneration` model with 318 input args, the compilation of `std::tie` for the args is about 10s. By changing to std::vector, the time of arg assignment is reduced to less than 1s.

### Code before:
```cpp
at::Tensor call_0(std::tuple<at::Tensor&, at::Tensor&> args) {
    at::Tensor arg0_1, arg1_1;
    std::tie(arg0_1, arg1_1) = args;
    ...
    return buf0; 
}
```

### Code after:
```cpp
at::Tensor call_0(std::vector<at::Tensor> args) {
    at::Tensor arg0_1, arg1_1;
    arg0_1 = args[0];
    arg1_1 = args[1];
    ...
    return buf0; 
}
```


cc @mlazos @soumith @voznesenskym @yanboliang @penguinwu @anijain2305 @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @Xia-Weiwen @wenzhe-nrv @jiayisunx @peterbell10 @desertfireStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90748

Summary: adding a section to the docs that help users understand when to
use the many quantization tools

Test Plan: just docs

Reviewers:

Subscribers:

Tasks:

Tags:Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90745
* #90621
* #90620
* #90579
* #90523

Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90750

For micro-benchmark, aten.elu.default and aten.elu_backward.default have poor performance with inductor compared to eager. The main reason is lack of the vectorization. With adding missing ops for cpp vectorization overrides, the vectorization could be successfully applied.

Performance data for eager v.s. inductor:
<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:x="urn:schemas-microsoft-com:office:excel"
xmlns="http://www.w3.org/TR/REC-html40">

<head>

<meta name=ProgId content=Excel.Sheet>
<meta name=Generator content="Microsoft Excel 15">
<link id=Main-File rel=Main-File
href="file:///C:/Users/xuanliao/AppData/Local/Temp/msohtmlclip1/01/clip.htm">
<link rel=File-List
href="file:///C:/Users/xuanliao/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml">
<!--table
	{mso-displayed-decimal-separator:"\.";
	mso-displayed-thousand-separator:"\,";}
@page
	{margin:.75in .7in .75in .7in;
	mso-header-margin:.3in;
	mso-footer-margin:.3in;}
tr
	{mso-height-source:auto;}
col
	{mso-width-source:auto;}
br
	{mso-data-placement:same-cell;}
td
	{padding-top:1px;
	padding-right:1px;
	padding-left:1px;
	mso-ignore:padding;
	color:black;
	font-size:11.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:Calibri, sans-serif;
	mso-font-charset:0;
	mso-number-format:General;
	text-align:general;
	vertical-align:bottom;
	border:none;
	mso-background-source:auto;
	mso-pattern:auto;
	mso-protection:locked visible;
	white-space:nowrap;
	mso-rotate:0;}
.xl63
	{mso-number-format:Percent;}
.xl64
	{color:gray;}
-->
</head>

<body link="#0563C1" vlink="#954F72">



op | speedup_old | RSD (3) | speedup_new | RSD (3) | increased_performance
-- | -- | -- | -- | -- | --
aten.elu.default | 0.205947276 | 1.73% | 0.995302802 | 4.76% | 383.28%
aten.elu_backward.default | 0.336280639 | 0.58% | 1.69473642 | 1.96% | 403.96%



</body>

</html>


The new supported ops for cpp vectorization overrides:
- eq
- ne
- lt
- gt
- le
- ge
- expm1


cc @mlazos @soumith @voznesenskym @yanboliang @penguinwu @anijain2305 @EikanWang @jgong5 @Guobing-Chen @chunyuan-w @XiaobingSuper @zhuhaozhe @blzheng @Xia-Weiwen @wenzhe-nrv @jiayisunx @peterbell10 @desertfireStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* #90748
* __->__ #90747

Summary:

Test Plan:

Reviewers:

Subscribers:

Tasks:

Tags:Adds the ability to store inputs used in tracing models when calling torch.jit.save and restore the input shapes using torch.jit.load if the appropriate variables are set.

Fixes [89185](https://github.com/pytorch/pytorch/issues/89185)
Summary:
Inductor can't fuse pointwise into the output of concat, but it can
fuse into the inputs, and that's the same thing.  So we hoist pointwise through
a concat (followed by an optional series of views).

Test Plan: New unit test

Differential Revision: D41901656



cc @mlazos @soumith @voznesenskym @yanboliang @penguinwu @anijain2305 @EikanWang @jgong5 @Guobing-Chen @chunyuan-w @XiaobingSuper @zhuhaozhe @blzheng @Xia-Weiwen @wenzhe-nrv @jiayisunx @peterbell10 @desertfireStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90739
* #90738

WIP, not ready

Differential Revision: [D41845303](https://our.internmc.facebook.com/intern/diff/D41845303/)

**NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D41845303/)!

cc @mlazos @soumith @voznesenskym @yanboliang @penguinwu @anijain2305 @EikanWang @jgong5 @Guobing-Chen @chunyuan-w @XiaobingSuper @zhuhaozhe @blzheng @Xia-Weiwen @wenzhe-nrv @jiayisunx @peterbell10 @desertfireFix TODO related to https://github.com/pytorch/pytorch/issues/38095
Reland of https://github.com/pytorch/pytorch/pull/90335
Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* #90739
* __->__ #90738

Differential Revision: [D41474473](https://our.internmc.facebook.com/intern/diff/D41474473/)

**NOTE FOR REVIEWERS**: This PR has internal Meta-specific changes or comments, please review them on [Phabricator](https://our.internmc.facebook.com/intern/diff/D41474473/)!

cc @mlazos @soumith @voznesenskym @yanboliang @penguinwu @anijain2305 @EikanWang @jgong5 @Guobing-Chen @chunyuan-w @XiaobingSuper @zhuhaozhe @blzheng @Xia-Weiwen @wenzhe-nrv @jiayisunx @peterbell10 @desertfireStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90735
* #90734
* #90733
* #90732
* #90731
* #90730

This PR changes the op registration to a better mechanism, now
we require the directly overload registration instead of the op
key str, this have several benefits:
1. We ensure that the op registration registers the correct op, which
  means it would be faild if the op registration become wrong (this PR
  already fixing several op registration errors as we use direct
  OpOverload registration
2. If the overload name get changed/deleted, we immediately know it at
  the source code compilation level, which is safer
3. This also keep it consistents with the op registration mechanism with
  other tensor subclasses within PyTorchStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* #90735
* #90734
* __->__ #90733
* #90732
* #90731
* #90730

This PR refactors the dispatching logic to make it more clean, and
isolate the sharding propagation logic out to a separate class.

This is so that we can implement more complicated propagation features
later.Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* #90735
* __->__ #90734
* #90733
* #90732
* #90731
* #90730

This PR adds a cached propagator for TP use, it caches the sharding
prop decision for the same input sharding on an operator. This could
improve eager mode performance.Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90737



cc @mlazos @soumith @voznesenskym @yanboliang @penguinwu @anijain2305 @EikanWang @jgong5 @Guobing-Chen @chunyuan-w @XiaobingSuper @zhuhaozhe @blzheng @Xia-Weiwen @wenzhe-nrv @jiayisunx @desertfireStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* #90735
* #90734
* #90733
* __->__ #90732
* #90731
* #90730

This PR moves OpSchema and types to a separate file to resolve
circular dependency better, this is part of refactor on dispatching
logic to enable more complicated featuresStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90728

Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* #90735
* #90734
* #90733
* #90732
* #90731
* __->__ #90730

This PR adds __hash__ to FunctionSchema pybind binding, so that
it could be used for things like dict indexingStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* #90735
* #90734
* #90733
* #90732
* __->__ #90731
* #90730

This PR adds __hash__ to device_mesh and dtensor_spec to allow
things like dict indexingThis PR is auto-generated nightly by [this action](https://github.com/pytorch/pytorch/blob/master/.github/workflows/_update-commit-hash.yml).
Update the pinned vision hash.Fixes #64427.

cc @sunway513 @jithunnair-amd @pruthvistony @ROCmSupportStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90724
* #90575



cc @mlazos @soumith @voznesenskym @yanboliang @penguinwu @anijain2305 @EikanWang @jgong5 @Guobing-Chen @chunyuan-w @XiaobingSuper @zhuhaozhe @blzheng @Xia-Weiwen @wenzhe-nrv @jiayisunx @desertfireFixes #86494
The mapping was incorrect, but only certain downstream pytorch extensions found this issue.  pytorch CI does not cover this mapping.

cc @sunway513 @jithunnair-amd @pruthvistony @ROCmSupportStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90719
* #90718



cc @nikitaved @cpuhrsch @amjames @bhosmer @ezyang @albanD @zou3519 @gqchen @soulitzer @Lezcano @Varal7Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* #90719
* __->__ #90718



cc @nikitaved @cpuhrsch @amjames @bhosmerStack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):
* __->__ #90722

Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Please describe the motivation of this PR and the goal you want to achieve through this PR.

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Please describe the motivation of this PR and the goal you want to achieve through this PR.

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
https://github.com/open-mmlab/mmengine/pull/611 is required.

> ## Motivation
To support Test-Time-Aug (TTA).



## Modification
* Add `DetTTAModel` inherited from the `BaseTTAModel` in MMEngine.
* Add `--tta` option in `tools/test.py` to enable TTA during the test.

## Use cases
**To use the default TTA (average the classification scores of images w/ and w/o flip)**

```shell
 python tools/test.py configs/retinanet/retinanet_r50_fpn_1x_coco.py checkpoints/resnet50_coco.pth --tta
 ```
 
 **To use your own custom TTA method**
 
 1. Add `tta_model` and `tta_pipeline` in your config file:
 
 ```python
tta_model = dict(
    type='DetTTAModel',
    tta_cfg=dict(nms=dict(type='nms', iou_threshold=0.5), max_per_img=100))
tta_pipeline = [
        dict(type='LoadImageFromFile', file_client_args=dict(backend='disk')),
        dict(type='TestTimeAug',
             transforms=[
                 [dict(type='Resize', scale=(1333, 800), keep_ratio=True),
                  dict(type='Resize', scale=(1333, 600), keep_ratio=True)],
                 [dict(type='RandomFlip', prob=1.),
                  dict(type='RandomFlip', prob=0.)],
                 [dict(type='LoadAnnotations', with_bbox=True)],
                 [dict(type='PackDetInputs',
                       meta_keys=('img_id', 'img_path', 'ori_shape',
                                  'img_shape', 'scale_factor', 'flip',
                                  'flip_direction'))]])
    ]
 ```
 
 2. test with TTA
 
 ```shell
 python tools/test.py configs/retinanet/retinanet_r50_fpn_1x_coco.py checkpoints.pth --tta
 ```

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Remove legacy build functions and replace them with `Registry.build()`

resolve #9475

## Modification

Remove all `build_detector` and `build_dataset`.

## BC-breaking

APIs in `mmdet.models.builder` and `mmdet.datasets.builder` are no longer available.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Please describe the motivation of this PR and the goal you want to achieve through this PR.

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
This PR is from https://github.com/open-mmlab/mmdetection/pull/9248 that only without the support of group detrÔºåto merge to main branchThanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Please describe the motivation of this PR and the goal you want to achieve through this PR.

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Finish the task of Codecamp to add type hints of part 8 including the following files:
1. models/losses/iou_loss.py; 
2. models/losses/kd_loss.py
3. models/losses/mse_loss.py
4. models/losses/seesaw_loss.py
5. models/losses/smooth_l1_loss.py
6. models/losses/utils.py
7. models/losses/varifocal_loss.py

## Modification

I have only modified the following files:
1. models/losses/iou_loss.py; 
2. models/losses/kd_loss.py
3. models/losses/mse_loss.py
4. models/losses/seesaw_loss.py
5. models/losses/smooth_l1_loss.py
6. models/losses/utils.py
7. models/losses/varifocal_loss.py

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

- [x] Pre-commit or other linting tools are used to fix the potential lint issues.
- [x] The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
- [ ] If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
- [x] The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Modify some typehints in csp_darknet.py.

## Modification

Modify some typehints in csp_darknet.py.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Resolved: https://github.com/open-mmlab/mmdetection/issues/9309

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
I'm working together with @jshilong, @Li-Qingyun, and @KeiChiTse to refactor the DETR-like algorithms in MMDetection 3.x, using a more lightweight and easy-to-read code style.

And we are trying our best to align with the original repo, the class number in original repo is 91,but default in mmdet is 80, so we we made our best to change little to support 91 class training anf eval.
## Motivation

To fix errors described on #8455.

```
Exception: input type is not supported.
```

## Modification

Before checking `masks is not None`, if `masks` is the list of `None`, then change to `None`.

```python
masks = [None, None, ..., None]
masks = None if set(masks) == {None} else masks
```


```python
masks = None if set(masks) == {None} else masks     # üëà new lines
if masks is not None:
    wandb_masks = self._get_wandb_masks(
        masks,
        labels,
        is_poly_mask=True,
        height=img_height,
        width=img_width)
else:
    wandb_masks = None
```## Motivation

paper: https://arxiv.org/abs/2205.08534
code: https://github.com/czczup/ViT-Adapter
issue: https://github.com/open-mmlab/mmdetection/issues/9044

## Related PR

https://github.com/open-mmlab/mmclassification/pull/1209
https://github.com/open-mmlab/mmcv/pull/2451
https://github.com/open-mmlab/mmcv/pull/2452

## Result

|  Backbone   | ASFF | box AP | mask AP |
| :---------: | :--: | :--: | :----: |
| DeiT-T |  official    |  46.0   |  41.0  |
| DeiT-T |  mmdet   |  45.6   |  40.9  |


## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation
Ë∂ÖÁ∫ßËßÜÂÆ¢Ëê•mmdetÂü∫Á°Ä‰ªªÂä°ÔºåÈÄâÊã©ÈìæÊé•‰∏≠‰ªª‰∏Ä part ‰ª£Á†ÅÊ∑ªÂä† type hintsÔºå‰∏∫part6ÁöÑres_layerÊ∑ªÂä†type hints

## Modification
‰∏∫ÂÖ∂‰∏≠ÁöÑReslayerÂíåSimplifiedBasicBlockÊ∑ªÂä†‰∫Ütype hint
Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Please describe the motivation of this PR and the goal you want to achieve through this PR.

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

https://github.com/open-mmlab/mmdetection/issues/9312

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
## Motivation

This PR **resolves** several _confilcits_ and **rearrange** the code structure based on PR #8811. Comparing to PR #8533 for 2.x, this PR aims to refactor DAB-DETR in MMDetection 3.x.

I'm working together with @jshilong, @Li-Qingyun, and @LYMDLUT to refactor the DETR-like algorithms in MMDetection 3.x, using a more lightweight and easy-to-read code style.

Details can be refered to in brother PRs #9149, #8362, #8763, #8544, #9248, feel free to contact me and give your advice!## Motivation

YOLOX-PAI for dev-3.x

Related PR:
https://github.com/open-mmlab/mmdetection/pull/8778
https://github.com/open-mmlab/mmclassification/pull/1126

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
Implement the results in the paper "[Conditional DETR: [Conditional DETR for Fast Training Convergence](https://arxiv.org/abs/2108.06152)]" and  "[Group DETR: [ Fast DETR Training with Group-Wise One-to-Many Assignment](https://arxiv.org/pdf/2207.13085.pdf)]"with mmdetection. The [original code](https://github.com/Atten4Vis/ConditionalDETR/tree/GroupDETR) has released.

Remark

Besides, there are also brother PRs https://github.com/open-mmlab/mmdetection/pull/9149, https://github.com/open-mmlab/mmdetection/pull/8544, https://github.com/open-mmlab/mmdetection/pull/8846, https://github.com/open-mmlab/mmdetection/pull/8533, https://github.com/open-mmlab/mmdetection/pull/8811 of three algorithms (DINO„ÄÅold Condition DETR and DAB DETR) developed in parallel.

This is my first experience of contributing a PR to the open source community. I'm trying hard to make Conditional DETR and Group DETR available in mmdetection as soon as possible.

The mAP of Group DETR is still aligningÔºådo not worryÔºåit will release in very recent days.## Motivation

The checkpoint saved by mmengine contains more keys (e.g. message_hub, param_scheduler). These parts are very large and may take dozens or even hundreds of MB.

## Modification

Pop the keys except for meta and state_dict.

## Motivation

Implement the results in the paper "[DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection](https://arxiv.org/abs/2203.03605)" with mmdetection. The [original code](https://github.com/IDEACVR/DINO) has released.

## Remark


For DINO implementation, our procedure includes three steps:

- [x] **Add DINO on mmdetection 2.x**  #8362 (Already finished!)

- [x] **Design refactor scheme, refactor DETR-like models on mmdetection 3.x.**  #8763 (Finished and merged!)

- [x] **Add(refactor) DINO on mmdetection 3.x**  #9149 (Coming soon)


Besides, there are also brother PRs #8544, #9405,  #8533, #9252 of two algorithms (Condition DETR and DAB DETR) developed in parallel.




I'm a student contributor in GitLink Code Camp. And this is my first experience of contributing a PR to the open source community. I'm trying hard to make DINO available in mmdetection as soon as possible.

**If your project allows to use mmdetection2.x, you can refer to #8362 for the version that has been finished but not merged.**## Motivation

The registry now supports auto-import modules from the given location.

register_all_modules before running is no longer needed. The modules will be lazy-imported during building.

This PR can be merged after https://github.com/open-mmlab/mmengine/pull/643. The MMEngine version should be updated.Follor PR: https://github.com/open-mmlab/mmeval/pull/23 and https://github.com/open-mmlab/mmeval/pull/29


# CocoMetric
## Before refactor

![image](https://user-images.githubusercontent.com/48282753/196786091-f13a4fde-c25e-47c4-b707-85b017dede82.png)

## After refactor

### Not load ann_file:
The area in coco is based on gt_mask. if using gt_bbox, it will lead to different small/medium/large AP results. Moreover, the area calculated from  gt_mask area in CocoDetectionMetric is almost equal to coco-json file (still a little difference in small AP). So if only calculate bbox ap, and do not load ann_file, it is suggested to load mask at the same time.

Using gt_box area:
![image](https://user-images.githubusercontent.com/48282753/197146111-55d309d7-2c1f-48c5-af1a-9dfe92c1030b.png)

Using gt_mask area:
![image](https://user-images.githubusercontent.com/48282753/197146188-dfa148c1-7abc-4a25-8c4a-67578b1f88d9.png)


###  Load ann_file:
![image](https://user-images.githubusercontent.com/48282753/196785090-79012272-9a2a-4e54-b1bc-1d66067cd0b5.png)


# ProposalRecallMetric

### Before refactor

![image](https://user-images.githubusercontent.com/48282753/197226735-941e2fc3-0e50-46fd-a477-3e9af9eddf56.png)


### After refactor

![image](https://user-images.githubusercontent.com/48282753/197225838-d76f7e7e-a6ed-425e-a722-64281b780993.png)
## Motivation

The COCO dataset recall evaluation in mmdetection differs from the [original pycocotools](https://cocodataset.org/#detection-eval). This is because the mmdetection's default `maxDets` (`[100, 500, 1000]` ) are not equal to the others (`[1, 10, 100]`).

This change fixes issue https://github.com/open-mmlab/mmdetection/issues/6884.

## Modification

- Rename `proposal_nums` to `max_dets`
  - `proposal_nums` seems to be used in the first stage of two-stage object detection (many proposals will appear).
  - The name `max_dets` is compatible to coco evaluation.
- Change the default values to `cocoEval.params.maxDets` from `[100, 500, 1000]` to `[1, 10, 100]`
  - [This change](https://github.com/open-mmlab/mmdetection/pull/3497/files#diff-136b3f31689b4e74b64162ee5eb155777202e00231010a752df486a097a8633dR452) incorrectly sets all case to `[100, 500, 1000]` 
  - We can fix it to set `cocoEval.params.maxDets` only if `metric == "proposal"`. I didn't because you'll change this variable in other situations (such as detection of a large number of objects).

## BC-breaking (Optional)

- Default recall evaluation of COCO dataset (measured after https://github.com/open-mmlab/mmdetection/pull/3497/commits/e20c5c2c83b9deac1ea24915955cea6b56632458 )
  - If you want to get the previous value, you can set `maxDets=[100, 500, 1000]` or simply see recall@100 (because recall@[100, 500, 1000] will get the same value in most experiments).

## Use cases (Optional)

COCO evaluation

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
## Motivation

In paper: [A Systematic IoU-Related Method: Beyond Simplified Regression for Better Localization](https://ieeexplore.ieee.org/document/9429909) of TIP2021, we propose a new Extended-IOU loss, which outperforms the commonly used GIOU and DIOU in object detection.
## Modification
add implementation of the proposed Extended-IOU Loss (EIOU).Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Please describe the motivation of this PR and the goal you want to achieve through this PR.

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
## Motivation

Support WandB in MMDetection

## Use cases
### 1 image_demo.py

Modify the `configs/_base_/default_runtime.py` file

```python
# vis_backends = [dict(type='LocalVisBackend')]
# visualizer = dict(
#     type='DetLocalVisualizer', vis_backends=vis_backends, name='visualizer')

# wandb
visualizer = dict(type='DetWandBVisualizer', name='visualizer', save_dir='demo')
```

```python
cd mmdetection
wget https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth
python demo/image_demo.py demo/demo.jpg configs/mask_rcnn/mask-rcnn_r50_fpn_1x_coco.py mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth
```

results: 
![image](https://user-images.githubusercontent.com/17425982/194736214-66e66018-e474-4a83-8ea9-d5f9cc60e563.png)


### 2 tools/analysis_tools/browse_dataset.py

Modify the `configs/_base_/default_runtime.py` file

```python
# vis_backends = [dict(type='LocalVisBackend')]
# visualizer = dict(
#     type='DetLocalVisualizer', vis_backends=vis_backends, name='visualizer')

# wandb
visualizer = dict(type='DetWandBVisualizer', name='visualizer', save_dir='demo')
```

`python tools/analysis_tools/browse_dataset.py configs/mask_rcnn/mask-rcnn_r50_fpn_1x_coco.py`

results: 
![image](https://user-images.githubusercontent.com/17425982/194736749-bcb9f74c-a295-4982-9e60-4342987888fd.png)
![image](https://user-images.githubusercontent.com/17425982/194736736-ffd8ef1e-f777-4b29-a816-aa5f561e9ce8.png)


### 3 tools/test.py

Modify the `configs/_base_/default_runtime.py` file

```python
# vis_backends = [dict(type='LocalVisBackend')]
# visualizer = dict(
#     type='DetLocalVisualizer', vis_backends=vis_backends, name='visualizer')

# wandb
visualizer = dict(type='DetWandBVisualizer', name='visualizer')
```

` python tools/test.py configs/mask_rcnn/mask-rcnn_r50_fpn_1x_coco.py mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth --show-dir test_results`

results: 
![image](https://user-images.githubusercontent.com/17425982/194738239-8cf9d7ce-38d7-44f3-b3e9-c1fcd3c29cec.png)
![image](https://user-images.githubusercontent.com/17425982/194738260-fc1e5a5b-a574-49ed-b323-dee6a5e524d9.png)

### 4 tools/train.py

Modify the `configs/_base_/default_runtime.py` file

```python
# vis_backends = [dict(type='LocalVisBackend')]
# visualizer = dict(
#     type='DetLocalVisualizer', vis_backends=vis_backends, name='visualizer')

# wandb
visualizer = dict(type='DetWandBVisualizer', name='visualizer')

default_hooks = dict(visualization=dict(type='DetVisualizationHook', draw=True))  # note 
```

`python tools/train.py configs/mask_rcnn/mask-rcnn_r50_fpn_1x_coco.py `


results: 
![image](https://user-images.githubusercontent.com/17425982/194741292-a61cfcd9-cac9-4dd5-b72c-ae023d0739bb.png)
![image](https://user-images.githubusercontent.com/17425982/194741281-8d9e0d9a-7079-49ba-8f1a-91a666ded28a.png)




## Motivation

Add device select for samplers, thus they can use MLU or other devices.

## Modification

Add ```get_device``` and ```sync_random_seed(seed, device)``` to infinite_sampler and class_aware_sampler.

## BC-breaking (Optional)

No BC-breaking.

## Use cases (Optional)

No cases.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
add SSH Module.Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Fix the bug that MMDetWandbHook cannot log evaluation results

## Modification

Fix the bug that MMDetWandbHook cannot log evaluation results

## Description

EvalHook calls all LoggerHook instances before evaluation. Since MMDetWandbHook class is a subclass of LoggerHook, `after_train_iter` hook is called twice in the iteration that performs evaluation. MMDetWandbHook logs the loss information in the first call and the evaluation results in the second call. If `self.commit` is True in the first call, then the second call will not log the evaluation results successfully because the metrics of this step are already persisted. Please check https://docs.wandb.ai/guides/track/log#stepwise-and-incremental-logging for more details.

I encountered this problem while training a panoptic segmentation model using MMDetWandbHook. I apologize for not verifying if this bug occurs when training instance segmentation models, as my GPU resources are pretty tight. Since MMDetWandbHook doesn't fully support the training of panoptic segmentation models, this bug may only occur when training panoptic segmentation models. If this is the case, please feel free to ignore my pr.

This bug can be demonstrated using the following simple example:

script_a.py:
```python
import wandb

wandb.init(project='project_name',
           entity='entity_name',
           name='use commit == True')

for i in range(100):
    wandb.log({'a': i}, step=i, commit=True)
    wandb.log({'b': i**2}, step=i, commit=True)
```


script_b.py:
```python
import wandb

wandb.init(project='project_name',
           entity='entity_name',
           name='use commit == False')

for i in range(100):
    wandb.log({'a': i}, step=i, commit=False)
    wandb.log({'b': i**2}, step=i, commit=True)
```

Running these two scripts and you will find that wandb only logs the points of `a` in script_a.py while wandb can log points of `a` and `b` in script_b.py  Using custom iou_thrs:
```
evaluation = dict(
    save_best='auto',
    interval=interval,
    dynamic_intervals=[(max_epochs - num_last_epochs, 1)],
    metric='bbox',
    iou_thrs=[0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75])
```

In coco.py, it says the iou_thrs could be a list.
```
def evaluate(self,
             results,
             metric='bbox',
             logger=None,
             jsonfile_prefix=None,
             classwise=False,
             proposal_nums=(100, 300, 1000),
             iou_thrs=None,
             metric_items=None):
    """Evaluation in COCO protocol.

    Args:
        results (list[list | tuple]): Testing results of the dataset.
        metric (str | list[str]): Metrics to be evaluated. Options are
            'bbox', 'segm', 'proposal', 'proposal_fast'.
        logger (logging.Logger | str | None): Logger used for printing
            related information during evaluation. Default: None.
        jsonfile_prefix (str | None): The prefix of json files. It includes
            the file path and the prefix of filename, e.g., "a/b/prefix".
            If not specified, a temp file will be created. Default: None.
        classwise (bool): Whether to evaluating the AP for each class.
        proposal_nums (Sequence[int]): Proposal number used for evaluating
            recalls, such as recall@100, recall@1000.
            Default: (100, 300, 1000).
        iou_thrs (Sequence[float], optional): IoU threshold used for
            evaluating recalls/mAPs. If set to a list, the average of all
            IoUs will also be computed. If not specified, [0.50, 0.55,
            0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95] will be used.
            Default: None.
        metric_items (list[str] | str, optional): Metric items that will
            be returned. If not specified, ``['AR@100', 'AR@300',
            'AR@1000', 'AR_s@1000', 'AR_m@1000', 'AR_l@1000' ]`` will be
            used when ``metric=='proposal'``, ``['mAP', 'mAP_50', 'mAP_75',
            'mAP_s', 'mAP_m', 'mAP_l']`` will be used when
            ``metric=='bbox' or metric=='segm'``.

    Returns:
        dict[str, float]: COCO style evaluation metric.
    """
```

In cocoeval.py: 
```
def _summarize( ap=1, iouThr=None, areaRng='all', maxDets=100 ):
    p = self.params
    iStr = ' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'
    titleStr = 'Average Precision' if ap == 1 else 'Average Recall'
    typeStr = '(AP)' if ap==1 else '(AR)'
    iouStr = '{:0.2f}:{:0.2f}'.format(p.iouThrs[0], p.iouThrs[-1]) \
        if iouThr is None else '{:0.2f}'.format(iouThr)

    aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]
    mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]
    if ap == 1:
        # dimension of precision: [TxRxKxAxM]
        s = self.eval['precision']
        # IoU
        if iouThr is not None:
            t = np.where(iouThr == p.iouThrs)[0]
            s = s[t]
        s = s[:,:,:,aind,mind]
    else:
        # dimension of recall: [TxKxAxM]
        s = self.eval['recall']
        if iouThr is not None:
            t = np.where(iouThr == p.iouThrs)[0]
            s = s[t]
        s = s[:,:,aind,mind]
    if len(s[s>-1])==0:
        mean_s = -1
    else:
        mean_s = np.mean(s[s>-1])
    print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))
    return mean_
```

p.iouThrs is the custom iou_thrs whose type is list. iouThr could be 0.5 or 0.75. np.where does not work for list. np.where([0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75] == 0.5) will return []. iou_thrs should be a numpy array.

Just add iou_thrs = np.array(iou_thrs) if iou_thrs is not None.
```
def evaluate_det_segm(self,
                      results,
                      result_files,
                      coco_gt,
                      metrics,
                      logger=None,
                      classwise=False,
                      proposal_nums=(100, 300, 1000),
                      iou_thrs=None,
                      metric_items=None):
    """Instance segmentation and object detection evaluation in COCO
    protocol.

    Args:
        results (list[list | tuple | dict]): Testing results of the
            dataset.
        result_files (dict[str, str]): a dict contains json file path.
        coco_gt (COCO): COCO API object with ground truth annotation.
        metric (str | list[str]): Metrics to be evaluated. Options are
            'bbox', 'segm', 'proposal', 'proposal_fast'.
        logger (logging.Logger | str | None): Logger used for printing
            related information during evaluation. Default: None.
        classwise (bool): Whether to evaluating the AP for each class.
        proposal_nums (Sequence[int]): Proposal number used for evaluating
            recalls, such as recall@100, recall@1000.
            Default: (100, 300, 1000).
        iou_thrs (Sequence[float], optional): IoU threshold used for
            evaluating recalls/mAPs. If set to a list, the average of all
            IoUs will also be computed. If not specified, [0.50, 0.55,
            0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95] will be used.
            Default: None.
        metric_items (list[str] | str, optional): Metric items that will
            be returned. If not specified, ``['AR@100', 'AR@300',
            'AR@1000', 'AR_s@1000', 'AR_m@1000', 'AR_l@1000' ]`` will be
            used when ``metric=='proposal'``, ``['mAP', 'mAP_50', 'mAP_75',
            'mAP_s', 'mAP_m', 'mAP_l']`` will be used when
            ``metric=='bbox' or metric=='segm'``.

    Returns:
        dict[str, float]: COCO style evaluation metric.
    """
    if iou_thrs is None:
        iou_thrs = np.linspace(
            .5, 0.95, int(np.round((0.95 - .5) / .05)) + 1, endpoint=True)
    else:
        iou_thrs = np.array(iou_thrs)
```refactor WIDERFaceDataset## Motivation
Use MMEval's VOCMeanAP and OIDMeanAP.

## Evaluation test  for VOCMetric
NOTE: `eval_mode='area'` and `use_legacy_coordinate=True`

### Before ([dev-3.x](https://github.com/open-mmlab/mmdetection/tree/e63459234d27b90a770e0a4bcc126b4371e5d2ad)):
Time cost 00:32 (from log)
[retinanet_r50_fpn_1x_voc0712_20220928_152838.log](https://github.com/open-mmlab/mmdetection/files/9662572/retinanet_r50_fpn_1x_voc0712_20220928_152838.log)
<img width="1122" alt="image" src="https://user-images.githubusercontent.com/32220263/192718139-934ea338-aea6-49fb-8a18-ccab9900d715.png">


### After (this PR):
Time cost 00:32 (from log)
[retinanet_r50_fpn_1x_voc0712_20220928_153415.log](https://github.com/open-mmlab/mmdetection/files/9662571/retinanet_r50_fpn_1x_voc0712_20220928_153415.log)
<img width="1108" alt="image" src="https://user-images.githubusercontent.com/32220263/192718208-f3470c88-bcba-4d32-8fb4-fa41ad4e425d.png">


## Evaluation test  for OpenImagesMetric
NOTE: `eval_mode='area'` and `use_legacy_coordinate=False`

### Before ([dev-3.x](https://github.com/open-mmlab/mmdetection/tree/e63459234d27b90a770e0a4bcc126b4371e5d2ad)):
Time cost 25:33 (from log)
[retinanet_r50_fpn_32xb2-1x_openimages_20220928_140816.log](https://github.com/open-mmlab/mmdetection/files/9662472/retinanet_r50_fpn_32xb2-1x_openimages_20220928_140816.log)
<img width="1043" alt="image" src="https://user-images.githubusercontent.com/32220263/192714992-0e26c5cb-a7f1-41a0-85cd-820c3e7d30f6.png">


### After (this PR):
Time cost 23:23 (from log)
[retinanet_r50_fpn_32xb2-1x_openimages_20220928_145158.log](https://github.com/open-mmlab/mmdetection/files/9662483/retinanet_r50_fpn_32xb2-1x_openimages_20220928_145158.log)
<img width="1090" alt="image" src="https://user-images.githubusercontent.com/32220263/192714909-421cb2bf-8cf8-47d0-a6cf-a3685244780c.png">


This PR aims to refactor Conditional DETR in  MMDetection 3.0!

I'm working together with @jshilong, @Li-Qingyun, and @KeiChiTse  to refactor the DETR-like algorithms in MMDetection 3.0, using a more lightweight and easy-to-read code style.

feel free to contact me!Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Please describe the motivation of this PR and the goal you want to achieve through this PR.

## Modification

Please briefly describe what modification is made in this PR.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
## Motivation

[YOLOX-PAI: An Improved YOLOX, Stronger and Faster than YOLOv6](https://arxiv.org/abs/2208.13040)
[official repo](https://github.com/alibaba/EasyCV/tree/master/configs/detection/yolox)

## Related PR
https://github.com/open-mmlab/mmcv/pull/2256
https://github.com/open-mmlab/mmclassification/pull/1025

## Result

|  Backbone   | ASFF | TOOD | box AP |
| :---------: | :--: | :--: | :----: |
| YOLOX-PAI-s |  N   |  N   |  42.2  |
| YOLOX-PAI-s |  Y   |  N   |  42.9  |
| YOLOX-PAI-s |  Y   |  Y   |  43.9  |

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
2. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
4. The documentation has been modified accordingly, like docstring or example tutorials.
## Motivation

Comparing to PR [#8533](https://github.com/open-mmlab/mmdetection/pull/8533), this PR aims to refactor DAB-DETR in the upcoming MMDetection 3.0!

I'm working together with @jshilong, @Li-Qingyun, and @LYMDLUT to refactor the DETR-like algorithms in MMDetection 3.0, using a more _lightweight_ and _easy-to-read_ code style.

Details can be refered to in [#8763](https://github.com/open-mmlab/mmdetection/pull/8763), feel free to give your advice!Thanks for your contribution and we appreciate it a lot. The following instructions would make your pull request more healthy and more easily get feedback. If you do not understand some items, don't worry, just make the pull request and seek help from maintainers.

## Motivation

Please describe the motivation of this PR and the goal you want to achieve through this PR.

## Modification

1. Add `MaskCost` for K-Net.
2. Update `panoptic_gt_processing`
3. Update docstring in mask_hungarian_assigner
4. Update `MaskFormerHead.preprocess_gt`.

## BC-breaking (Optional)

Does the modification introduce changes that break the backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the downstream projects should modify their code to keep compatibility with this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint issues.
5. The modification is covered by complete unit tests. If not, please add more unit test to ensure the correctness.
6. If the modification has potential influence on downstream projects, this PR should be tested with downstream projects, like MMDet or MMCls.
7. The documentation has been modified accordingly, like docstring or example tutorials.
When using `scale_ranges` in `***Metric`, `average_precision()` returns `ap` as a list, which causes the `round()` exception in ` ***Metric`.
> TypeError: type list doesn't define __round__ methodFixes #157872Changing the get started walkthrough from a checked list to a regular list as some have suggested in issue #142219

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Fixes https://github.com/microsoft/vscode/issues/119345Changed the register themingParticipant to the theme in css

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

Fixes #168601

After reload `instance.target` and `hasChildProcesses` were undefined
For #166603

Also added https://github.com/microsoft/vscode/issues/164935 in
Fixes #159684

![](https://memes.peet.io/img/22-12-1cb508f3-ef31-4d91-912e-dc1fcec3cba3.png)Alternative for #168883

**Requires linked changes in the extension, too. The extension should be published before these changes are released.**<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Fixes #168643

Regression from https://github.com/microsoft/vscode/pull/165742

Problem is the order `onWillShutdown` event gets fired in terminalService, it could fire before `TerminalEditorInput` serialization happens which is also triggered by `onWillShutdown` event. so let's move that logic to the TerminalEditorInput itself as it's created much later, also remove `shutdownPersistentProcessId` as [it was a workaround for this same issue](https://github.com/microsoft/vscode/pull/151852#issuecomment-1159551006)Fixes: https://github.com/microsoft/vscode/issues/151904Fixes #168968<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Fixes #168741

The recently added `AbstractTaskService._inProgressTasks` used the task label to prevent multiple copies of the same task running at the same time. But tasks in different folders can have the same label, and there's no reason not to run them at the same time.

There's an example in #168741 that demonstrates the problem without this commit. The example works in 1.73 and earlier, and also works with this pull request.

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

For #167688 Before this change, editing the Git grammars required making PRs to https://github.com/textmate/git.tmbundle and then importing the new grammars in here.

However, that **upstream repo is dead**:
* No changes since 2019: https://github.com/textmate/git.tmbundle/commits/master
* Upstream test suite requires ruby 1.8.7, which is EOL since 2014:
  https://github.com/textmate/git.tmbundle/issues/59

With this change in place, it is now possible to make PRs to improve Git grammars, to solve problems like this one for example: https://github.com/microsoft/vscode/issues/133888

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

#167146

Another try to fix #167146 by reference https://github.com/microsoft/vscode/pull/167828#issuecomment-1339197955

This PR makes the following changes:
- `IDecorationsProvider` is able to fire another event `onForceRefresh`, to tell which URI need to be refreshed.
- `DecorationsService` will listen to the event, record the `URI`s that need to be refreshed. And when getting values, it will get the fresh value rather than cache from the `IDecorationsProvider` if the `IDecorationsProvider` and `URI` are both same.

However, this PR is kind of noisy, because it adds `onForceRefresh` to all `IDecorationsProvider`s. Should this method be optional?<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
fix #167649
fix https://github.com/microsoft/vscode/issues/167652
fix https://github.com/microsoft/vscode/issues/167646
fix https://github.com/microsoft/vscode/issues/167621
fix  #167584
fix #167586
fix #167587
fix #167557
fix #167590

Also got rid of a hack where I was using `class` to indicate the `type`Fixes #149593

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

Related issue: #168667

See attached issue for details.  But this diff adds support for measuring the latency within the network connection and logs (to logService) measurements of latency that exceed a threshold and also boundary logs of when high latency is detected and resolved.  If desired in the future, this could drive a UX feature that shows when a user is in a high latency situation.
Fixes #158810

@joyceerhl would you be able to test this? I want to make sure it works and it's the safe way of doing this.Fixes #168516

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

To test:

Build the extension in webview-view-sample folder at https://github.com/r3m0t/vscode-extension-samples/tree/webview-samples-slow and install it into VS Code/Code - OSS Dev

Close Workspace (if any is open)

Choose Foo on the activity bar, it loads eventually:

![image](https://user-images.githubusercontent.com/1485998/206670936-56931d15-a202-4ac8-9587-4694158e3f1a.png)

From Command Palette, run "Add folder to Workspace" and choose a trusted folder.

Correct behaviour: the Foo reloads.

Incorrect behaviour (seen in VS Code Insiders and probably VS Code): see screenshot - the webviews are empty

![image](https://user-images.githubusercontent.com/1485998/206671495-fec51a1f-edb6-4730-b187-bbb79a804806.png)
See: #167525<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

Fixes #168451
Fixes #167055

This fixes a conflict in the `@types/node` types in this file

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Fixes #168272 <!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Implements #122664.

Note: I wanted to add unit testing to this but couldn't figure out how to make the editor recognize the multiline text as Typescript, and couldn't find examples to do so.Fix #166885

<img width="394" alt="CleanShot 2022-12-06 at 14 00 50@2x" src="https://user-images.githubusercontent.com/25163139/206032756-fbde000e-9c76-4777-8459-4f50002db058.png">

<img width="194" alt="CleanShot 2022-12-06 at 14 01 03@2x" src="https://user-images.githubusercontent.com/25163139/206032763-a89d50f1-0289-46b7-973a-14b24cb81088.png">

<img width="646" alt="CleanShot 2022-12-06 at 14 01 27@2x" src="https://user-images.githubusercontent.com/25163139/206032768-bcee0e48-3df9-4320-9780-4e09f954d2c0.png">
closes #139400

`XDG_DATA_DIRS` is specified[1] as
> a set of preference ordered base directories relative to which data files should be searched.

the fish shell uses it[2] (among other things)
to let *other tools* provide additional configuration files
for the fish shell to load on startup.

this change exposes the fish shell integration configuration script
in a place matching what fish expects
(in a `fish/vendor_conf.d` subdirectory)
and appends the exposed directory to the value of `XDG_DATA_DIRS`
if automatic shell integration is requested.
if `XDG_DATA_DIRS` is unset it uses the specified default value
`/usr/local/share:/usr/share`
and appends the exposed xdg_data directory to that.

[1]: https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html
[2]: https://fishshell.com/docs/current/language.html#configuration-files

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Fixes https://github.com/microsoft/vscode-remote-release/issues/6972<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

This PR add the `fileWorkspaceFolderBasename` variable that would be useful in `launch.json` and `task.json` configurations. Especially it will be useful to create dynamic launch configurations when a binary name equals to a project root folder name.

Closes #159795
Fixes #148068
Fixes #164926<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Addresses #165169

Leaving one call of `registerThemingParticipant` in `searchView.ts` because there is a fixed opacity applied to the foreground variable.fix #167564 

The changes in `goToDefinitionAtPosition.ts` disable decoration of the nearest token on hover with Ctrl, and the other changes fix the target when clicking. I didn't find out how to add a test for it but I can do that with some mentoring if needed.<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

Fixes #167545

The branch name, if available, is now displayed on the "Commit" button popup.

![Branch name included in the "Commit" button popup](https://user-images.githubusercontent.com/36728931/205034662-49c95bcf-78a6-498f-a676-4c5dbf3e15fd.png)

This PR also updates the "Publish Branch" button's popups:

![publish-popup](https://user-images.githubusercontent.com/36728931/205044228-0ea82bf6-2042-49de-bff7-afd7a584207b.png)
![publishing-popup](https://user-images.githubusercontent.com/36728931/205044220-53606a57-4b3a-4a86-bad4-5b873e0d5902.png)This helps separate elevated widgets from main UI layer and moves them to be consistent with the menu look & feel updates from https://github.com/microsoft/vscode/pull/164165

- Adds `widgetBorder` and applies to quick input, find, debug, feedback, notifications, and more.

<img width="631" alt="CleanShot 2022-12-01 at 11 10 55@2x" src="https://user-images.githubusercontent.com/25163139/205139918-180502df-bfa3-41e4-9ca6-fe106a651a33.png">
<img width="375" alt="CleanShot 2022-12-01 at 11 11 14@2x" src="https://user-images.githubusercontent.com/25163139/205139922-2f8f7c18-5ce0-4243-8acf-8ddd756438b8.png">
<img width="470" alt="CleanShot 2022-12-01 at 11 13 05@2x" src="https://user-images.githubusercontent.com/25163139/205139924-5fe7444f-9a33-4ef6-8b3d-d4599b980c7d.png">
<img width="489" alt="CleanShot 2022-12-01 at 11 14 20@2x" src="https://user-images.githubusercontent.com/25163139/205139925-82ee6e51-d683-4169-9eae-11aa2f0fd363.png">
<img width="494" alt="CleanShot 2022-12-01 at 11 14 25@2x" src="https://user-images.githubusercontent.com/25163139/205139930-189c8ede-3eaf-4954-bbf6-e8b450784774.png">

‚Ä¶only one editor group

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

Fixed #167745.

Fixes https://github.com/microsoft/vscode/issues/164050

![TabFix](https://user-images.githubusercontent.com/28519865/204670969-9b12c0d6-0bde-4e98-a2f4-8f706efccfa5.gif)
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Fixed #167724<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

This PR fixes #54731. 
This is the same code as in PR #104942, but updated to allow setting fixed layout as option. The default behavior remains the same.

This adds a new configuration option `workbench.editor.centeredLayoutFixedWidth` that allows to change the way centered layout reacts to window width change. The default is to stretch/squeeze editor in proportion to window. The new `fixed` behavior attempts to preserve the width. 

The layout width is preserved between the sessions just like with dynamic width; and when switching between the two the layout size is recalculated to preserve the current width.
Ref: https://github.com/microsoft/vscode/issues/165169

Moves css rules for ` src/vs/workbench/browser/parts/activitybar/activitybarActions.ts`
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
fix #135587Improving the performance by running the independent `async` functions in parallel ‚úàÔ∏è.

> I might missed some independent async functions :(

_Sorry if I made any mistakes :(_
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
fix #164679
though `autocomplete=off` doesn't work on chrome/edge, we can add a `name` attribute for non-password inputs to let the browser distinguish them<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

for #165169

- [x] src/vs/workbench/contrib/extensions/browser/extensionEditor.ts
- [x] src/vs/workbench/contrib/extensions/browser/extensionsActions.ts
- [x]  src/vs/workbench/contrib/debug/browser/callStackEditorContribution.ts

This PR is my second attempt at resolving #66971, following feedback from @joaomoreno on my original PR (#164472).

I am submitting it as a draft because  of the 2 ts(2339) problems it contains. I will add a comment to the offending line.
Fixes #162596

This PR adds a validation element to enum settings in the Settings UI. 

A downside is that if the error comes from an invalid value in the JSON file, then the Settings UI will still display one of the valid options in the SelectBox while displaying the error. I'm unable to get the SelectBox to "unselect" any of its options while displaying the error. Changing the innerText also doesn't change the fact that it has a certain valid option selected.

![Screenshot showing a validation error rendering for an enum setting as a red box under the selectBox. The red box contains the error message in white text.](https://user-images.githubusercontent.com/7199958/203448577-a01dc3d2-68c0-40e8-9aeb-a8cbecac6200.png)


<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
We now apply fuzzy matching on the (absolute) path of files/resources, which allows fuzzy matching to work even if the user has a partial absolute path or subpath which is rooted in folders outside of the workspace folders.

The main motivation is that we have files in our code-workspaces which are referenced currently via their folder-relative path, but in many places elsewhere, the paths given are relative to the monorepo. This causes issues when searching, since the monorepo path is longer than the relative path and then search doesn't work.

I'm open to other suggestions - I'm not sure if plain fuzzy matching on the entire path makes sense - for instance, this causes quiet a bit of test failures since the fuzzy matching doesn't have any minimum score requirement so it can match across many fragments of a path.
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

for #165169

- [x]  src/vs/workbench/browser/parts/views/viewFilter.ts
- [x]  src/vs/workbench/browser/style.ts
- [x]  src/vs/workbench/contrib/customEditor/browser/customEditors.ts


Fixes: https://github.com/microsoft/vscode/issues/166747. 
The checkbox now is toggled on select. The completion events now seem to be unnecessary? 

Should we consider adding Next button as a part of this task itself or would we consider that after user feedback? cc: @daviddossett <!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

for #165169

- [x] src/vs/workbench/browser/parts/notifications/notificationsCenter.ts
- [x]  src/vs/workbench/browser/parts/titlebar/menubarControl.ts
- [x]  src/vs/workbench/browser/parts/titlebar/titlebarPart.ts

<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
Fixes #165188

![CleanShot 2022-11-22 at 13 47 48](https://user-images.githubusercontent.com/5123601/203234985-2a66a0a1-b33b-474f-ae30-5365509c2113.gif)


<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->
<!-- Thank you for submitting a Pull Request. Please:
* Read our Pull Request guidelines:
  https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests
* Associate an issue with the Pull Request.
* Ensure that the code is up-to-date with the `main` branch.
* Include a description of the proposed changes and how to test them.
-->

Hello!

## Commit message

By reading "ui/list/listView.ts" we know that whether the tab can be dragged ([```domNode.draggable```](https://github.com/microsoft/vscode/blob/fef85ea792f6627c83024d1df726ca729d8c9cb3/src/vs/base/browser/ui/list/listView.ts#L830)) depends on the "drag URI". When editing the name of a terminal tab, a "falsy" URI should be returned to make the tab undraggable.

Single-click and double-click make terminalTabsList perform some actions (spawning new terminal in a group, focusing on a terminal box, etc), but it should not happen when the tab is being renamed.

I learned above from "[```WatchExpressionsDragAndDrop::getDragURI()```](https://github.com/microsoft/vscode/blob/fef85ea792f6627c83024d1df726ca729d8c9cb3/src/vs/workbench/contrib/debug/browser/watchExpressionsView.ts#L389-L395)" and "[```WatchExpressionsView::onMouseDblClick()```](https://github.com/microsoft/vscode/blob/fef85ea792f6627c83024d1df726ca729d8c9cb3/src/vs/workbench/contrib/debug/browser/watchExpressionsView.ts#L191-L206)" in "debug/browser/watchExpressionsView.ts".

## Related Issues

Did not found, yet.

## Screen Recording

- Before (fef85ea792f6627c83024d1df726ca729d8c9cb3):

Filename: 20221120-vscode-terminalTabsList-ScreenRecording-nay-1.mp4

https://user-images.githubusercontent.com/29089388/202912700-b41a6754-0d31-4168-b066-96b09803f2a9.mp4

<!--
old video:
20221120-vscode-terminalTabsList-ScreenRecording-nay.mp4
https://user-images.githubusercontent.com/29089388/202893573-d2551516-dc01-43ab-b8df-4db8eeccb783.mp4
-->

- After (37f2f6ea1f50a127bb6edf500e35de514926bd33):

Filename: 20221120-vscode-terminalTabsList-ScreenRecording-yea-1.mp4

https://user-images.githubusercontent.com/29089388/202912716-5b93fa94-1d0f-4c46-b5cb-27e3525ba57f.mp4

<!--
old video:
20221120-vscode-terminalTabsList-ScreenRecording-yea.mp4
https://user-images.githubusercontent.com/29089388/202893580-ab208925-3e61-48d8-b689-7af8f7515f51.mp4
-->

<br>

The above videos are recorded by [OBS Studio](https://obsproject.com/) and edited with [Kdenlive](https://kdenlive.org/); the overlay of input of mouse and keyboard is from the [univrsal/input-overlay](https://github.com/univrsal/input-overlay) plugin. Thanks to Open Source.

## How to test

There seems to be no unit tests covering this change, so we may have to test it manually. The steps are as follows.

Here I'm assuming that both "single-clicks" and "double-clicks" are "left-button clicks".

#### Special: focus on a terminal box by single-click

1. In "Settings", set the value of "Terminal > Integrated > Tabs: Focus Mode" to "singleClick".
2. Create multiple terminals to make the tab list appear.
3. Enter "tab name editing mode". Right-click the tab, then click "Rename...".
4. **Try** to single-click the inputbox.
5. **Try** re-entering "tab name editing mode". Press and hold down the mouse button on the tab, then type ```F2``` and release the mouse button.

#### Common steps for following sections

1. In "Settings", set the value of "Terminal > Integrated > Tabs: Focus Mode" to "doubleClick".
2. Create multiple terminals to make the tab list appear.
3. Enter "tab name editing mode". Select the tab, then type ```F2``` or use the right-click context menu.

#### Selection & Draging and Dropping (DnD)

1. **Try** selecting the text in the inputbox. Press and hold down the mouse button and move the cursor.
2. Select the text by keyboard.
3. **Try** move the selection. Drag the selection to a different location and drop it.

#### Focus on a terminal box by double-click

1. **Try** selecting a word by double-clicking it in the inputbox.

#### Spawn a new terminal in a group with the current one

1. **Try** holding the ```ALT``` key and single-clicking the inputbox.

<br>

EOF
Updates telemetry API.
- Moves options out to their own object
- Adds the ability to ignore unhandled errorsThe phrase ‚Äúdouble-clicking‚Äù should almost always be hyphenated.This PR suggests some changes to the wording in the UI of the ‚ÄúContext lines‚Äù feature in Search editors. Though the underlying variables are named in line with the idea of the displayed lines providing context to the user, I think the wording I‚Äôve chosen here (‚Äúsurrounding lines‚Äù) is more natural and makes more sense in terms of UI writing.In recent releases of MongoDB, there‚Äôs a couple optimization been made around Refreshing incremental Routing Info, however the performance issue caused by it wasn‚Äôt rooted out for good that big sharded clusters would still suffer slow queries due to it.

Tencent cloud MongoDB team have (or hope so) come up with an optimization solution to solve the problem by utilizing Two-Dimensional Sorting & Search. With the optimization, there‚Äôd be no latency caused by refreshing routing info, that the refreshing time cost would remain at around 2ms regardless of the data size of the shreded cluster.

In the official release, refreshing routing info requires iterating full ChunkInfo in the ChunkMap twice, plus iterating ChunkVector once to free shared pointers ‚Äì This could be very time- & resource-consuming if the chunk size exceeds certain threshold.

The updated _chunkMap and algorithm in the proposed method requires only one iteration on a very small portion of ChunkInfo based on the changed Chunks to update routing info: _chunkMap, _collectionVersion & _shardVersions.# Patching CVE-2007-4559

Hi, we are security researchers from the Advanced Research Center at [Trellix](https://www.trellix.com). We have began a campaign to patch a widespread bug named CVE-2007-4559. CVE-2007-4559 is a 15 year old bug in the Python tarfile package. By using extract() or extractall() on a tarfile object without sanitizing input, a maliciously crafted .tar file could perform a directory path traversal attack. We found at least one unsantized extractall() in your codebase and are providing a patch for you via pull request. The patch essentially checks to see if all tarfile members will be extracted safely and throws an exception otherwise. We encourage you to use this patch or your own solution to secure against CVE-2007-4559. Further technical information about the vulnerability can be found in this [blog](https://www.trellix.com/en-us/about/newsroom/stories/research/tarfile-exploiting-the-world.html).

If you have further questions you may contact us through this projects lead researcher [Kasimir Schulz](mailto:kasimir.schulz@trellix.com).
# Patching CVE-2007-4559

Hi, we are security researchers from the Advanced Research Center at [Trellix](https://www.trellix.com). We have began a campaign to patch a widespread bug named CVE-2007-4559. CVE-2007-4559 is a 15 year old bug in the Python tarfile package. By using extract() or extractall() on a tarfile object without sanitizing input, a maliciously crafted .tar file could perform a directory path traversal attack. We found at least one unsantized extractall() in your codebase and are providing a patch for you via pull request. The patch essentially checks to see if all tarfile members will be extracted safely and throws an exception otherwise. We encourage you to use this patch or your own solution to secure against CVE-2007-4559. Further technical information about the vulnerability can be found in this [blog](https://www.trellix.com/en-us/about/newsroom/stories/research/tarfile-exploiting-the-world.html).

If you have further questions you may contact us through this projects lead researcher [Kasimir Schulz](mailto:kasimir.schulz@trellix.com).
In recent releases of MongoDB, there‚Äôs a couple optimization been made around Refreshing incremental Routing Info, however the performance issue caused by it wasn‚Äôt rooted out for good that big sharded clusters would still suffer slow queries due to it.

Tencent cloud MongoDB team have (or hope so) come up with an optimization solution to solve the problem by utilizing Two-Dimensional Sorting & Search. With the optimization, there‚Äôd be no latency caused by refreshing routing info, that the refreshing time cost would remain at around 2ms regardless of the data size of the shreded cluster.

In the official release, refreshing routing info requires iterating full ChunkInfo in the ChunkMap twice, plus iterating ChunkVector once to free shared pointers ‚Äì This could be very time- & resource-consuming if the chunk size exceeds certain threshold.

The updated _chunkMap and algorithm in the proposed method requires only one iteration on a very small portion of ChunkInfo based on the changed Chunks to update routing info: _chunkMap, _collectionVersion & _shardVersions.<h3>Snyk has created this PR to upgrade http-server from 0.12.3 to 0.13.0.</h3>

![merge advice](https://app.snyk.io/badges/merge-advice/?package_manager=npm&package_name=http-server&from_version=0.12.3&to_version=0.13.0&pr_id=0af927ca-4867-4e11-9395-8e043512ac79&visibility=true&has_feature_flag=false)
:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.
<hr/>

- The recommended version is **1 version** ahead of your current version.
- The recommended version was released **a year ago**, on 2021-08-07.

The recommended version fixes:

Severity                   | Issue                | PriorityScore (*)                 | Exploit Maturity |
:-------------------------:|:-------------------------|-------------------------|:-------------------------
<img src="https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png" width="20" height="20" title="high severity"/>  | Denial of Service (DoS)<br/> [SNYK-JS-ECSTATIC-540354](https://snyk.io/vuln/SNYK-JS-ECSTATIC-540354) | **696/1000**  <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 7.5  | Proof of Concept 

(*) Note that the real score may have changed since the PR was raised.


<details>
<summary><b>Release notes</b></summary>
<br/>
  <details>
    <summary>Package name: <b>http-server</b></summary>
    <ul>
      <li>
        <b>0.13.0</b> - <a href="https://snyk.io/redirect/github/http-party/http-server/releases/tag/v0.13.0">2021-08-07</a></br><p>A long time coming, the next major release for http-server! This will be the final release before a switch to actual semantic versioning. This release's major achievement is the internalization of the functionality of the now-abandoned <code>ecstatic</code> library, thus removing it as a dependency. Huge thanks to <a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/zbynek/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/zbynek">@ zbynek</a> for help on that front, as well as several other included changes.</p>
<h3>Breaking changes:</h3>
<ul>
<li>No longer sends the header <code>server: http-server-${version}</code> with every response</li>
</ul>
<h3>New features:</h3>
<ul>
<li>All responses include <code>Accept-Ranges: bytes</code> to advertise support for partial requests</li>
</ul>
<h3>Fixes</h3>
<ul>
<li>Removes dependency on the abandoned <code>ecstatic</code> library</li>
<li>Dependency upgrades to fix several security alerts</li>
<li><code>http-server -a 0.0.0.0</code> will now do what you told it to do, rather than overriding the address to 127.0.0.1</li>
<li>Will no longer serve binary files with a charset in the Content-Type, fixing serving WebAssembly files, among other issues</li>
<li>Support <code>.mjs</code> MimeType correctly</li>
</ul>
<h3>Internal</h3>
<ul>
<li>Switched from Travis to GH Actions for CI</li>
</ul>
      </li>
      <li>
        <b>0.12.3</b> - <a href="https://snyk.io/redirect/github/http-party/http-server/releases/tag/v0.12.3">2020-04-27</a></br><p>Patch release to package man page</p>
      </li>
    </ul>
    from <a href="https://snyk.io/redirect/github/http-party/http-server/releases">http-server GitHub release notes</a>
  </details>
</details>


<details>
  <summary><b>Commit messages</b></summary>
  </br>
  <details>
    <summary>Package name: <b>http-server</b></summary>
    <ul>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/77243e7a824a85b2ae0773b7a05fa24d41db2ce5">77243e7</a> 0.13.0</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/a845834986980b85c7ce627b65d7c6a355d6eb27">a845834</a> Update dependency tree</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/f2c0dfb0a5a0b1e3bb444e868d996df3a63663e9">f2c0dfb</a> update milestone</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/aec39118d6be457caf222be3edbd100bdb303127">aec3911</a> update security for release</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/1f994c0df46a40a7e423052dc1d30a323157e35d">1f994c0</a> Merge pull request #591 from http-party/no_server_headers</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/c57654d72f1ebbb4b8db73f9aba87f4ef5aefa50">c57654d</a> Merge branch &#x27;master&#x27; into no_server_headers</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/a4ec10be2838667bd5d4aef17ddfb6ebd3e81329">a4ec10b</a> Merge pull request #713 from http-party/codeql-bye-bye</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/6b87653c2f6ed654444f865a1dab870b347e443a">6b87653</a> drop codeql</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/a7fdf0fd90cb76e19e680e92ec472a0d88fd80c7">a7fdf0f</a> remove server header</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/cd1afb763383e5c592f7c2bb7cdaf9d71a378192">cd1afb7</a> Merge pull request #706 from zbynek/no-charset-binary</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/46c0ce7a38b689293efc7fec2cb3d6d20249e0dc">46c0ce7</a> Merge pull request #705 from zbynek/patch-1</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/9c51cb23b3a4731c6e3466b306b99809362f2ac1">9c51cb2</a> Merge branch &#x27;master&#x27; into no_server_headers</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/cd84a85dc9d3b0afb9d7dc944230bf8df97c76f9">cd84a85</a> revert</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/7830ac22d0c2803efe7781091c3f52591f76362f">7830ac2</a> Remove charset from header of binary files</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/b4991b85c97be6d235b294113bd847a908ea9402">b4991b8</a> Remove line break from LICENSE</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/fab3248827feca1516f6d7b865b019cd235bdc38">fab3248</a> Merge pull request #704 from zbynek/patch-1</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/e9716d1418e04dedab0ce82218117be67f6bd34f">e9716d1</a> Account for CRLF in a test</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/0f3e24188a3362253ccedfcf64beefa682352b3b">0f3e241</a> Merge pull request #642 from skyward-luke/master</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/33fe714aa1970429de1d942a18f16aa62d5b0828">33fe714</a> Merge pull request #702 from http-party/replace-travis</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/e9ad2693debb1ce6ac96c955d5090729b264c429">e9ad269</a> Replace travis badge</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/f09c821cd5cc6840a6ad2d5af00930eaf87f66f0">f09c821</a> Update node.js.yml</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/2c2ad02a9cfa8334ad612cf07f2dad966ce2c194">2c2ad02</a> Update node.js.yml</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/dad375d2ba12ef3a3b65a9482ef0b3d6682977e8">dad375d</a> Update node.js.yml</li>
      <li><a href="https://snyk.io/redirect/github/http-party/http-server/commit/133a64c762498a527fed1b31a0f80d98b644b669">133a64c</a> Update node.js.yml</li>
    </ul>

   <a href="https://snyk.io/redirect/github/http-party/http-server/compare/d7bce39827d4db03190cb33b5f33d3a543464ee1...77243e7a824a85b2ae0773b7a05fa24d41db2ce5">Compare</a>
  </details>
</details>
<hr/>

**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*

For more information:  <img src="https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwYWY5MjdjYS00ODY3LTRlMTEtOTM5NS04ZTA0MzUxMmFjNzkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjBhZjkyN2NhLTQ4NjctNGUxMS05Mzk1LThlMDQzNTEyYWM3OSJ9fQ==" width="0" height="0"/>

üßê [View latest project report](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üõ† [Adjust upgrade PR settings](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üîï [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?pkg&#x3D;http-server&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)

<!--- (snyk:metadata:{"prId":"0af927ca-4867-4e11-9395-8e043512ac79","prPublicId":"0af927ca-4867-4e11-9395-8e043512ac79","dependencies":[{"name":"http-server","from":"0.12.3","to":"0.13.0"}],"packageManager":"npm","type":"auto","projectUrl":"https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source=github&utm_medium=referral&page=upgrade-pr","projectPublicId":"3b2e88fd-cb95-451f-b9f9-1f2c4e47706f","env":"prod","prType":"upgrade","vulns":["SNYK-JS-ECSTATIC-540354"],"issuesToFix":[{"issueId":"SNYK-JS-ECSTATIC-540354","severity":"high","title":"Denial of Service (DoS)","exploitMaturity":"proof-of-concept","priorityScore":696,"priorityScoreFactors":[{"type":"exploit","label":"Proof of Concept","score":107},{"type":"fixability","label":true,"score":214},{"type":"cvssScore","label":"7.5","score":375}]}],"upgrade":["SNYK-JS-ECSTATIC-540354"],"upgradeInfo":{"versionsDiff":1,"publishedDate":"2021-08-07T19:10:45.347Z"},"templateVariants":["merge-advice-badge-shown","priorityScore"],"hasFixes":true,"isMajorUpgrade":false,"isBreakingChange":false,"priorityScoreList":[696]}) --->
<h3>Snyk has created this PR to upgrade react-force-graph-3d from 1.18.8 to 1.21.12.</h3>

![merge advice](https://app.snyk.io/badges/merge-advice/?package_manager=npm&package_name=react-force-graph-3d&from_version=1.18.8&to_version=1.21.12&pr_id=d853b9e8-f507-4eac-88ca-7d419e1b44cd&visibility=true&has_feature_flag=false)
:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.
<hr/>

- The recommended version is **18 versions** ahead of your current version.
- The recommended version was released **7 months ago**, on 2022-01-31.


<details>
<summary><b>Release notes</b></summary>
<br/>
  <details>
    <summary>Package name: <b>react-force-graph-3d</b></summary>
    <ul>
      <li>
        <b>1.21.12</b> - 2022-01-31
      </li>
      <li>
        <b>1.21.11</b> - 2022-01-31
      </li>
      <li>
        <b>1.21.10</b> - 2021-07-09
      </li>
      <li>
        <b>1.21.9</b> - 2021-06-19
      </li>
      <li>
        <b>1.21.8</b> - 2021-05-26
      </li>
      <li>
        <b>1.21.7</b> - 2021-05-24
      </li>
      <li>
        <b>1.21.6</b> - 2021-05-13
      </li>
      <li>
        <b>1.21.5</b> - 2021-05-12
      </li>
      <li>
        <b>1.21.4</b> - 2021-05-08
      </li>
      <li>
        <b>1.21.3</b> - 2021-04-22
      </li>
      <li>
        <b>1.21.2</b> - 2021-04-21
      </li>
      <li>
        <b>1.21.1</b> - 2021-04-05
      </li>
      <li>
        <b>1.21.0</b> - 2021-03-17
      </li>
      <li>
        <b>1.20.0</b> - 2021-03-17
      </li>
      <li>
        <b>1.19.2</b> - 2021-03-16
      </li>
      <li>
        <b>1.19.1</b> - 2021-03-10
      </li>
      <li>
        <b>1.19.0</b> - 2021-03-10
      </li>
      <li>
        <b>1.18.9</b> - 2021-02-03
      </li>
      <li>
        <b>1.18.8</b> - 2020-10-13
      </li>
    </ul>
    from <a href="https://snyk.io/redirect/github/vasturiano/react-force-graph/releases">react-force-graph-3d GitHub release notes</a>
  </details>
</details>
<hr/>

**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*

For more information:  <img src="https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkODUzYjllOC1mNTA3LTRlYWMtODhjYS03ZDQxOWUxYjQ0Y2QiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImQ4NTNiOWU4LWY1MDctNGVhYy04OGNhLTdkNDE5ZTFiNDRjZCJ9fQ==" width="0" height="0"/>

üßê [View latest project report](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üõ† [Adjust upgrade PR settings](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üîï [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?pkg&#x3D;react-force-graph-3d&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)

<!--- (snyk:metadata:{"prId":"d853b9e8-f507-4eac-88ca-7d419e1b44cd","prPublicId":"d853b9e8-f507-4eac-88ca-7d419e1b44cd","dependencies":[{"name":"react-force-graph-3d","from":"1.18.8","to":"1.21.12"}],"packageManager":"npm","type":"auto","projectUrl":"https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source=github&utm_medium=referral&page=upgrade-pr","projectPublicId":"3b2e88fd-cb95-451f-b9f9-1f2c4e47706f","env":"prod","prType":"upgrade","vulns":[],"issuesToFix":[],"upgrade":[],"upgradeInfo":{"versionsDiff":18,"publishedDate":"2022-01-31T19:59:04.748Z"},"templateVariants":["merge-advice-badge-shown"],"hasFixes":false,"isMajorUpgrade":false,"isBreakingChange":false,"priorityScoreList":[]}) --->
<h3>Snyk has created this PR to upgrade force-graph from 1.40.0 to 1.42.11.</h3>

![merge advice](https://app.snyk.io/badges/merge-advice/?package_manager=npm&package_name=force-graph&from_version=1.40.0&to_version=1.42.11&pr_id=20d8f7a8-8abc-47ab-876d-ef84c73fe5eb&visibility=true&has_feature_flag=false)
:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.
<hr/>

- The recommended version is **21 versions** ahead of your current version.
- The recommended version was released **2 months ago**, on 2022-07-11.

The recommended version fixes:

Severity                   | Issue                | PriorityScore (*)                 | Exploit Maturity |
:-------------------------:|:-------------------------|-------------------------|:-------------------------
<img src="https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png" width="20" height="20" title="medium severity"/>  | Regular Expression Denial of Service (ReDoS)<br/> [SNYK-JS-D3COLOR-1076592](https://snyk.io/vuln/SNYK-JS-D3COLOR-1076592) | **586/1000**  <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.3  | Proof of Concept 

(*) Note that the real score may have changed since the PR was raised.


<details>
<summary><b>Release notes</b></summary>
<br/>
  <details>
    <summary>Package name: <b>force-graph</b></summary>
    <ul>
      <li>
        <b>1.42.11</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.11">2022-07-11</a></br><p>1.42.11</p>
      </li>
      <li>
        <b>1.42.10</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.10">2022-07-08</a></br><p>1.42.10</p>
      </li>
      <li>
        <b>1.42.9</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.9">2022-03-26</a></br><p>1.42.9</p>
      </li>
      <li>
        <b>1.42.8</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.8">2022-03-13</a></br><p>1.42.8</p>
      </li>
      <li>
        <b>1.42.7</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.7">2022-02-09</a></br><p>1.42.7</p>
      </li>
      <li>
        <b>1.42.6</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.6">2022-02-09</a></br><p>1.42.6</p>
      </li>
      <li>
        <b>1.42.5</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.5">2022-01-30</a></br><p>1.42.5</p>
      </li>
      <li>
        <b>1.42.4</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.4">2021-10-14</a></br><p>1.42.4</p>
      </li>
      <li>
        <b>1.42.3</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.3">2021-10-03</a></br><p>1.42.3</p>
      </li>
      <li>
        <b>1.42.2</b> - <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases/tag/v1.42.2">2021-08-04</a></br><p>1.42.2</p>
      </li>
      <li>
        <b>1.42.1</b> - 2021-07-10
      </li>
      <li>
        <b>1.42.0</b> - 2021-07-08
      </li>
      <li>
        <b>1.41.2</b> - 2021-06-19
      </li>
      <li>
        <b>1.41.1</b> - 2021-05-26
      </li>
      <li>
        <b>1.41.0</b> - 2021-05-26
      </li>
      <li>
        <b>1.40.6</b> - 2021-05-24
      </li>
      <li>
        <b>1.40.5</b> - 2021-05-11
      </li>
      <li>
        <b>1.40.4</b> - 2021-05-10
      </li>
      <li>
        <b>1.40.3</b> - 2021-04-28
      </li>
      <li>
        <b>1.40.2</b> - 2021-04-22
      </li>
      <li>
        <b>1.40.1</b> - 2021-04-21
      </li>
      <li>
        <b>1.40.0</b> - 2021-04-06
      </li>
    </ul>
    from <a href="https://snyk.io/redirect/github/vasturiano/force-graph/releases">force-graph GitHub release notes</a>
  </details>
</details>


<details>
  <summary><b>Commit messages</b></summary>
  </br>
  <details>
    <summary>Package name: <b>force-graph</b></summary>
    <ul>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/c70471da38484e3e1b6620ad6127874c737e5400">c70471d</a> 1.42.11</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/f6c25dad4da4eb297814b98631fe00801fe137b2">f6c25da</a> Merge pull request #272 from stefanprobst/export-types</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/fdbddfbecbbf7eba4480758e0da91a54c47f1260">fdbddfb</a> add any to allowed return type for CanvasCustomRenderModeFn</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/2999e8e787e559456fb1a3047172d39489470c9a">2999e8e</a> Export types</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/9dd5c49e9e9e014ba68f13e13d53438bfd06fbeb">9dd5c49</a> 1.42.10</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/7ff7b679836de030dbdfda39c9ddcaba8331b9e3">7ff7b67</a> Bump dev deps</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/f8cd0043c6502fc43e9d3b3749291a17d79662a1">f8cd004</a> Merge pull request #271 from stefanprobst/module-augmentation</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/674563d681328d8d5af2e66a2637030c4a50a20f">674563d</a> Allow module augmentation for NodeObject and LinkObject types</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/fcb2647526be264b48098d38b446f34377d6e264">fcb2647</a> 1.42.9</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/16400ca0a2fe2449f4f864d87285990810c97062">16400ca</a> Bump deps</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/2170b5f2b88d68097017d5ff339c638fd54a6385">2170b5f</a> Merge branch &#x27;voraciousdev-prevent-initial-graph-tooltip-overflow&#x27;</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/a56ea689628cd0165dca4f5e071df78183a0da20">a56ea68</a> Pin only top position</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/a9499aa571e227ab056020e96202dbe21a60036d">a9499aa</a> Prevent initial graph-tooltip overflow</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/c26cacd52dbb7d49aa5cd6218efe00bc188a1009">c26cacd</a> 1.42.8</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/288a05f823bc32be03383472b7d78c3d44ade198">288a05f</a> Bump deps</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/4afc50fe3c72481aae6ef2d28323d09e897a6328">4afc50f</a> Merge branch &#x27;Trombach-patch-1&#x27;</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/eb3709f47852efe2f1dc96e3da152573160c5cf4">eb3709f</a> Allow any falsy type on nodeCanvasObjectMode</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/d704d2ec54b3a042f6654801c378da115b00acff">d704d2e</a> Updated type signature of nodeCanvasObjectMode</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/5c91509d895bdeea0c6b67ed154c09571c6f7d49">5c91509</a> 1.42.7</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/4a1fc4ecc6051e36cd393744d458c8678ed5dda1">4a1fc4e</a> Upd readme</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/452cfb28cfb6a0ccf4503c1e5460045f3e8f39e5">452cfb2</a> 1.42.6</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/e4190230bcc180fbbe6952e03cb275a8e4142a03">e419023</a> Upd readme</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/1fb942d37bb2490cfe4885208a217bd2793cad5e">1fb942d</a> 1.42.5</li>
      <li><a href="https://snyk.io/redirect/github/vasturiano/force-graph/commit/12401c875437fe3b2ae8b2df53f7208c291c2121">12401c8</a> Bump deps</li>
    </ul>

   <a href="https://snyk.io/redirect/github/vasturiano/force-graph/compare/d701c09fd1957ad5eeaf5b805e7b8acb9e8a5d6a...c70471da38484e3e1b6620ad6127874c737e5400">Compare</a>
  </details>
</details>
<hr/>

**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*

For more information:  <img src="https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyMGQ4ZjdhOC04YWJjLTQ3YWItODc2ZC1lZjg0YzczZmU1ZWIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjIwZDhmN2E4LThhYmMtNDdhYi04NzZkLWVmODRjNzNmZTVlYiJ9fQ==" width="0" height="0"/>

üßê [View latest project report](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üõ† [Adjust upgrade PR settings](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üîï [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?pkg&#x3D;force-graph&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)

<!--- (snyk:metadata:{"prId":"20d8f7a8-8abc-47ab-876d-ef84c73fe5eb","prPublicId":"20d8f7a8-8abc-47ab-876d-ef84c73fe5eb","dependencies":[{"name":"force-graph","from":"1.40.0","to":"1.42.11"}],"packageManager":"npm","type":"auto","projectUrl":"https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source=github&utm_medium=referral&page=upgrade-pr","projectPublicId":"3b2e88fd-cb95-451f-b9f9-1f2c4e47706f","env":"prod","prType":"upgrade","vulns":["SNYK-JS-D3COLOR-1076592"],"issuesToFix":[{"issueId":"SNYK-JS-D3COLOR-1076592","severity":"medium","title":"Regular Expression Denial of Service (ReDoS)","exploitMaturity":"proof-of-concept","priorityScore":586,"priorityScoreFactors":[{"type":"exploit","label":"Proof of Concept","score":107},{"type":"fixability","label":true,"score":214},{"type":"cvssScore","label":"5.3","score":265}]}],"upgrade":["SNYK-JS-D3COLOR-1076592"],"upgradeInfo":{"versionsDiff":21,"publishedDate":"2022-07-11T16:51:55.586Z"},"templateVariants":["merge-advice-badge-shown","priorityScore"],"hasFixes":true,"isMajorUpgrade":false,"isBreakingChange":false,"priorityScoreList":[586]}) --->
Knowing that a cache will be larger than cache allows to make different
decisions about how to ingest new content and store the index information.

This currently compiles, but I very much doubt it would work...Remove redundant function call.

The following three perform the same logic, why not just call the os.path.dirnam() function once???

```python
MONGODB_ROOT = os.path.abspath(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
MONGODB_ROOT = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
MONGODB_ROOT = os.path.abspath(os.path.dirname(__file__))
```<h4 dir="auto" style="box-sizing: border-box; margin-top: 24px; margin-bottom: 16px; font-size: 14px; font-weight: 600; line-height: 1.25; color: rgb(201, 209, 217); font-family: -apple-system, &quot;system-ui&quot;, &quot;Segoe UI&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(13, 17, 23); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;">Changes included in this PR</h4><ul dir="auto" style="box-sizing: border-box; padding-left: 2em; margin-top: 0px; margin-bottom: 16px; color: rgb(201, 209, 217); font-family: -apple-system, &quot;system-ui&quot;, &quot;Segoe UI&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;; font-size: 14px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(13, 17, 23); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"><li style="box-sizing: border-box; margin-left: 0px;">Changes to the following files to upgrade the vulnerable dependencies to a fixed version:<ul dir="auto" style="box-sizing: border-box; padding-left: 2em; margin-top: 0px; margin-bottom: 0px;"><li style="box-sizing: border-box; margin-left: 0px;">buildscripts/libdeps/graph_visualizer_web_stack/package.json</li></ul></li></ul><h4 dir="auto" style="box-sizing: border-box; margin-top: 24px; margin-bottom: 16px; font-size: 14px; font-weight: 600; line-height: 1.25; color: rgb(201, 209, 217); font-family: -apple-system, &quot;system-ui&quot;, &quot;Segoe UI&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(13, 17, 23); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;">Vulnerabilities that will be fixed</h4><h5 dir="auto" style="box-sizing: border-box; margin-top: 24px; margin-bottom: 16px; font-size: 0.875em; font-weight: 600; line-height: 1.25; color: rgb(201, 209, 217); font-family: -apple-system, &quot;system-ui&quot;, &quot;Segoe UI&quot;, Helvetica, Arial, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(13, 17, 23); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;">With an upgrade:</h5>

Severity | Priority Score (*) | Issue | Breaking Change | Exploit Maturity
-- | -- | -- | -- | --
¬†High | 696/1000Why?¬†Proof of Concept exploit, Has a fix available, CVSS 7.5 | Denial of Service (DoS)SNYK-JS-ECSTATIC-540354 | No | Proof of Concept

[](https://camo.githubusercontent.com/9d51f28c19d68a26a2a08210e149d8afec20f84af0925bd9aedbd406c56cad72/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f736e796b2f696d6167652f75706c6f61642f775f32302c685f32302f76313536313937373831392f69636f6e2f682e706e67)In this patch:
- Added a concatenate_with_tenant_id_and_db namespace type for IDL defined commands
- Removed securityToken from opCtx and put on the request object

Not in this patch:
- Changes to logging
- Changes to audit

Example of command parse method (I realized it might be nice to see the generated code):
```
CreateCommand CreateCommand::parse(const IDLParserErrorContext& ctxt, const OpMsgRequest& request) {
    NamespaceString localNS;
    CreateCommand object(localNS);
    object.parseProtected(ctxt, request);
    return object;
}
void CreateCommand::parseProtected(const IDLParserErrorContext& ctxt, const OpMsgRequest& request) {
    std::bitset<23> usedFields;
    const size_t kCappedBit = 0;
    const size_t kAutoIndexIdBit = 1;
    const size_t kIdIndexBit = 2;
    const size_t kSizeBit = 3;
    const size_t kMaxBit = 4;
    const size_t kStorageEngineBit = 5;
    const size_t kValidatorBit = 6;
    const size_t kValidationLevelBit = 7;
    const size_t kValidationActionBit = 8;
    const size_t kIndexOptionDefaultsBit = 9;
    const size_t kViewOnBit = 10;
    const size_t kPipelineBit = 11;
    const size_t kCollationBit = 12;
    const size_t kRecordPreImagesBit = 13;
    const size_t kChangeStreamPreAndPostImagesBit = 14;
    const size_t kTimeseriesBit = 15;
    const size_t kClusteredIndexBit = 16;
    const size_t kExpireAfterSecondsBit = 17;
    const size_t kEncryptedFieldsBit = 18;
    const size_t kTempBit = 19;
    const size_t kFlagsBit = 20;
    const size_t kDbNameBit = 21;
    const size_t kDollarTenantIdBit = 22;
    BSONElement commandElement;
    bool firstFieldFound = false;

    for (const auto& element :request.body) {
        const auto fieldName = element.fieldNameStringData();

        if (firstFieldFound == false) {
            commandElement = element;
            firstFieldFound = true;
            continue;
        }

        if (fieldName == kCappedFieldName) {
            if (MONGO_likely(ctxt.checkAndAssertTypes(element, {Bool, NumberLong, NumberInt, NumberDecimal, NumberDouble}))) {
                if (MONGO_unlikely(usedFields[kCappedBit])) {
                    ctxt.throwDuplicateField(element);
                }

                usedFields.set(kCappedBit);

                _capped = element.trueValue();
            }
        }
       ******
       // continue setting all other fields, removing to be more concise
      *******
        else if (fieldName == kDbNameFieldName) {
            if (MONGO_likely(ctxt.checkAndAssertType(element, String))) {
                if (MONGO_unlikely(usedFields[kDbNameBit])) {
                    ctxt.throwDuplicateField(element);
                }

                usedFields.set(kDbNameBit);

                _hasDbName = true;
                _dbName = element.str();
            }
        }
        else if (fieldName == kDollarTenantIdFieldName) {
            if (MONGO_unlikely(usedFields[kDollarTenantIdBit])) {
                ctxt.throwDuplicateField(element);
            }

            usedFields.set(kDollarTenantIdBit);

            _dollarTenantId = TenantId::parseFromBSON(element);
        }
        else {
            if (!mongo::isGenericArgument(fieldName)) {
                ctxt.throwUnknownField(fieldName);
            }
        }
    }


    if (MONGO_unlikely(!usedFields.all())) {
        if (!usedFields[kDbNameBit]) {
            ctxt.throwMissingField(kDbNameFieldName);
        }
    }

    boost::optional<TenantId> tenantId;

    if (request.securityToken.nFields() > 0) {
        _securityToken.emplace(auth::SecurityToken::parse({"Security Token"}, request.securityToken));
        uassert(ErrorCodes::BadValue, "Security token authenticated user requires a valid Tenant ID", _securityToken->getAuthenticatedUser().getTenant());
        tenantId.emplace(*_securityToken->getAuthenticatedUser().getTenant());
    }

    if (!tenantId && _dollarTenantId) {
        tenantId.emplace(*_dollarTenantId);
    }
    invariant(_nss.isEmpty());

    _nss = ctxt.parseNSCollectionRequired(_dbName, commandElement, false, tenantId);
}
```https://jira.mongodb.org/browse/SERVER-62642JIRA Ticket: https://jira.mongodb.org/browse/SERVER-45617

Notes:

1. `codepoints_diacritic_map.cpp` was changed to add removal of diacritis for ƒê and ƒë. It had to be updated manually because it doesn't look like it is being regenerated based on the `SConscript` script located in the `fts/unicode` folder.

2. Serbian stemmer from the latest version of _Snowball_ was adjusted for and compiled with the version of _Snowball_ that is currently being used in _MongoDB_.‚Ä¶ameterupdated READMEhttps://jira.mongodb.org/browse/SERVER-58467<h3>Snyk has created this PR to upgrade react-force-graph-2d from 1.18.1 to 1.23.10.</h3>

![merge advice](https://app.snyk.io/badges/merge-advice/?package_manager=npm&package_name=react-force-graph-2d&from_version=1.18.1&to_version=1.23.10&pr_id=5c55aee8-807c-4bd9-8291-7ccfc23599c1&visibility=true&has_feature_flag=false)
:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.
<hr/>

- The recommended version is **19 versions** ahead of your current version.
- The recommended version was released **7 months ago**, on 2022-01-31.


<details>
<summary><b>Release notes</b></summary>
<br/>
  <details>
    <summary>Package name: <b>react-force-graph-2d</b></summary>
    <ul>
      <li>
        <b>1.23.10</b> - 2022-01-31
      </li>
      <li>
        <b>1.23.9</b> - 2022-01-31
      </li>
      <li>
        <b>1.23.8</b> - 2021-07-09
      </li>
      <li>
        <b>1.23.7</b> - 2021-06-19
      </li>
      <li>
        <b>1.23.6</b> - 2021-05-26
      </li>
      <li>
        <b>1.23.5</b> - 2021-05-24
      </li>
      <li>
        <b>1.23.4</b> - 2021-05-12
      </li>
      <li>
        <b>1.23.3</b> - 2021-05-08
      </li>
      <li>
        <b>1.23.2</b> - 2021-04-22
      </li>
      <li>
        <b>1.23.1</b> - 2021-04-21
      </li>
      <li>
        <b>1.23.0</b> - 2021-04-06
      </li>
      <li>
        <b>1.22.2</b> - 2021-04-05
      </li>
      <li>
        <b>1.22.1</b> - 2021-03-16
      </li>
      <li>
        <b>1.22.0</b> - 2021-03-15
      </li>
      <li>
        <b>1.21.0</b> - 2021-03-10
      </li>
      <li>
        <b>1.19.1</b> - 2021-03-10
      </li>
      <li>
        <b>1.19.0</b> - 2021-02-04
      </li>
      <li>
        <b>1.18.3</b> - 2021-02-03
      </li>
      <li>
        <b>1.18.2</b> - 2021-01-24
      </li>
      <li>
        <b>1.18.1</b> - 2020-10-13
      </li>
    </ul>
    from <a href="https://snyk.io/redirect/github/vasturiano/react-force-graph/releases">react-force-graph-2d GitHub release notes</a>
  </details>
</details>
<hr/>

**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*

For more information:  <img src="https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1YzU1YWVlOC04MDdjLTRiZDktODI5MS03Y2NmYzIzNTk5YzEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVjNTVhZWU4LTgwN2MtNGJkOS04MjkxLTdjY2ZjMjM1OTljMSJ9fQ==" width="0" height="0"/>

üßê [View latest project report](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üõ† [Adjust upgrade PR settings](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üîï [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?pkg&#x3D;react-force-graph-2d&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)

<!--- (snyk:metadata:{"prId":"5c55aee8-807c-4bd9-8291-7ccfc23599c1","prPublicId":"5c55aee8-807c-4bd9-8291-7ccfc23599c1","dependencies":[{"name":"react-force-graph-2d","from":"1.18.1","to":"1.23.10"}],"packageManager":"npm","type":"auto","projectUrl":"https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source=github&utm_medium=referral&page=upgrade-pr","projectPublicId":"3b2e88fd-cb95-451f-b9f9-1f2c4e47706f","env":"prod","prType":"upgrade","vulns":[],"issuesToFix":[],"upgrade":[],"upgradeInfo":{"versionsDiff":19,"publishedDate":"2022-01-31T19:58:41.126Z"},"templateVariants":["merge-advice-badge-shown"],"hasFixes":false,"isMajorUpgrade":false,"isBreakingChange":false,"priorityScoreList":[]}) --->
<h3>Snyk has created this PR to upgrade bezier-js from 4.0.3 to 4.1.1.</h3>

![merge advice](https://app.snyk.io/badges/merge-advice/?package_manager=npm&package_name=bezier-js&from_version=4.0.3&to_version=4.1.1&pr_id=c15ebea6-125e-4b48-827a-da551330be8c&visibility=true&has_feature_flag=false)
:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.
<hr/>

- The recommended version is **2 versions** ahead of your current version.
- The recommended version was released **a year ago**, on 2021-04-30.


<details>
<summary><b>Release notes</b></summary>
<br/>
  <details>
    <summary>Package name: <b>bezier-js</b></summary>
    <ul>
      <li>
        <b>4.1.1</b> - <a href="https://snyk.io/redirect/github/Pomax/bezierjs/releases/tag/v4.1.1">2021-04-30</a></br><p>4.1.1</p>
      </li>
      <li>
        <b>4.1.0</b> - <a href="https://snyk.io/redirect/github/Pomax/bezierjs/releases/tag/v4.1.0">2021-04-20</a></br><p>4.1.0</p>
      </li>
      <li>
        <b>4.0.3</b> - <a href="https://snyk.io/redirect/github/Pomax/bezierjs/releases/tag/v4.0.3">2020-11-15</a></br><p>4.0.3</p>
      </li>
    </ul>
    from <a href="https://snyk.io/redirect/github/Pomax/bezierjs/releases">bezier-js GitHub release notes</a>
  </details>
</details>


<details>
  <summary><b>Commit messages</b></summary>
  </br>
  <details>
    <summary>Package name: <b>bezier-js</b></summary>
    <ul>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/707f7f50b4671a7940e3adfc0f89ec92395cdf3f">707f7f5</a> 4.1.1</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/6af37cf944fec7038bcdfa4d56e378d869eb8ab0">6af37cf</a> Merge pull request #154 from pranavtotla/master</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/9832af011611a538e6a478d74628497fc4b78124">9832af0</a> Fix: lerp() for 3D points where z is 0</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/cb4fe3e55add7401bdc5ee56ada46abb61b55883">cb4fe3e</a> 4.1.0</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/9448953bd7f7485688ca728dcf4b4d3a2ede9170">9448953</a> Merge pull request #150 from GrumpySailor/fix/commonjs</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/094da68c5fcd4af8e0bccc855ed11596e9c6c354">094da68</a> Add Node Support Matrix</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/43677c0e5d27de9392203e4ca9492a222f48f584">43677c0</a> Switch to Conditional Exports</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/4e5cd955eeb6c561f4e18a36f35d66ef26b3c0e1">4e5cd95</a> Fix CommonJS</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/c6a33e6021f302a8969843e403b8db52794061e7">c6a33e6</a> Merge pull request #147 from joostdecock/patch-1</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/b61c031678a28397efdc267b6e901c5551630430">b61c031</a> Fixed project name in README funding pitch</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/be81bfb68910016bdbc68e7c52a3b42499bc0679">be81bfb</a> Update package.json</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/fad9f7664ea857595d162ea97d03fce189d83faf">fad9f76</a> Update FUNDING.md</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/a410da13eec50cceae3b63f9171d6a21f61ab416">a410da1</a> Create FUNDING.md</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/70a8d79ab4482c88a6261fa0fdc23eb48588842f">70a8d79</a> Update package.json</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/7e2ace1e81abbd1bdb861170c6096b059832125c">7e2ace1</a> Update README.md</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/060cac550798266aefc18db0099213f7121df480">060cac5</a> Merge pull request #143 from ntamas/fix/derivative-3d</li>
      <li><a href="https://snyk.io/redirect/github/Pomax/bezierjs/commit/1c34a81684d5726a362c13dda9ec967e28f40cc9">1c34a81</a> derivative calculations now work for the 3D case as well</li>
    </ul>

   <a href="https://snyk.io/redirect/github/Pomax/bezierjs/compare/ebbd3050b4ca106957bd7e6dfc69a830df89d64b...707f7f50b4671a7940e3adfc0f89ec92395cdf3f">Compare</a>
  </details>
</details>
<hr/>

**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*

For more information:  <img src="https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMTVlYmVhNi0xMjVlLTRiNDgtODI3YS1kYTU1MTMzMGJlOGMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMxNWViZWE2LTEyNWUtNGI0OC04MjdhLWRhNTUxMzMwYmU4YyJ9fQ==" width="0" height="0"/>

üßê [View latest project report](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üõ† [Adjust upgrade PR settings](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üîï [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f/settings/integration?pkg&#x3D;bezier-js&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)

<!--- (snyk:metadata:{"prId":"c15ebea6-125e-4b48-827a-da551330be8c","prPublicId":"c15ebea6-125e-4b48-827a-da551330be8c","dependencies":[{"name":"bezier-js","from":"4.0.3","to":"4.1.1"}],"packageManager":"npm","type":"auto","projectUrl":"https://app.snyk.io/org/mongodb-default/project/3b2e88fd-cb95-451f-b9f9-1f2c4e47706f?utm_source=github&utm_medium=referral&page=upgrade-pr","projectPublicId":"3b2e88fd-cb95-451f-b9f9-1f2c4e47706f","env":"prod","prType":"upgrade","vulns":[],"issuesToFix":[],"upgrade":[],"upgradeInfo":{"versionsDiff":2,"publishedDate":"2021-04-30T15:29:37.265Z"},"templateVariants":["merge-advice-badge-shown"],"hasFixes":false,"isMajorUpgrade":false,"isBreakingChange":false,"priorityScoreList":[]}) --->
When building with SSL=off, latest 4.4.4 release doesn't compile with the following error:

```
src/mongo/db/db.cpp:340: error: undefined reference to 'mongo::OCSPManager::startThreadPool()'
src/mongo/util/net/ocsp/ocsp_manager.h:49: error: undefined reference to 'mongo::OCSPManager::OCSPManager()'
collect2: error: ld returned 1 exit status
scons: *** [build/opt/mongo/mongod] Error 1
scons: building terminated because of errors.
build/opt/mongo/mongod failed: Error 1
```

OCSPManager thread pool probably shouldn't be started when SSL is off, as this class is not compiled in the presence of such an option.

Also some info here: https://developer.mongodb.com/community/forums/t/failure-to-build-mongodb-4-4-4/100231

This is blocking Meteor build of MongoDB, as we do use a small binary without SSL for development easiness.

The last version it was working is : MONGODB_VERSION='4.2.8'In recent versions of WSL2, the `/proc/sys/kernel/osrelease` has changed -- the string "microsoft" can now be lower case.
```
> cat /proc/sys/kernel/osrelease
4.19.128-microsoft-standard
```
This PR simply changes the check to be case-insensitive.Added a Dockerfile to build Ubuntu 18.04 based image with all the required dependencies to run mongo build.# Keep receiving  [ftdc] Rollback ID is not initialized yet.


```
2020-12-14T02:22:27.353+0000 I NETWORK  [conn162784] end connection 127.0.0.1:60928 (1 connection now open)
2020-12-14T02:22:28.000+0000 W REPL     [ftdc] Rollback ID is not initialized yet.
2020-12-14T02:22:29.000+0000 W REPL     [ftdc] Rollback ID is not initialized yet.
2020-12-14T02:22:30.000+0000 W REPL     [ftdc] Rollback ID is not initialized yet.
2020-12-14T02:22:31.000+0000 W REPL     [ftdc] Rollback ID is not initialized yet.
2020-12-14T02:22:31.335+0000 I NETWORK  [listener] connection accepted from 127.0.0.1:32846 #162785 (2 connections now open)
2020-12-14T02:22:31.336+0000 I NETWORK  [conn162785] received client metadata from 127.0.0.1:32846 conn162785: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "3.6.21" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2020-12-14T02:22:31.339+0000 I ACCESS   [conn162785] Unauthorized: not authorized on admin to execute command { endSessions: [ { id: UUID("be0872d6-b470-48e0-b332-51c9b861d4e1") } ], $db: "admin" }
```



Add mips arch support. Test on loongson cloud platform(base on loongson 3A4000) 

I noted that there was a pull request before, but it was rejected. The main reason is mongodb version too old, and you don't have test machine for mips arch.
We have modified and tested it in the master brach.
If necessary, We can provide a mips arch test environment by an account of loongson cloud platform.

In the third party, most of the changes are related to the configuratin of the arch. Only "mozjs-60" and "wiredtiger" require some simple source code changes.

ChangeLog:
1. Modify ./SConstruct. Add mips arch configuration.
2. Modify ./thrid_party/IntelRDFPMathLib20U1/SConscript. Add mips arch configuration.
3. Modify ./thrid_party/gperftools-2.7. Add mips arch support. Auto-generate source code by shell script "import.sh" and "host_config.sh".
4. Modify ./thrid_party/mozjs-60. Get source code by shell script "get-sources.sh", generate source code by command "./gen-config.sh mips64el linux" and "./extract.sh". Modify source code for mips arch support.
5. Modify ./thrid_party/wiredtiger. Add mips arch configuration in "SConstruct" and "SConscript". Modify crc32 function. Add mips arch path to filelist.

https://jira.mongodb.org/browse/SERVER-50459thread debug capabilities enabled and
native thread identifier fix.Hello! I've noticed the README file for the project isn't in markdown or having the extension ".md". This makes the README bland and harder to read. If the README is bland and hard to read, this may discourage newcomers or potential contributors. I've redesigned the README to keep the content virtually the same, but look much nicer and more professional.

Note: I have signed the MongoDB Contributor Agreement.‚Ä¶Developer Community ForumsThis fixes compilation with alpinelinux
see https://github.com/mongodb/libmongocrypt/pull/89

Signed-off-by: Vincent Prince <vincent.prince.fr@gmail.com>https://jira.mongodb.org/browse/SERVER-26752

I doubt I followed the code standards exactly, but I think this will work.### Problem:
mongo causes os shell crash if we type ctrl + c when entering password in stdin.

In linux platform:

When we login to mongo server in shell with `-p` args but don't pass the password in the argument list, then mongo shell will prompt us `Enter password:` to enter the password from stdin. At that time, if we send `ctrl +c`(SIGINT) to stdin, the mongo shell will be closed, but at the same time, user's os shell will be crashed, and we can't input anything in the shell. We must close the whole shell session and login again to do other maintaining job.

In windows platform, there is no such problem.

I think we should ignore `ctrl c` when we type password in stdin, just like other database client shell, such as mysql.

### Step to reproduce:
login a new linux shell, and use mongo shell:
```
root@DESKTOP-UVUP1SF:/opt/mongo# build/opt/mongo/mongo localhost:14821/admin -u node -p
```

Press enter key, then it will prompt us to enter password without echo in the screen:
```
root@DESKTOP-UVUP1SF:/opt/mongo# build/opt/mongo/mongo localhost:14821/admin -u node -p
Enter password:
```

At that time, we input some password, but don't press enter key. Instead of it, we type `ctrl c`:
```
root@DESKTOP-UVUP1SF:/opt/mongo# build/opt/mongo/mongo localhost:14821/admin -u node -p
Enter password: 2020-02-06T12:14:21.173+0800 I CONTROL [main] shutting down with code:0
root@DESKTOP-UVUP1SF:/opt/mongo#
```

Because of SIGINT, the mongo shell closed normally, and returned to user's os main shell.

But in user's os main shell, we can't input anything more.
```
root@DESKTOP-UVUP1SF:/opt/mongo# build/opt/mongo/mongo localhost:14821/admin -u node -p
Enter password: 2020-02-06T12:14:21.173+0800 I CONTROL [main] shutting down with code:0
root@DESKTOP-UVUP1SF:/opt/mongo# root@DESKTOP-UVUP1SF:/opt/mongo# root@DESKTOP-UVUP1SF:
```

User's os main shell is crash now.

Signed-off-by: lifubang <lifubang@acmcoder.com>I have added a new stage called `ShardNameStage` to add shard name to a `$meta` projection. It made sense to meld the functionality of the existing stages `ShardFilterStage` and `TextOrStage` into `ShardNameStage` and to modify it to output the current shard name. This might be an incorrect route for implementation, please provide guidance.

To start sharded instances:
```bash
mlaunch --replicaset --sharded tic tac toe --port 27027 --binarypath ~/src/mongo/
mlaunch start
mlaunch kill
```

```js
use example;
sh.enableSharding("example");

db.items.ensureIndex({ a: "hashed" });
sh.shardCollection("example.items", { a: "hashed" });

for (var i = 0; i < 100; i++) db.items.insert({ a: i });

db.items.find({}, { shard: { $meta: "shardName" } }).sort({ a: 1 });

{ "_id" : 1, "a" : 1, "foo" : 1, "shard" : "toe" }
{ "_id" : 5, "a" : 5, "foo" : 5, "shard" : "toe" }
{ "_id" : 2, "a" : 2, "foo" : 2, "shard" : "tic" }
{ "_id" : 3, "a" : 3, "foo" : 3, "shard" : "tic" }
{ "_id" : 4, "a" : 4, "foo" : 4, "shard" : "tic" }
```

I have tested it locally with [mlaunch](http://blog.rueckstiess.com/mtools/mlaunch.html). There are no unit tests in this PR as of now, as I might be completely lost while implementing it. If functionality is as expected and modifications fit or be made to fit the expected architecture, I can add some unit tests.add mips64el support, test on loongson 3A3000JIRAÔºö https://jira.mongodb.org/browse/SERVER-43618Example error message added with this PR:
```js
> db.runCommand({explain: {find: "c"}, unknownArg: "unknown"})
{
	"ok" : 0,
	"errmsg" : "explain command requires a single argument with an optional verbosity",
	"code" : 72,
	"codeName" : "InvalidOptions"
}
```Dear MongoDB team,
We are using MongoDB for data collections from Gateways, Routers and CPEs. Most of our requirements for memory-efficient and reliable accumulations are satisfied by using MongoDB Aggregation API. At the moment, we calculate the percentile of the data outside of the MongoDB platform. Having big data set and reading this data out of mongodb just for percentile is not optimal.

To optimise some of our use cases in calculating the ‚Äúpercentile‚Äù, we tried to implement a built-in accumulator for MongoDB using well-known t-digest algorithm (https://github.com/tdunning/t-digest) which is introducing an on-line approach with constant memory bound and constant accuracy. The possibility of merging independent digests enables the ‚ÄúSharded‚Äù setups to get benefit of distributed accumulations.

This is also motivated by current open issues in MongoDB:
https://jira.mongodb.org/browse/SERVER-4929
https://jira.mongodb.org/browse/SERVER-7463

In current proposal, we used Folly implementation of t-digest (https://github.com/facebook/folly/blob/master/folly/stats/TDigest.h) which we merged with current Group Aggregation Accumulators as a new ‚Äú$percentile‚Äù accumulator.

In this implementation, unlike the other accumulators, we pass the necessary parameters (percentile value and digest size) to percentile accumulator. For e.g.: 

`db.mycollection.aggregate({
  "$group": {
    _id: "$metadata",
    "my_percentile_result": {
      "$percentile": {
        "percentile": 0.95,
        "value": "$jitter",
        "digest_size": 1000
      }
    }
  }
})`

We had the challenge in passing the percentile parameters to accumulator processor. We tried to solve this by passing the necessary parameters together with the documents to the accumulator processor.
The proposal includes new unittests for the percentile accumulator and will be followed by appropriate documentations after your initial reviews.

We are looking forward to your feedback on the proposed feature.We added these expressions:
 - '$cossim', '$chi2', '$euclidean', '$squared_euclidean', '$manhattan'

Which allow us to compare long vectors (image features) stored as arrays or BSON.
It is useful to find the most similar images in a dataset. The usage is the following:

```python
db.test_speed.aggregate([
    {   
        '$project':
        {
            'id': '$id',
            "other_id": '$other_id',
            'distance': {'$cossim': [vector, '$vector']},
        },
    },
    {"$sort": {"distance": -1}},
    {"$limit": 20}
])
```

In addition implementations using avx2 and avx512 are included in this pull request.Change prototype of DERToken::parse function from
parse(ConstDataRange cdr, size_t* outLength);
to parse(ConstDataRange cdr, uint64_t* outLength);

Otherwise, we got the following error:

src/mongo/util/net/ssl_manager.cpp: In static member function 'static mongo::StatusWith<mongo::{anonymous}::DERToken> mongo::{anonymous}::DERToken::parse(mongo::ConstDataRange, size_t*)':
src/mongo/util/net/ssl_manager.cpp:575:79: error: invalid conversion from 'size_t* {aka unsigned int*}' to 'long unsigned int*' [-fpermissive]
  if (mongoUnsignedAddOverflow64(tagAndLengthByteCount, derLength, outLength) ||

Signed-off-by: Fabrice Fontaine <fontaine.fabrice@gmail.com>This new setting adds support for building from either gcc or clang, since the two compilers support portable command naming (`cc` and `c++`).

This way not only GCC users can compile mongodb code, but also LLVM users.See details in [SERVER-31687](https://jira.mongodb.org/browse/SERVER-31687)

`$lte` condition may cause the oplog full scan, so we should just use `$gte`, and compare in the client side.Solve the problem that mongod can not be connected by socket connection when ssl is opened.Add a condition for judging whether it is a BulkWriteError or not in curd_api.js, or it will occur "TpyeError: err.hasWriteErrors is not a function"commit 3607059 introduced a default fork option, but it has not
been enforced in the command line. Since fork is enforced in the
systemd unit and ignores the configuration file, if the config
file has fork disabled (default value) then the unit will not
start properly. This is problematic for situations where a config
file is being managed by an external system like ansibleSet UMask=0027 in debian/mongod.service so that database files are created with no permissions for "other" users.In ``docs/building.md`` , It require GCC version 5.4.0 or newer, but ``SConstruct`` require 5.3.0 or newer.
Is it mistake? Without these using `std::string`, mongodb does not build here.

I'm using gcc 6.4.0.

Please ask if you need more information about my build :)The trailing slash argument is missing in mongorestore command example in debian mans.Add range search feature on full text search (original version has only exact match)

For CJK language, mongodb does not support stemmer for full text search.
Also not easy to implement stemmer for those language (Especially Korean).
So we usually use N-gram parser for full text search not supported mongodb yet.

Fortunately in Korean, we use space character between words and Korean(and also Japanese) use only suffix not prefix. So we can use mongodb full text search if mongodb support prefix match in fulltext. So I propose this simple feature.

>> Match range of original fulltext search
    * 'ÌïúÍ∏Ä' <= match_range <= 'ÌïúÍ∏Ä'
    * 'ÌÖåÏä§Ìä∏' <= match_range <= 'ÌÖåÏä§Ìä∏'
    * 'Ïù¥ÏÑ±' <= match_range <= 'Ïù¥ÏÑ±'
    * 'Ìïú' <= match_range <= 'Ìïú'

>> Match range of patched fulltext search
    * 'ÌïúÍ∏Ä' <= match_range < 'ÌïúÍ∏Å'
    * 'ÌÖåÏä§Ìä∏' <= match_range < 'ÌÖåÏä§Ìäπ'
    * 'Ïù¥ÏÑ±' <= match_range < 'Ïù¥ÏÑ≤'
    * 'Ìïú' <= match_range < 'Ìïù'

I hope user can control this search mode (exact or prefix match) by query parameter or internal parameter.

now the Explain command will not accept unknown command like verbos: 'queryPlanner'Elimination of some redundancy. Some function arguments are passed by reference. Few bugs are fixed.When uncommented this `// print a non-UTC time` block and changed `var UTC = '';` got invalid timezone offsets like: `ISODate("2016-11-14T00:00:00+-100")`. This makes Date be displayed as `ISODate("2016-11-14T00:00:00+0100")`Same as #1060 but for 3.x version.
- [x] alpine-release on processinfo
- [x] Fix `'ELFCLASS__ELF_NATIVE_CLASS' was not declared in this scope`
- [x] Fix `gnu_get_libc_version` usage that does not exist on Musl
- [x] Fix undefined `mallinfo` function
- [x] error_code.ipp:110:22: error: could not convert 'strerror_r(value, ((char*)(& buf)), sizeof (buf))' from 'int' to 'std::__cxx11::string {aka std::__cxx11::basic_string<char>}
  - https://github.com/chriskohlhoff/asio/pull/95
- [ ] `third_party/gperftools-2.2`: `error: '__off64_t' has not been declared`
  - https://github.com/gperftools/gperftools/issues/693
I'm trying to perform a no-js engine build, and no mongo command. I've hit two issues:

serveronly target was underlinked, failing to find a reference to local_sharding_info.

core target referenced mongo executable, when it was not going to be built.

Below fixes both of the above issues on the v3.4 branch.Fully functional windows performance counters imlpemented as a mongod.exe Module.

See README. See jira SERVER-2541 for some additional notes.
- No Visual Studio project file have been updated. (I can't do that with VS Express).
- I didn't make use of this new "buildscripts/moduleconfig.py" infrastructure mostly because of my incompetence: new to scons, new to python, didn't like both. 8-)
- There is a new artifact that needs to be distributed along with mongod.exe: mongod.man. I didn't look into that (packaging).

Thanks
Arm64Return niljOswcd0QKbPSYOcoRHfkMwwnci+ar2KUGplRFR8kCjElatest verwsion of Ubuntu<!--- Provide a general summary of your changes in the Title above -->

## Description

<!--- Describe your changes in detail -->

This PR is providing multiple TradingView indicators. 

### Warnings: Please do a backup before upgrading. It may break due to migrations. If it breaks, please let me know. 


**Changes:**

- A migration has been added to migrate from the single TradingView to the multiple TradingView. [migrations/1664194720480-add-multiple-tradingviews.js](https://github.com/chrisleekr/binance-trading-bot/pull/539/files#diff-35266655a7ab4c0344314452fe7139e2b401c7110d8179bfc1aa6635ee3362baR1)
- Now the bot is getting multiple TradingView indicators 
  - [app/cronjob/trailingTrade/step/get-indicators.js](https://github.com/chrisleekr/binance-trading-bot/pull/539/files#diff-7ccbb93b9754d4b42354368b890277e25593218ff5a764898da3b4aeb2b9bcedR173)
  - [app/cronjob/trailingTradeIndicator/step/get-tradingview.js](https://github.com/chrisleekr/binance-trading-bot/pull/539/files#diff-0e1a8db8c37a3d9d7ab3a585dd68cf9a666168c917fd6ada597a0aefb5c8a644R193)
- When determining actions - [app/cronjob/trailingTrade/step/determine-action.js](https://github.com/chrisleekr/binance-trading-bot/pull/539/files#diff-7b3b81ac3f35b686b8003e303150b48195c16993dd3a8373ae2d587e978b8be7R397), it will check whether the bot should force to sell because the TraidingView indicators Neutral/Sell/Strong Sell. It will check all eligible interval indicators. 
- Removed override interval and TradingView recommendations when it's override action.
- When placing the buy order - [app/cronjob/trailingTrade/step/place-buy-order.js](https://github.com/chrisleekr/binance-trading-bot/pull/539/files#diff-4519c980590f37959bc31959f6d67b38d5eb50a895e5c5d693031046c451a8ccR96), it will check whether the bot can place the buy order based on the TradingView indicators Buy/Strong Buy. It will check all eligible interval indicators.
- Pass `{symbol:'global'}` to `slack.sendMessage` to make sure not flooding with duplicate messages.
- UI has been updated.


**Caveats:**
- I am limiting the number of TradingView intervals to 3 intervals. The bot will request the TradingView API endpoint extensively (it's POST - https://github.com/brian-the-dev/python-tradingview-ta/blob/main/tradingview_ta/main.py#L107). For example, if I set 3 intervals, then it will request 3 intervals * 60 seconds = 180 requests per min. I think it's already too many requests and likely blocked by TradingView. Although, they may not have any rate limit (or they do?).

## Related Issue

<!--- This project only accepts pull requests related to open issues -->
<!--- If suggesting a new feature or change, please discuss it in an issue first -->
<!--- If fixing a bug, there should be an issue describing it with steps to reproduce -->
<!--- Please link to the issue here: -->

#438

## Motivation and Context

<!--- Why is this change required? What problem does it solve? -->
<!--- If it fixes an open issue, please link to the issue here. -->

The TradingView is providing the indicator per interval. 
At the moment, the bot only monitors a single TradingView interval, which is ok. 
But the trend can be changed very quickly before new technical analysis results. 


## How Has This Been Tested?

<!--- Please describe in detail how you tested your changes. -->
<!--- Include details of your testing environment, and the tests you ran to -->
<!--- see how your change affects other areas of the code, etc. -->

It's been running on my server.
However, this requires intensive test before releasing.


## Screenshots (if appropriate):

![image](https://user-images.githubusercontent.com/5715919/202825862-164b2c91-f520-4ed1-bc2b-d65e052e5840.png)
![image](https://user-images.githubusercontent.com/5715919/202825888-00d8432b-87b0-4db9-9d1f-7e481cdce5be.png)
![image](https://user-images.githubusercontent.com/5715919/202826011-ba4a5d42-3ae4-416a-9a31-1e44ee6445b5.png)




Let it only print errors by default so that the `pre-commit` output  doesn't get spammed on success.Source hash: 397d703570648f3797261048f221d1b387dce94b
Remaining commits: 6
Code cleanup.Code cleanup.There's no reason to raise here, all the caller is looking for is an instance of the CATWallet that they're looking for and to create it if it doesn't exist.

https://github.com/Chia-Network/chia-blockchain/issues/14002
Code Maintenance. No user visible changes.Code Maintenance. No user visible changes.Code Maintenance. No user visible changes.Code Maintenance. No user visible changes.No user-visible changes. Code maintenance.Code maintenance. No user visible changes.Based on:
- #14069 ## What is the purpose of the changes in this PR?
There was an issue where actual conflict status and label did not match.
https://github.com/Chia-Network/chia-blockchain/pull/14052
https://github.com/Chia-Network/chia-blockchain/actions/runs/3631834598/jobs/6126986602#step:2:182
The mismatch seems to be happened because the `label-conflict` action did not run after the conflict resolved.

## What is the current behavior?
`label-conflict` action does not run when PR from forked branch is opened/reopened.

## What is the new behavior (if this is a feature change)?
`label-conflict` action does run when PR from forked branch is opened/reopened.

## Does this PR introduce a breaking change?
No

## Testing notes (is this code covered by tests, or equivalent manual testing?)
In the workflow jobs in this PR, there is not a `label-conflict` action on `pull_request_target` context.
(Only `label-conflict` action of `push` to `main` ran but it seems the action of push context does not run for forked PR)

<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
<!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->
make sure we dont send new capabilities for clients under 1.7
no breaking changes, fixes the issue where old clients would disconnect new one but only for the older clients outbound connections 

example:
a 1.5 peer initiates a connection to a 1.7 peer, the 1.7 knows what 1.5 supports and only sends those to avoid the disconnect

this cant be done the other way because of who sends the first handshake message with the version and supported capabilties 

<!-- What is the current behavior?** (You can also link to an open issue here) -->



<!-- What is the new behavior (if this is a feature change)? -->



<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->



<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->



<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
Based on:
- #14068 <!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->

See title.


<!-- What is the current behavior?** (You can also link to an open issue here) -->



<!-- What is the new behavior (if this is a feature change)? -->



<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->



<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->



<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
No user-visible changes. Code maintenance.

<!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->



<!-- What is the current behavior?** (You can also link to an open issue here) -->



<!-- What is the new behavior (if this is a feature change)? -->



<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->



<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->



<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
<!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->
Purpose: PR to source input for changes to the PR template


<!-- What is the current behavior?** (You can also link to an open issue here) -->
Current Behavior: The PR template is pretty basic, and there have been some requests to modify some aspects of it.


<!-- What is the new behavior (if this is a feature change)? -->
New Behavior: TBD


<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->
Breaking Changes: None


<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->
Testing Notes: none


<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
This is a precursor to collecting API metadata on the peer API classes.

<!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->



<!-- What is the current behavior?** (You can also link to an open issue here) -->



<!-- What is the new behavior (if this is a feature change)? -->



<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->



<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->



<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
<!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->
Fix test_get_info


<!-- What is the current behavior?** (You can also link to an open issue here) -->



<!-- What is the new behavior (if this is a feature change)? -->



<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->



<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->



<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
**What is the purpose of the changes in this PR?**
To populate transactions with memos that were sent with coins. 


**What is the current behavior?**
The memos are not read from the blockchain so no memos are present in `Transaction` object.


**What is the new behavior (if this is a feature change)?**
Memos will appear when printing transactions in CLI and `Transaction` object will have memos filled. 

**Testing notes**
We should test if this has significant impact on performance and if there are cases where we could miss filling memos.


_I tested toilet wallet (on testnet) and memos make syncing about **3X SLOWER**_

<!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->

Fix issue in fee estimator: Don't re-create fee estimator on each new block when Mempool is recreated

<!-- What is the current behavior?** (You can also link to an open issue here) -->


<!-- What is the new behavior (if this is a feature change)? -->



<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->



<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->

Testing Notes: Try `chia show -f` while blocks are full

<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
This PR introduces the WalletActionManager which is a utility similar to the TradeManager but designed to be more generally applicable for any action a wallet can perform.  The general flow is as such:
1) User constructs a summary (see summary format below for what that entails)
2) User submits summary to wallet action manager which turns it into an unsigned & incomplete spend
3) User submits unsigned & incomplete spend to wallet for signing (currently this is still integrated into the wallet action manager, but this could be a separate airgapped machine for example)
4) User is returned a signed & incomplete spend
5) User submits signed & incomplete spend and an environment of variables (similar to a clvm solution) to wallet action manager which returns a signed and complete spend ready to be pushed to the network
6) User pushes spend to the network

The separation of transaction creation, signing, and completion allows for clients to construct more powerful applications without needing explicit support on the wallet backend.

### Backwards Compatibility
This PR is only designed to supply the underlying infrastructure, it does not yet expose the full functionality at the RPC level for users to use.  Instead, the trade manager calls methods from the wallet action manager in response to its normal calls like `/create_offer_for_ids`.  It leverages a library of functions to convert legacy requests/responses <-> action manager requests/responses.  Furthermore, this PR does not even use the underlying infrastructure for any supported use case, it only calls action manager methods in exactly the case where there is a DL singleton in the offer and also some other type of asset.  This means the new infrastructure only gets called to create/respond to a payment <-> dl_inclusion offer.  All other offers still use the same code paths in the trade manager.  The new summary format does not need to be used for pay-to-include offers, there is back compat code for converting requests and responses for those as well.

The idea is that in the future, we can do a slow cut-over to the new infrastructure and slowly (emphasis on slow) deprecate the trade manager and the offers it creates being careful to add unit tests for the old use cases in the new action manager.  While spends made in the new infrastructure may not be byte for byte similar to the same spend made on the old infrastructure, the intention is that new infrastructure spends will be able to be interpreted by old infrastructure clients.

Despite the following functionality not yet being available, here's a description of the intended interaction with the action manager when we do start to uncover it.

### Summary Format
```
{
  "actions" : [
    {
      "with": {*coin specification*},
      "do": [
        {*wallet action*},
        ...
      ],
    },
    ...
  ],
  "bundle_actions": [
    {*wallet action*}
  ],
  *additional keys*
}
```

The summary to build a spend is passed in as a CLVM dict similar to the `driver_dict` argument in `/create_offer_for_ids`.  Keys are strings, values are strings interpreted as CLVM.

The `"actions"` key is the main part of the summary.  Each action specifies a `"with"` key that contains a specification for the types and quantity of assets that should be selected in order to perform the spend.  For example `{"amount": "10"}` will select a plain XCH coin or coin(s) combining to at least 10 mojos.  `{"asset_id": "0xlauncher_id"}` will select the current generation of a singleton with the specified asset ID (no amount required).  Previous arguments to select_coin work as well like "min_coin_amount".  Each action also specifies a `"do"` key that is a list of arbitrary dictionaries each with a `"type"` key that specifies the action name so the action manager knows what parser to use.  An example action is `{"type": "offered_amount", "amount": "100"}` which will send 100 mojos to the offer puzzle hash allowing someone to claim it.

`"bundle_actions"` is simply a list of actions that have no `"with"` spec.  The idea is that the user does not care which coins complete the action, just that it get completed.  A `"request_payment"` action is currently the most common use case of this, or `"require_dl_inclusion"` for DL offers.

Additional keys can be specified that are additional instructions for how to construct the spend.  For example, the action manager currently will automatically add in a direct payment of the leftover amount to the local wallet as change.  However, this can be disabled with `"change": "()"`.

### Wallet Integration

This PR also introduces a few protocols that a wallet can implement in order to automatically integrate with the action manager:
* `OuterDriver` is a class whose instance can be used to spend coins with a specific outer puzzle or series of outer puzzles
* `InnerDriver` is a class whose instance can be used to spend coins with a specific inner puzzle
* `WalletAction` is a class that can parse an action from the request summary and that a `-Driver` class knows how to handle (right now there are only two of these for our standard inner puzzle: `Condition` and `Graftroot`).
* `ActionAlias` is a class that can parse an action from the request summary and then can digest that into a `WalletAction`.

### Securing Bundles with Annoucements

As good practice, spend bundles are generally made to be cohesive with announcements rather than relying on signatures alone to be inseparable.  In our standard wallet transactions, we secure with announcements by choosing an "origin coin" that creates all of the outputs and have it create an announcement that any coins supplying the amount can assert.  This assures that an attacker can never push the supply spends without the origin coin, however, it does not prevent them from pushing the origin coin without the supply spends.  This is fine for simple transactions, but from a general perspective, it does not satisfy the requirement that the bundle be cohesive where no spend can be pushed without the others.

The action manager makes the decision to be more general by having the coins form a ring of announcements (like how CATs do it).  This ensures that if one spend is omitted, the whole ring collapses and no spends are valid anymore.  This comes at the additional cost of ~32 bytes per coin spend, but also makes cancellation of multi asset spends cheaper since fewer coins have to be spent.  It also gives more flexibility to which coin can be spent to cancel the whole batch.

### New Chialisp

Reviewers may notice a few new chialisp files in the diff.  The `curry_*` files can be mostly ignored, they are utility functions and are not designed to hit the blockchain.  This leaves `add_wrapped_announcement.clsp` which is a new graftroot puzzle that does the functionality of requesting payments.  Using asset type specifications (covered in the next section) it can be solved with missing information in order to request payment of an asset type where some information must be concrete and some information is flexible.  For example, currently requesting an NFT requires that the NFT metadata be exactly the same as the time you requested it in order to fill the offer for that NFT.  It would be nicer if you could request an NFT with a specific launcher ID, but leave it to the taker to fill in what the metadata is at the time of taking.

The `add_wrapped_announcement.clsp` makes this possible by allowing some information to be curried in, but other information to be solved, and then it uses all of the information to build the puzzle hash of the asset it's expecting to hear from. Then, it adds a dynamic announcement assertion of a specific message from that puzzle hash.  This puzzle is not used in any current use cases as they all require complete knowledge of the puzzle hash at the time of making.  When a `RequestPayment` is parsed, it can see whether it has all of the information necessary to complete the puzzle hash and instead of using this graftroot puzzle with a pretty large overhead, it simplifies the puzzle to one that simply prepends the calculated announcement to the output of the inner delegated puzzle.

### Asset Type Specifications

One problem that arose while implementing this and thinking ahead to future use cases was a general way to describe the type of an asset.  Currently, we rely on asset ids and internal mappings of them to understand what asset the user intends to spend/request.  However, as described in the section above, what if we don't have all of the information?

The construct that was designed to solve for this is an "asset type spec" which consists of three pieces of information:
1) A "mod" or uncurried base puzzle with no environment
2) A "solution_template" which is a template of the environment, indicating which elements are concrete and which are flexible.  An example template for most puzzles would look like this: `(1 -1 0 . $)` which corresponds to the following chialisp `(mod (COMMITTED_ARG SOLVABLE_ARG INNER_PUZZLE . rest_of_the_solution) ...)`
3) "committed_args" which is a mirror of the solution template but with committed arguments where they should be (everything else is ignored so might as well use `()`).  Here's an example for the template above `(0xlauncher_id_or_something () () . ())`.

When it is time to turn an asset type into a puzzle hash, the above information will be used as well as another mirror of the solution template called "solution_args" which looks like a "committed_args" template but filling in all of `-1` spots instead.  Continuing with the example: `(() ("metadata" "and" "stuff") () . ())`

## To do:
### This PR

- [x] Create WalletActionManager, move all relevant trade manager functions to it
- [x] Merge main in and resolve conflicts
- [x] Divide offer_request.py into action_manager_offer_backcompat.py and the rest -> wallet_action_manager.py
- [x] Get all new protocols into their own file and make them up to date with the wallets
- [x] Delete add_conditions.clsp
- [x] Bring CATWallet fully into conformity with `ActionProtocol`
- [x] Mypy
- [ ] Add more comments

### Follow-ups
- [ ] Create `OuterDriver`s for remaining wallets (currently the standard wallet is the only inner wallet)
- [ ] Implement `TradeRecord` style tracking of spends
- [ ] Add RPCs for action manager
- [ ] Implement Minting for CATs

### Migration
- [ ] Bring other offer types over to new infrastructure (backwards compatibility unit tests!)
- [ ] Move other action-like RPCs to call action manager

### Lofty Long-Term Plans
- [ ] Allow > 1 outer wallet per coin (Recursive matching)
- [ ] Bring Singletons and NFT metadata layers out of NFT, DL, and DID wallets, make them their own wallet
- [ ] Refactor wallet state management and sync to work in similarly general ways with input from wallets
- [ ] Define a wallet protocol that once implemented automatically integrates fully with the whole infrastructure
- [ ] Create a plugin protocol<h3>Snyk has created this PR to upgrade lerna from 5.5.2 to 5.6.2.</h3>

:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.
<hr/>

- The recommended version is **4 versions** ahead of your current version.
- The recommended version was released **2 months ago**, on 2022-10-09.

The recommended version fixes:

Severity                   | Issue                | PriorityScore (*)                 | Exploit Maturity |
:-------------------------:|:-------------------------|-------------------------|:-------------------------
<img src="https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png" width="20" height="20" title="medium severity"/>  | Prototype Pollution<br/> [SNYK-JS-UGLIFYJS-3113873](https://snyk.io/vuln/SNYK-JS-UGLIFYJS-3113873) | **311/1000**  <br/> **Why?** Recently disclosed, CVSS 4.8  | No Known Exploit 

(*) Note that the real score may have changed since the PR was raised.


<details>
<summary><b>Release notes</b></summary>
<br/>
  <details>
    <summary>Package name: <b>lerna</b></summary>
    <ul>
      <li>
        <b>5.6.2</b> - <a href="https://snyk.io/redirect/github/lerna/lerna/releases/tag/v5.6.2">2022-10-09</a></br><h2><a href="https://snyk.io/redirect/github/lerna/lerna/compare/v5.6.1...v5.6.2">5.6.2</a> (2022-10-09)</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>bootstrap:</strong> reject-cycles when using workspaces (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3168" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3168/hovercard">#3168</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/8a47a6d55a871eb6ce1c0e620a3cea2b92bf76ea">8a47a6d</a>)</li>
<li><strong>core:</strong> fix "cannot read property 'version' of undefined" for pnpm + independent versioning (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3358" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3358/hovercard">#3358</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/31e4c98cc77ba1689c28c5362c6a3de0f20f7fb7">31e4c98</a>)</li>
<li><strong>core:</strong> replace <code>"red"</code> color with <code>"brightBlue"</code> on package's output prefix (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/2774" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/2774/hovercard">#2774</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/d7c1b8784841477b24ab44b248df7e1cd2958198">d7c1b87</a>)</li>
<li><strong>create:</strong> remove unused globby dep (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3360" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3360/hovercard">#3360</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/e873f0c0b35275cd2568f43a945a84fbae364c2e">e873f0c</a>)</li>
<li><strong>npm-publish:</strong> Allows disabling of strict SSL checks (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/2952" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/2952/hovercard">#2952</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/eec3207a3e26436e2311a136f5287558332fcb2a">eec3207</a>)</li>
<li><strong>run:</strong> always set env LERNA_PACKAGE_NAME environment variable (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3359" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3359/hovercard">#3359</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/012d31d1dee36bfacb392cb9f6503aab78cdd4d1">012d31d</a>)</li>
</ul>
      </li>
      <li>
        <b>5.6.1</b> - <a href="https://snyk.io/redirect/github/lerna/lerna/releases/tag/v5.6.1">2022-09-30</a></br><h2><a href="https://snyk.io/redirect/github/lerna/lerna/compare/v5.6.0...v5.6.1">5.6.1</a> (2022-09-30)</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>add-caching:</strong> ensure lerna.json is configured automatically (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/9677cda7c9e16ae3cc02cd01c7b1087d81095750">9677cda</a>)</li>
</ul>
      </li>
      <li>
        <b>5.6.0</b> - <a href="https://snyk.io/redirect/github/lerna/lerna/releases/tag/v5.6.0">2022-09-29</a></br><h1><a href="https://snyk.io/redirect/github/lerna/lerna/compare/v5.5.4...v5.6.0">5.6.0</a> (2022-09-29)</h1>
<h3>Bug Fixes</h3>
<ul>
<li><strong>run:</strong> only defer to Nx when targetDefaults are defined in nx.json (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3349" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3349/hovercard">#3349</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/51f80d901fceb285677bd55ef2a456f3fb264c13">51f80d9</a>)</li>
</ul>
<h3>Features</h3>
<ul>
<li><strong>core:</strong> add add-caching command (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3350" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3350/hovercard">#3350</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/ef09a06ffc30384194fb120307269f49e4ebc54b">ef09a06</a>)</li>
<li><strong>repair:</strong> add lerna repair command (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3314" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3314/hovercard">#3314</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/7defab3434687fc8e17f921250846aa279ac3df3">7defab3</a>)</li>
<li><strong>version:</strong> apply prettier to updated files, if applicable (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3348" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3348/hovercard">#3348</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/d63fc1fdd8b51911e793bf91469bc15babbf0343">d63fc1f</a>)</li>
</ul>
      </li>
      <li>
        <b>5.5.4</b> - <a href="https://snyk.io/redirect/github/lerna/lerna/releases/tag/v5.5.4">2022-09-28</a></br><h2><a href="https://snyk.io/redirect/github/lerna/lerna/compare/v5.5.3...v5.5.4">5.5.4</a> (2022-09-28)</h2>
<p><strong>Note:</strong> Version bump only for package lerna-monorepo</p>
      </li>
      <li>
        <b>5.5.2</b> - <a href="https://snyk.io/redirect/github/lerna/lerna/releases/tag/v5.5.2">2022-09-20</a></br><h2><a href="https://snyk.io/redirect/github/lerna/lerna/compare/v5.5.1...v5.5.2">5.5.2</a> (2022-09-20)</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>run:</strong> missing <code>fs-extra</code> dependency declaration (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3332" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3332/hovercard">#3332</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/068830e95f0552a33db3ea678092134372a40af1">068830e</a>)</li>
<li><strong>run:</strong> warn on incompatible arguments with useNx (<a href="https://snyk.io/redirect/github/lerna/lerna/issues/3326" data-hovercard-type="pull_request" data-hovercard-url="/lerna/lerna/pull/3326/hovercard">#3326</a>) (<a href="https://snyk.io/redirect/github/lerna/lerna/commit/ebf654240aa1c0c67d7f1ba5dec458c14edd5c32">ebf6542</a>)</li>
</ul>
      </li>
    </ul>
    from <a href="https://snyk.io/redirect/github/lerna/lerna/releases">lerna GitHub release notes</a>
  </details>
</details>


<details>
  <summary><b>Commit messages</b></summary>
  </br>
  <details>
    <summary>Package name: <b>lerna</b></summary>
    <ul>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/04f85a38c72dd043e7e25072c6e29d8a6411b867">04f85a3</a> chore(release): v5.6.2</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/e873f0c0b35275cd2568f43a945a84fbae364c2e">e873f0c</a> fix(create): remove unused globby dep (#3360)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/d7c1b8784841477b24ab44b248df7e1cd2958198">d7c1b87</a> fix(core): replace &#x60;&quot;red&quot;&#x60; color with &#x60;&quot;brightBlue&quot;&#x60; on package&#x27;s output prefix (#2774)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/012d31d1dee36bfacb392cb9f6503aab78cdd4d1">012d31d</a> fix(run): always set env LERNA_PACKAGE_NAME environment variable (#3359)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/411813d48f8d2a42ac0765836d5fa0daa0eb8418">411813d</a> chore: update bootstrap README.md re --use-workspace (#2708)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/eec3207a3e26436e2311a136f5287558332fcb2a">eec3207</a> fix(npm-publish): Allows disabling of strict SSL checks (#2952)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/8a47a6d55a871eb6ce1c0e620a3cea2b92bf76ea">8a47a6d</a> fix(bootstrap): reject-cycles when using workspaces (#3168)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/31e4c98cc77ba1689c28c5362c6a3de0f20f7fb7">31e4c98</a> fix(core): fix &quot;cannot read property &#x27;version&#x27; of undefined&quot; for pnpm + independent versioning (#3358)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/c455b1ce9c6de70bd876c1304cc93124b6a1bbaa">c455b1c</a> chore(release): v5.6.1</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/9677cda7c9e16ae3cc02cd01c7b1087d81095750">9677cda</a> fix(add-caching): ensure lerna.json is configured automatically</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/07271fe0347052a1505e81c6f08a4f12c4b70c7a">07271fe</a> chore(release): v5.6.0</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/ef09a06ffc30384194fb120307269f49e4ebc54b">ef09a06</a> feat(core): add add-caching command (#3350)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/d63fc1fdd8b51911e793bf91469bc15babbf0343">d63fc1f</a> feat(version): apply prettier to updated files, if applicable (#3348)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/51f80d901fceb285677bd55ef2a456f3fb264c13">51f80d9</a> fix(run): only defer to Nx when targetDefaults are defined in nx.json (#3349)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/7defab3434687fc8e17f921250846aa279ac3df3">7defab3</a> feat(repair): add lerna repair command (#3314)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/add4356eae2bea4f1a3e341d007e164c70715672">add4356</a> chore: update nx to 14.8.1 (#3347)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/cb147d18b820c0b055522dc083f4051914242984">cb147d1</a> chore: fix formatting after release</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/f65ef552cb6c8299b3c55aaded78a037fea10294">f65ef55</a> chore(release): v5.5.4</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/32251c0068a2ef924fe015b837208235a7ecbb81">32251c0</a> chore(release): v5.5.3</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/fef2ae6c13b35330b2367d89a63e539f2646f04e">fef2ae6</a> fix(run): fully defer to Nx for dep detection when nx.json exists (#3345)</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/b3df23351b8248ae651b09978fc1a6aa18228ff9">b3df233</a> chore: improve clarity of docs</li>
      <li><a href="https://snyk.io/redirect/github/lerna/lerna/commit/1c39987df8f90a2432a85bc89dabab6f92b511b5">1c39987</a> chore: fix formatting after release</li>
    </ul>

   <a href="https://snyk.io/redirect/github/lerna/lerna/compare/6a0c3fb1cb0aad0f79e6110806af9f54058f5be0...04f85a38c72dd043e7e25072c6e29d8a6411b867">Compare</a>
  </details>
</details>
<hr/>

**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*

For more information:  <img src="https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmOWY4NzllZC00ODUyLTQzNWYtYjFhZi1mNjI0ODliZDVjZmEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImY5Zjg3OWVkLTQ4NTItNDM1Zi1iMWFmLWY2MjQ4OWJkNWNmYSJ9fQ==" width="0" height="0"/>

üßê [View latest project report](https://app.snyk.io/org/chia-network/project/60086b00-3a88-48b6-acc0-ffbc19952b6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üõ† [Adjust upgrade PR settings](https://app.snyk.io/org/chia-network/project/60086b00-3a88-48b6-acc0-ffbc19952b6e/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üîï [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/chia-network/project/60086b00-3a88-48b6-acc0-ffbc19952b6e/settings/integration?pkg&#x3D;lerna&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)

<!--- (snyk:metadata:{"prId":"f9f879ed-4852-435f-b1af-f62489bd5cfa","prPublicId":"f9f879ed-4852-435f-b1af-f62489bd5cfa","dependencies":[{"name":"lerna","from":"5.5.2","to":"5.6.2"}],"packageManager":"npm","type":"auto","projectUrl":"https://app.snyk.io/org/chia-network/project/60086b00-3a88-48b6-acc0-ffbc19952b6e?utm_source=github&utm_medium=referral&page=upgrade-pr","projectPublicId":"60086b00-3a88-48b6-acc0-ffbc19952b6e","env":"prod","prType":"upgrade","vulns":["SNYK-JS-UGLIFYJS-3113873"],"issuesToFix":[{"issueId":"SNYK-JS-UGLIFYJS-3113873","severity":"medium","title":"Prototype Pollution","exploitMaturity":"no-known-exploit","priorityScore":311,"priorityScoreFactors":[{"type":"freshness","label":true,"score":71},{"type":"cvssScore","label":"4.8","score":240}]}],"upgrade":["SNYK-JS-UGLIFYJS-3113873"],"upgradeInfo":{"versionsDiff":4,"publishedDate":"2022-10-09T21:18:37.272Z"},"templateVariants":["priorityScore"],"hasFixes":true,"isMajorUpgrade":false,"isBreakingChange":false,"priorityScoreList":[311]}) --->
Start of a series of PR's working towards using

```
IPAddress = Union[IPv4Address, IPv6Address]
```

wherever we use string hosts except in some places where they are needed because it can be a domain also. One example would be in `PeerInfo` to use `address: IPAddress` instead of `host: str` which is a big example since it will require a bunch of other changes and will also be done in few steps but i think at the end if this is all done things will be much cleaner.<!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->
This PR adds the generated shell completion files which can be generated by the following commands:
`_CHIA_COMPLETE=bash_source chia`
`_CHIA_COMPLETE=zsh_source chia`
`_CHIA_COMPLETE=fish_source chia`

<!-- What is the current behavior?** (You can also link to an open issue here) -->
Currently, there is no documented mention of this being possible, as it may have been unknown (I stumbled upon this https://click.palletsprojects.com/en/8.1.x/shell-completion/#enabling-completion).


<!-- What is the new behavior (if this is a feature change)? -->
The user may source these files once their venv is activated.
For possible future tasks, we may want to do one (or many) of the following:
- For users who install from src, as a final step of `install.sh`, it may be desirable to inject a `source chia-complete.bash` into the relevant `venv/bin/activate` script, so that the completion is activated when the venv is activated
- When packaging the installers, we may want to unpack these to a standardized location (for example: `/usr/share/chia/chia-complete.bash` for bash)
- We may want to add a CLI command to generate this file, i.e.: `chia completion --bash`
- It may be best to simply document the availability of this feature, and perhaps recommend how this can get added to their dotfiles, or what not to do (going the `eval` route would lead to a sluggish experience)


<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->

<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->

<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->

https://user-images.githubusercontent.com/8990544/204255728-69109215-a314-47cb-8200-e697871bc1c6.mp4

Add `get_name` function to WalletProtocol. This is part of the preparation for adding type checking to WalletStateManager
Changed the existing `get_name` function that was in some wallets to be a sync call instead of async as it just returns a property of wallet_info
The standard wallet returns a fixed string "Standard Wallet" (which is ultimately what things like the Datalayer and Pool wallets do via wallet_info).
Call this `get_name` method in several tests and where needed (eg `generate_wallet_name`)
Disambiguate `get_name_for_wallet_id`->`get_unit_name_for_wallet_id` as this is getting the units for the wallet for use when printing txs.

Code cleanup and tech debt - no change in behavior, no user-facing implications.Bumps [bitstring](https://github.com/scott-griffiths/bitstring) from 3.1.9 to 4.0.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href="https://github.com/scott-griffiths/bitstring/releases">bitstring's releases</a>.</em></p>
<blockquote>
<h2>bitstring-4.0.1</h2>
<h2>November 2022: version 4.0.1 released</h2>
<p>This is a major release which drops support for Python 2.7 and has a new minimum
requirement of Python 3.7. Around 95% of downloads satisfy this - users of
older versions can continue to use bitstring 3.1, which will still be supported
with fixes, but no new features.</p>
<p>Other changes are minimal, with a few features added.</p>
<h2>Breaking changes:</h2>
<ul>
<li>Minimum supported Python version is now Python 3.7.</li>
<li>Removed ConstBitArray and BitString class aliases. Use Bits and BitStream instead.</li>
<li>The cut() method will now also yield the final bits of a bitstring, even if they
are shorter than the requested cut size.</li>
<li>Removed default uint interpretation. This wasn't being applied uniformly - default
is now always to return a bitstring object of the given length and not to interpret
it as a uint. Bug 220.</li>
<li>If an overwrite goes beyond the end of the bitstring it will now extend the bitstring
rather than raise an exception. Bug 148.</li>
</ul>
<h2>New features and improvements:</h2>
<ul>
<li>
<p>Type hints added throughout the code.</p>
</li>
<li>
<p>Underscores are now allowed in strings representing number literals.</p>
</li>
<li>
<p>The copy() method now works on Bits as well as BitArray objects.</p>
</li>
<li>
<p>The experimental command-line feature is now official. Command-line
parameters are concatenated and a bitstring created from them. If
the final parameter is either an interpretation string or ends with
a <code>.</code> followed by an interpretation string then that interpretation
of the bitstring will be used when printing it. ::</p>
<pre><code>$ python -m bitstring int:16=-400
0xfe70
$ python -m bitstring float:32=0.2 bin
00111110010011001100110011001101
</code></pre>
</li>
<li>
<p>New pp() method that pretty-prints the bitstring in various formats - useful
especially in interactive sessions. Thanks to Omer Barak for the suggestion
and discussion.</p>
<pre><code>  &gt;&gt;&gt; s.pp()
    0: 10001000 01110110 10001110 01110110 11111000 01110110 10000111 00101000
   64: 01110010 11111001 10000111 10011000 11110111 10011110 10000111 11111101
  128: 11111001 10001100 01111111 10111100 10111111 11011011 11101011 11111011
  192: 1100
</code></pre>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href="https://github.com/scott-griffiths/bitstring/blob/main/release_notes.txt">bitstring's changelog</a>.</em></p>
<blockquote>
<h2>November 2022: version 4.0.1 released</h2>
<p>This is a major release which drops support for Python 2.7 and has a new minimum
requirement of Python 3.7. Around 95% of downloads satisfy this - users of
older versions can continue to use bitstring 3.1, which will still be supported
with fixes, but no new features.</p>
<p>Other breaking changes are minimal, and there are a few cool features added.</p>
<p>Breaking changes:</p>
<ul>
<li>Minimum supported Python version is now Python 3.7.</li>
<li>Removed ConstBitArray and BitString class aliases. Use Bits and BitStream instead.</li>
<li>The cut() method will now also yield the final bits of a bitstring, even if they
are shorter than the requested cut size.</li>
<li>Removed default uint interpretation. This wasn't being applied uniformly - default
is now always to return a bitstring object of the given length and not to interpret
it as a uint. Bug 220.</li>
<li>If an overwrite goes beyond the end of the bitstring it will now extend the bitstring
rather than raise an exception. Bug 148.</li>
</ul>
<p>New features and improvements:</p>
<ul>
<li>
<p>Type hints added throughout the code.</p>
</li>
<li>
<p>Underscores are now allowed in strings representing number literals.</p>
</li>
<li>
<p>The copy() method now works on Bits as well as BitArray objects.</p>
</li>
<li>
<p>The experimental command-line feature is now official. Command-line
parameters are concatenated and a bitstring created from them. If
the final parameter is either an interpretation string or ends with
a '.' followed by an interpretation string then that interpretation
of the bitstring will be used when printing it.</p>
<p>$ python -m bitstring int:16=-400
0xfe70
$ python -m bitstring float:32=0.2 bin
00111110010011001100110011001101</p>
</li>
<li>
<p>New pp() method that pretty-prints the bitstring in various formats - useful
especially in interactive sessions. Thanks to Omer Barak for the suggestion
and discussion.</p>
<blockquote>
<blockquote>
<blockquote>
<p>s.pp()
0: 10001000 01110110 10001110 01110110 11111000 01110110 10000111 00101000
64: 01110010 11111001 10000111 10011000 11110111 10011110 10000111 11111101
128: 11111001 10001100 01111111 10111100 10111111 11011011 11101011 11111011
192: 1100
s.pp('bin, hex')
0: 10001000 01110110 10001110 01110110 11111000 01110110   88 76 8e 76 f8 76
48: 10000111 00101000 01110010 11111001 10000111 10011000   87 28 72 f9 87 98</p>
</blockquote>
</blockquote>
</blockquote>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/d3583bb2c5d2d685b9594f587a518febcda767a1"><code>d3583bb</code></a> Merge branch '4.0-update'</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/b1e71673c95cd6a480140902b771b6489f3c89e7"><code>b1e7167</code></a> Upping version to 4.0.1 after Python3.7 fix.</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/676a6c8bed6455627c10892dc435bdb89524307c"><code>676a6c8</code></a> Merge pull request <a href="https://github-redirect.dependabot.com/scott-griffiths/bitstring/issues/241">#241</a> from alexjacobson95/bugfix/fix-python-3.7-support</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/7540a5c59947dfefaa88794da53fef2d1d2061a2"><code>7540a5c</code></a> Fix to bfloat interpretation working even if length is not 16 bits.</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/14f2dd1d12eb5e8fc64edac4979f994387517e44"><code>14f2dd1</code></a> <a href="https://github-redirect.dependabot.com/scott-griffiths/bitstring/issues/240">#240</a> fixes python 3.7 support</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/ef569bc52d0e414148c89450ff1cab685a593824"><code>ef569bc</code></a> Updating to version 4.0.0.</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/b6873b6d94d9f06b5d684f9eed4317b886ad2bd4"><code>b6873b6</code></a> Documentation tidying.</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/2e54e157e658b3c5585d199236bc7080677b7a2f"><code>2e54e15</code></a> Renaming test directory to tests.</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/0a5ab50bc52353015b7cc5cd0a010ccaa83e9aec"><code>0a5ab50</code></a> Trying to do setup exclusively in a pyproject.toml file.</li>
<li><a href="https://github.com/scott-griffiths/bitstring/commit/db13748dcc711f1d575c93c81f2e95a69bd1b143"><code>db13748</code></a> bloatne missing in some docstrings.</li>
<li>Additional commits viewable in <a href="https://github.com/scott-griffiths/bitstring/compare/bitstring-3.1.9...bitstring-4.0.1">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=bitstring&package-manager=pip&previous-version=3.1.9&new-version=4.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>Bumps [colorama](https://github.com/tartley/colorama) from 0.4.5 to 0.4.6.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href="https://github.com/tartley/colorama/blob/master/CHANGELOG.rst">colorama's changelog</a>.</em></p>
<blockquote>
<p>0.4.6 Current release</p>
<ul>
<li><a href="https://github-redirect.dependabot.com/tartley/colorama/pull/139">tartley/colorama#139</a> Add alternative to 'init()',
called 'just_fix_windows_console'. This fixes many longstanding problems
with 'init', such as working incorrectly on modern Windows terminals, and
wonkiness when init gets called multiple times. The intention is that it
just makes all Windows terminals treat ANSI the same way as other terminals
do. Many thanks the njsmith for fixing our messes.</li>
<li><a href="https://github-redirect.dependabot.com/tartley/colorama/pull/352">tartley/colorama#352</a> Support Windows 10's ANSI/VT
console. This didn't exist when Colorama was created, and avoiding us
causing havok there is long overdue. Thanks to segeviner for the initial
approach, and to njsmith for getting it merged.</li>
<li><a href="https://github-redirect.dependabot.com/tartley/colorama/pull/338">tartley/colorama#338</a> Internal overhaul of package
metadata declaration, which abolishes our use of the now heavily
discouraged setuptools (and hence setup.py, setup.cfg and MANIFEST.in), in
favor of hatchling (and hence pyproject.toml), generously contributed by
ofek (author of hatchling). This includes dropping support Python3.5 and
3.6, which are EOL, and were already dropped from setuptools, so this
should not affect our users.</li>
<li><a href="https://github-redirect.dependabot.com/tartley/colorama/pull/353">tartley/colorama#353</a> Attention to detail award to
LqdBcnAtWork for a spelling fix in demo06</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href="https://github.com/tartley/colorama/commit/3de9f013df4b470069d03d250224062e8cf15c49"><code>3de9f01</code></a> bump version 0.4.6</li>
<li><a href="https://github.com/tartley/colorama/commit/a45949b3252633060261c9666b6aada4b2f2f020"><code>a45949b</code></a> Format the CHANGELOG bullet list, no content change</li>
<li><a href="https://github.com/tartley/colorama/commit/f55f72e9d3950276679da91ba6dc713cefc603db"><code>f55f72e</code></a> comment need for a fix after recent MP broke it</li>
<li><a href="https://github.com/tartley/colorama/commit/cb83041b25a6962d8124647e8741cfa0ab139994"><code>cb83041</code></a> fix test-release after recent MPs broke it</li>
<li><a href="https://github.com/tartley/colorama/commit/832f14ce9a4d00c2dfb88e8cb02e2defadb76ba9"><code>832f14c</code></a> README tweaks</li>
<li><a href="https://github.com/tartley/colorama/commit/54b89c33b2448a1a0fab67ab020a902622b9a932"><code>54b89c3</code></a> Bump version to 0.4.6rc1</li>
<li><a href="https://github.com/tartley/colorama/commit/7991d34773c72db791eb09d9ec349212d080fbc0"><code>7991d34</code></a> 'make bootstrap' uses system python3, not pinned v3.8</li>
<li><a href="https://github.com/tartley/colorama/commit/0ae5ef2f9ab89335fb5b50933b75323178cb38bc"><code>0ae5ef2</code></a> CHANGELOG updates for upcoming 0.4.6 release</li>
<li><a href="https://github.com/tartley/colorama/commit/52f4cfd7af3a779b0ba8a7ee320d99c0bfec9ce8"><code>52f4cfd</code></a> Tweak ordering of release checklist</li>
<li><a href="https://github.com/tartley/colorama/commit/ab64cfac23fd70b9bf2944acd985e3673a1f09e1"><code>ab64cfa</code></a> Merge pull request <a href="https://github-redirect.dependabot.com/tartley/colorama/issues/353">#353</a> from LqdBcnAtWork/patch-1</li>
<li>Additional commits viewable in <a href="https://github.com/tartley/colorama/compare/0.4.5...0.4.6">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=colorama&package-manager=pip&previous-version=0.4.5&new-version=0.4.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>Draft for:
- [ ] do not merge, just testing for https://github.com/Chia-Network/chia-blockchain/pull/13923
<!-- Merging Requirements:
- Please give your PR a title that is release-note friendly
- In order to be merged, you must add the most appropriate category Label (Added, Changed, Fixed) to your PR
- Use the prompts below to provide information wherever applicable
-->
<!-- What is the purpose of the changes in this PR? -->



<!-- What is the current behavior?** (You can also link to an open issue here) -->



<!-- What is the new behavior (if this is a feature change)? -->



<!-- Does this PR introduce a breaking change?** (What changes might users need to make in their application due to this PR?) -->



<!-- Testing notes (is this code covered by tests, or equivalent manual testing?) -->



<!-- Are there any visual examples to help explain this PR? (attach any .gif/movie/console output below) -->
Draft for:
- [x] https://github.com/Chia-Network/actions/pull/47 being merged
- [x] updating to `@main`
- [ ] move to a dedicated job
- [ ] the action needs to handle ssh signing https://github.com/Chia-Network/actions/actions/runs/3599290314/jobs/6062780993#step:3:45Bumps [keyring](https://github.com/jaraco/keyring) from 23.9.3 to 23.11.0.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href="https://github.com/jaraco/keyring/blob/main/CHANGES.rst">keyring's changelog</a>.</em></p>
<blockquote>
<h2>v23.11.0</h2>
<ul>
<li><a href="https://github-redirect.dependabot.com/jaraco/keyring/issues/603">#603</a>: In <code>libsecret</code>, check that the service is available before
declaring viability.</li>
</ul>
<h2>v23.10.0</h2>
<ul>
<li><a href="https://github-redirect.dependabot.com/jaraco/keyring/issues/526">#526</a>: Bump requirement on <code>importlib_metadata</code> to pull in fix for
improperly-normalized names on egg-info.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href="https://github.com/jaraco/keyring/commit/f3b14d09732d8582cbf758553d64aafa83682a85"><code>f3b14d0</code></a> Merge pull request <a href="https://github-redirect.dependabot.com/jaraco/keyring/issues/603">#603</a> from lazka/libsecret-check-session</li>
<li><a href="https://github.com/jaraco/keyring/commit/c3eb39b17dc6e83cd396f17823129747a0e89be4"><code>c3eb39b</code></a> Update changelog</li>
<li><a href="https://github.com/jaraco/keyring/commit/9672a5db24766eebedbcf47e2ebfff24f52ea084"><code>9672a5d</code></a> libsecret: skip if there is no secret service running</li>
<li><a href="https://github.com/jaraco/keyring/commit/8b18015dfba9232568358fc049ccca558c76c47e"><code>8b18015</code></a> Disable flake8 due to incompatibility.</li>
<li><a href="https://github.com/jaraco/keyring/commit/19374c65876c14ea69dcc4a29fb9858fcbc3c749"><code>19374c6</code></a> Bump requirement on importlib_metadata to 4.11.4. Fixes <a href="https://github-redirect.dependabot.com/jaraco/keyring/issues/526">#526</a>.</li>
<li><a href="https://github.com/jaraco/keyring/commit/590d80489d36532ec75b1d2f44016997bbf16d55"><code>590d804</code></a> Merge <a href="https://github.com/jaraco/skeleton">https://github.com/jaraco/skeleton</a></li>
<li><a href="https://github.com/jaraco/keyring/commit/b2412262dc1dd5d3d697e551d86acee4d5519bb6"><code>b241226</code></a> Indicate to use latest Python version (workaround for readthedocs/readthedocs...</li>
<li><a href="https://github.com/jaraco/keyring/commit/b4b3b5cc92b2fd5f675b8e6e1c91f2118dca3947"><code>b4b3b5c</code></a> Merge <a href="https://github.com/jaraco/skeleton">https://github.com/jaraco/skeleton</a></li>
<li><a href="https://github.com/jaraco/keyring/commit/679eebb215c80c7376a1df02c77fd368347620b0"><code>679eebb</code></a> Adopt furo theme for docs.</li>
<li><a href="https://github.com/jaraco/keyring/commit/3372559194b20c8328762b20fe822adfec65bfdc"><code>3372559</code></a> Merge <a href="https://github.com/jaraco/skeleton">https://github.com/jaraco/skeleton</a></li>
<li>Additional commits viewable in <a href="https://github.com/jaraco/keyring/compare/v23.9.3...v23.11.0">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=keyring&package-manager=pip&previous-version=23.9.3&new-version=23.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>Bumps [setproctitle](https://github.com/dvarrazzo/py-setproctitle) from 1.2.3 to 1.3.2.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href="https://github.com/dvarrazzo/py-setproctitle/releases">setproctitle's releases</a>.</em></p>
<blockquote>
<h2>setproctitle 1.3.1</h2>
<ul>
<li>Fixed segfault on macOS 12.5 in forked processes (issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/111">#111</a>).
Note that, as a workaround, Activity Monitor will show the title of the parent.</li>
</ul>
<h2>setproctitle 1.3.0</h2>
<ul>
<li>Added fallback no-op implementation if building the extension fails.</li>
<li>Added support for displaying title as the process name in MacOS Activity
Monitor (issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/10">#10</a>).</li>
<li>Fixed &quot;Symbol not found: _Py_GetArgcArgv&quot; error when using Xcode provided
Python (issues <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/82">#82</a>, <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/103">#103</a>).</li>
<li>Fixed FreeBSD support, broken in 1.2 (issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/94">#94</a>).</li>
<li>Added package type annotations (issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/101">#101</a>).</li>
<li>Dropped support for Python 3.6.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href="https://github.com/dvarrazzo/py-setproctitle/blob/master/HISTORY.rst">setproctitle's changelog</a>.</em></p>
<blockquote>
<h2>Version 1.3.2</h2>
<ul>
<li>Restore import-time initialization of macOS to avoid crash on thread+fork
(issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/113">#113</a>).</li>
</ul>
<h2>Version 1.3.1</h2>
<ul>
<li>Fixed segfault on macOS 12.5 in forked processes (issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/111">#111</a>).
Note that, as a workaround, Activity Monitor will show the title of the
parent.</li>
</ul>
<h2>Version 1.3.0</h2>
<ul>
<li>Added fallback no-op implementation if building the extension fails.</li>
<li>Added support for displaying title as the process name in MacOS Activity
Monitor (issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/10">#10</a>).</li>
<li>Fixed &quot;Symbol not found: _Py_GetArgcArgv&quot; error when using Xcode provided
Python (issues <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/82">#82</a>, <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/103">#103</a>).</li>
<li>Fixed FreeBSD support, broken in 1.2 (issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/94">#94</a>).</li>
<li>Added package type annotations (issue <a href="https://github-redirect.dependabot.com/dvarrazzo/py-setproctitle/issues/101">#101</a>).</li>
<li>Dropped support for Python 3.6.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li>See full diff in <a href="https://github.com/dvarrazzo/py-setproctitle/commits">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=setproctitle&package-manager=pip&previous-version=1.2.3&new-version=1.3.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>This might not be worthwhile, but sometimes it seems having a config setting for this is useful for some troubleshooting.
Also change the default for the Daemon to be 300 seconds.
Rationale: The daemon connections are typically almost always localhost connections. The heartbeat is only useful for detecting connections that were closed. I'll note that there is already a manual ping task running in the daemon server that will also detect closed connections since the send will fail. Therefore, the heartbeat is mostly useful for clients to detect that the daemon connection has closed when there is minimal traffic and I don't believe that there is any practical scenario where this causes substantial user issues.
Note that other WS connections (farmer<->harvester for example) continue to use a 60 seconds heartbeat setting. (although similar arguments can be made this isn't that useful, since these connections tend to be quite chatty anyway)https://github.com/Chia-Network/chia-blockchain/pull/13882

Draft for:
- [ ] Do not merge
[Towncrier](https://towncrier.readthedocs.io/en/stable/) builds changelogs from change fragment (newsfragment) files in the `changes/` directory.  A basic PR deserving of a changelog entry should create a file such as `changes/13882.added` with content in markdown format of the existing changelog.  Using separate files avoids the constant merge conflicts that would be present if everyone directly added items to the ends of the sections in the final changelog file.  One of the PR checks verifies that such a file is being introduced or modified by the PR.  When ready to make a release, Towncrier is run to consume these fragments and add them to the `CHANGELOG.md` file.  At this time the consumed fragments are deleted and the updated `CHANGELOG.md` is committed.  The intent presently is to retain the existing sections and format of the changelog.  Additionally, in each PR the changelog is built and provided as both a most-recent-version summary on the workflow summary page as well as being available as a downloadable artifact with the full generated `CHANGELOG.md`.  See https://github.com/Chia-Network/chia-blockchain/actions/runs/3431382476 for example.

More fragments are visible in the test PR https://github.com/Chia-Network/chia-blockchain/pull/13884 such as at https://github.com/Chia-Network/chia-blockchain/actions/runs/3431499033#summary-9397068321.

There are various benefits to this approach.

- No vendor lock-in.  We are not storing our data exclusively in GitHub, not using the GitHub tooling to process that data, and our changelog management isn't forced to be tied to the actual PR objects.
- Any user at any time can render the changelog, including locally, to see what it looks like in final form.  This means the rendered changelog can be reviewed as part of reviewing the associated PR.
- All changes are tracked in git as granularly as we make them.  Since we require reviews this means that all changes get reviewed.
- Changelog entries can be created without a one to one relationship to a PR.  Some PRs need no changelog entry because they are any of a number of forms of internal changes.  Some PRs need multiple entries because they are deprecating or removing one thing and adding a replacement for it.  There are certainly other situations as well.
- Thank yous, links to issues, documentation, PRs, etc can be readily added without them awkwardly sitting in the PR title.
- The changelog fragment is shown in the PR diff view along all the other source changes that should be reviewed for the PR.
- Other groups, such as product or comms, can view and suggest changes to the fragments whenever they choose.  This can be done by viewing the latest rendered changelog via `main` builds or their own PR and providing edits to the relevant files.  These changes will go through the normal review process instead of just anyone changing any PR title and tags whenever.

Draft for:
- [ ] Being more than an exploration
- [ ] Test multiline, code block, links, etc fragments
- [ ] Add blankline between sections https://github.com/Chia-Network/chia-blockchain/actions/runs/3431499033/jobs/5719701176/summary_raw
- [ ] Discuss how to handling having references to PRs and issues for context.  The relevant automatic feature for this is presently being disregarded since our final format in the past has excluded these links.  But, they are used during processing of the changelog and thus we need to put some consideration into this.This adds connection compression between full nodes in order to save bandwidth.
During the handshake they announce their capability to decompress messages if received.
The sending side checks if the receiver is able to decompress and the size of the message is large enough for it to be beneficial, and if so compresses the message using zstandard.
Both compression and decompression is settable in the config.Let's consider DataStores that are changed often and the keys overwritten often. An application that connects via RPC with Chia (a project of mine) must download these DataStores, but starting from item 1 the time taken to download all versions is very long. Furthermore, in "ecological" terms, unloading more than necessary has an impact.
This development allows you to download the latest version at the first request. This way you can build a dedicated server for this. I developed in server terms with a backward compatible explicit key so that it is explicit that the files located "\data_layer\db\server_files_location_mainnet" are not useful for mirroring. Its best use and with a docker to have a fast DataStore reader.
in other words, "WE TREAT THE LAST FULL FILE AS A SNAPSHOT"Avoid housekeeping of the other members, should not be relevant for the 
perfomance?https://github.com/rhysd/actionlintBased on testing of GitHub Actions runners in https://github.com/Chia-Network/chia-blockchain/pull/13724 it seems that we need a system dependent timeout delay to account for the runners seemingly randomly hanging for seconds at a time.  This applies that to at least our time out assertions.  Many of these assertions could be reduced now but that may be left for another time.

Draft for:
- [x] just testing for now
- [x] can this nicely be less import time or at least less global code?  maybe?
- [x] Get https://github.com/Chia-Network/chia-blockchain/pull/13727/files#r1018542266 once merged.Draft for:
- [x] https://github.com/Chia-Network/bls-signatures/pull/346
- [x] https://github.com/Chia-Network/chiavdf/pull/134
- [x] https://github.com/Chia-Network/chiabip158/pull/19
- [x] https://github.com/Chia-Network/chiapos/pull/339
- [x] https://github.com/Chia-Network/chia_rs/pull/72<h3>Snyk has created this PR to upgrade electron-builder from 23.5.1 to 23.6.0.</h3>

![merge advice](https://app.snyk.io/badges/merge-advice/?package_manager=npm&package_name=electron-builder&from_version=23.5.1&to_version=23.6.0&pr_id=2bffd18e-35dc-4450-b678-9f3672430ab9&visibility=true&has_feature_flag=false)
:information_source: Keep your dependencies up-to-date. This makes it easier to fix existing vulnerabilities and to more quickly identify and fix newly disclosed vulnerabilities when they affect your project.
<hr/>

- The recommended version is **1 version** ahead of your current version.
- The recommended version was released **a month ago**, on 2022-10-03.


<details>
<summary><b>Release notes</b></summary>
<br/>
  <details>
    <summary>Package name: <b>electron-builder</b></summary>
    <ul>
      <li>
        <b>23.6.0</b> - <a href="https://snyk.io/redirect/github/electron-userland/electron-builder/releases/tag/v23.6.0">2022-10-03</a></br><h2>What's Changed</h2>
<ul>
<li>feat: add nsis option to remove the default uninstall welcome page by <a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/moulinierf/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/moulinierf">@ moulinierf</a> in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1375546442" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7141" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7141/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7141">#7141</a></li>
<li>feat: add Github Actions environment variable to isPullRequest method by <a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/kuidaoring/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/kuidaoring">@ kuidaoring</a> in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1382739074" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7152" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7152/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7152">#7152</a></li>
<li>fix: formatting of Code in the MacOS PKG docs by <a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/hrueger/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/hrueger">@ hrueger</a> in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1375569677" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7142" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7142/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7142">#7142</a></li>
<li>chore: Updating node 16 docker images by <a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/Tarrowren/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/Tarrowren">@ Tarrowren</a> in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1385367393" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7158" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7158/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7158">#7158</a></li>
<li>fix(ci): workflows security hardening by <a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/sashashura/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/sashashura">@ sashashura</a> in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1385092096" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7156" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7156/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7156">#7156</a></li>
<li>feat: non-silent mode allow not to run the app when the installation is complete by <a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/shenglianlee/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/shenglianlee">@ shenglianlee</a> in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1372719388" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7136" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7136/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7136">#7136</a></li>
<li>feat: update note for pnpm by <a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/romadryud/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/romadryud">@ romadryud</a> in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1388993021" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7163" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7163/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7163">#7163</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/moulinierf/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/moulinierf">@ moulinierf</a> made their first contribution in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1375546442" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7141" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7141/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7141">#7141</a></li>
<li><a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/kuidaoring/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/kuidaoring">@ kuidaoring</a> made their first contribution in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1382739074" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7152" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7152/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7152">#7152</a></li>
<li><a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/hrueger/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/hrueger">@ hrueger</a> made their first contribution in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1375569677" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7142" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7142/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7142">#7142</a></li>
<li><a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/Tarrowren/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/Tarrowren">@ Tarrowren</a> made their first contribution in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1385367393" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7158" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7158/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7158">#7158</a></li>
<li><a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/sashashura/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/sashashura">@ sashashura</a> made their first contribution in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1385092096" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7156" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7156/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7156">#7156</a></li>
<li><a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/shenglianlee/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/shenglianlee">@ shenglianlee</a> made their first contribution in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1372719388" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7136" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7136/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7136">#7136</a></li>
<li><a class="user-mention notranslate" data-hovercard-type="user" data-hovercard-url="/users/romadryud/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://snyk.io/redirect/github/romadryud">@ romadryud</a> made their first contribution in <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1388993021" data-permission-text="Title is private" data-url="https://github.com/electron-userland/electron-builder/issues/7163" data-hovercard-type="pull_request" data-hovercard-url="/electron-userland/electron-builder/pull/7163/hovercard" href="https://snyk.io/redirect/github/electron-userland/electron-builder/pull/7163">#7163</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a class="commit-link" href="https://snyk.io/redirect/github/electron-userland/electron-builder/compare/v23.5.1...v23.6.0"><tt>v23.5.1...v23.6.0</tt></a></p>
      </li>
      <li>
        <b>23.5.1</b> - <a href="https://snyk.io/redirect/github/electron-userland/electron-builder/releases/tag/docker%4023.5.1">2022-09-08</a></br>No content.
      </li>
    </ul>
    from <a href="https://snyk.io/redirect/github/electron-userland/electron-builder/releases">electron-builder GitHub release notes</a>
  </details>
</details>
<hr/>

**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open upgrade PRs.*

For more information:  <img src="https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyYmZmZDE4ZS0zNWRjLTQ0NTAtYjY3OC05ZjM2NzI0MzBhYjkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjJiZmZkMThlLTM1ZGMtNDQ1MC1iNjc4LTlmMzY3MjQzMGFiOSJ9fQ==" width="0" height="0"/>

üßê [View latest project report](https://app.snyk.io/org/chia-network/project/60086b00-3a88-48b6-acc0-ffbc19952b6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üõ† [Adjust upgrade PR settings](https://app.snyk.io/org/chia-network/project/60086b00-3a88-48b6-acc0-ffbc19952b6e/settings/integration?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr)

üîï [Ignore this dependency or unsubscribe from future upgrade PRs](https://app.snyk.io/org/chia-network/project/60086b00-3a88-48b6-acc0-ffbc19952b6e/settings/integration?pkg&#x3D;electron-builder&amp;utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;upgrade-pr#auto-dep-upgrades)

<!--- (snyk:metadata:{"prId":"2bffd18e-35dc-4450-b678-9f3672430ab9","prPublicId":"2bffd18e-35dc-4450-b678-9f3672430ab9","dependencies":[{"name":"electron-builder","from":"23.5.1","to":"23.6.0"}],"packageManager":"npm","type":"auto","projectUrl":"https://app.snyk.io/org/chia-network/project/60086b00-3a88-48b6-acc0-ffbc19952b6e?utm_source=github&utm_medium=referral&page=upgrade-pr","projectPublicId":"60086b00-3a88-48b6-acc0-ffbc19952b6e","env":"prod","prType":"upgrade","vulns":[],"issuesToFix":[],"upgrade":[],"upgradeInfo":{"versionsDiff":1,"publishedDate":"2022-10-03T19:38:48.407Z"},"templateVariants":["merge-advice-badge-shown"],"hasFixes":false,"isMajorUpgrade":false,"isBreakingChange":false,"priorityScoreList":[]}) --->
Draft for:
- [ ] Just an exploration
Bumps [chiabip158](https://github.com/Chia-Network/chiabip158) from 1.1 to 1.2.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href="https://github.com/Chia-Network/chiabip158/releases">chiabip158's releases</a>.</em></p>
<blockquote>
<h2>1.2</h2>
<h2>What's Changed</h2>
<ul>
<li>Fix arm64 wheels for python 3.10 by <a href="https://github.com/cmmarslender"><code>@‚Äãcmmarslender</code></a> in <a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/pull/14">Chia-Network/chiabip158#14</a></li>
<li>Fix linux arm targeting by <a href="https://github.com/cmmarslender"><code>@‚Äãcmmarslender</code></a> in <a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/pull/15">Chia-Network/chiabip158#15</a></li>
<li>rework build matrix to a single workflow by <a href="https://github.com/altendky"><code>@‚Äãaltendky</code></a> in <a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/pull/17">Chia-Network/chiabip158#17</a></li>
<li>Python 3.11 by <a href="https://github.com/altendky"><code>@‚Äãaltendky</code></a> in <a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/pull/16">Chia-Network/chiabip158#16</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href="https://github.com/altendky"><code>@‚Äãaltendky</code></a> made their first contribution in <a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/pull/17">Chia-Network/chiabip158#17</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href="https://github.com/Chia-Network/chiabip158/compare/1.1...1.2">https://github.com/Chia-Network/chiabip158/compare/1.1...1.2</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href="https://github.com/Chia-Network/chiabip158/commit/f80a76b7c2e6ce0c7fda0ca7577ae40330883be4"><code>f80a76b</code></a> Python 3.11 (<a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/issues/16">#16</a>)</li>
<li><a href="https://github.com/Chia-Network/chiabip158/commit/87eff9da28ea66744ea78c1620d8d6ce20d362b0"><code>87eff9d</code></a> rework build matrix to a single workflow (<a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/issues/17">#17</a>)</li>
<li><a href="https://github.com/Chia-Network/chiabip158/commit/eca9df73cd5107c57f1660d9808aedf232fe649c"><code>eca9df7</code></a> Fix linux arm targeting (<a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/issues/15">#15</a>)</li>
<li><a href="https://github.com/Chia-Network/chiabip158/commit/8d8178325bf19167616e704c441ef50a186abea4"><code>8d81783</code></a> Fix arm64 wheels for python 3.10 (<a href="https://github-redirect.dependabot.com/Chia-Network/chiabip158/issues/14">#14</a>)</li>
<li>See full diff in <a href="https://github.com/Chia-Network/chiabip158/compare/1.1...1.2">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=chiabip158&package-manager=pip&previous-version=1.1&new-version=1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>Testing https://github.com/Chia-Network/chia-blockchain/pull/13632
See a sample failure at https://github.com/Chia-Network/chia-blockchain/pull/13633.

Draft for:
- [x] consideration of this thing's place in the avoidance of unsigned commits
- [x] consideration of what signing statuses we want to actually reject
- [x] make this reusable, such as an actionTesting timeout adjustmentsDraft for:
- [x] See if it works
- [ ] If it does, wait for it to be releasedthe minimal fix https://github.com/Chia-Network/chia-blockchain/pull/13570

Draft for:
- [ ] self consideration
- [x] ack!
- [x] tests like https://github.com/Chia-Network/chia-blockchain/pull/13576 (and more)Example stack when snyk is analyzing.

```python-traceback
  File "/tmp/tmp-2590981-sBSqAOYgFiEr/pip_resolve.py", line 351, in <module>
    sys.exit(main())
  File "/tmp/tmp-2590981-sBSqAOYgFiEr/pip_resolve.py", line 342, in main
    create_dependencies_tree_by_req_file_path(
  File "/tmp/tmp-2590981-sBSqAOYgFiEr/pip_resolve.py", line 306, in create_dependencies_tree_by_req_file_path
    package_tree = create_tree_of_packages_dependencies(
  File "/tmp/tmp-2590981-sBSqAOYgFiEr/pip_resolve.py", line 126, in create_tree_of_packages_dependencies
    dir_as_root = create_dir_as_root()
  File "/tmp/tmp-2590981-sBSqAOYgFiEr/pip_resolve.py", line 109, in create_dir_as_root
    name, version = setup_file.parse_name_and_version(setup_py_file.read())
  File "/tmp/tmp-2590981-sBSqAOYgFiEr/setup_file.py", line 22, in parse_name_and_version
    passed_arguments = parse(setup_py_content)
  File "/tmp/tmp-2590981-sBSqAOYgFiEr/setup_file.py", line 16, in parse
    exec(setup_py_content, globals())
  File "<string>", line 7, in <module>
```
https://github.com/Chia-Network/issue-tracker/issues/36Since we share some test keys that are referred-to by the first word in their mnemonic, why not make it easy to generate wallets with known words. Now anyone can easily create their own "toilet" wallet.Stop using DataLayer fee setting in config and remove the setting from the initial config. Note any previous installs will still have a fee setting, but it is ignored
Tests are updated to specify the old default fee in order to keep reference offer data the same

Fixes #13365 

Draft for:
- [ ] Discussion with Michael.Relates to https://github.com/Chia-Network/chia-blockchain/pull/13324.

Draft for:
- [ ] This is a ginormous mess that shouldn't be done mid-release, not even on the `main` branch what with all the cross merging going on.
- [ ] This is still cheating by not keeping the full IPv6 5(?)-tuple.
- [ ] This mixes with eliminating the `self_hostname` passing all over in the tests since that was our 'shortcut' for the host.- renamed the indexes according to #13304
- removed index `coin_id` as there is already an internal index for the PK: sqlite_autoindex_singleton_records_1
- removed index `inner_puzzle_hash` as I found no SQL query using it
- fixed wrong indexed column for index `confirmed_at_height`, indexed column was `root`
- removed index `id` as there is already an internal index for the PK: sqlite_autoindex_launchers_1
- added index `mirrors_launcher_id_index` as there is a query [here](https://github.com/Chia-Network/chia-blockchain/blob/98c44fdd15ea0f06948a393d237142c71bd9d532/chia/data_layer/dl_wallet_store.py#L303) which would benefit from itin order to perform bulk-lookups of parent coins. This is a step towards bulk-add of coins.Open to other measures but these seem like some common sense options.Catches https://github.com/Chia-Network/chia-blockchain/pull/11005 up with `main`.

Draft for:
- [ ] Self reflection and continued exploration
- [ ] Inclusion and adjustment to use https://github.com/Chia-Network/chia-blockchain/pull/11006The main motivation behind this is to speed up generating new puzzle hashes. The bottleneck right now is `puzzle_for_pk()` and `get_tree_hash()`.

`puzzle_for_pk()` is slow because it has to call `curry()`, and `get_tree_hash()` is slow because it has to operate on `Program` (the python tree structure) instead of `SerializedProgram`.

This patch implements `curry()` to operate directly on `SerializedProgram`, which avoids the critical path from having to parse the program and speeds up `curry()` as well as `get_tree_hash()`.

| operation | before | after | after / before |
| --- | --- | --- | --- |
| puzzle_for_pk() | 17.15% | 9.64% | 0.56 |
| get_tree_hash() | 25.40% | 6.62% | 0.25 |

The profile from current main:
![chia-hotspot-0](https://user-images.githubusercontent.com/661450/185082885-32d88010-8019-4f51-bf50-f1542772a1f3.png)

The profile with this patch:
![chia-hotspot-0-patched](https://user-images.githubusercontent.com/661450/185083238-e9df6aff-cd52-448d-b31c-424c7892479d.png)

and don't chunk coin states in trusted sync.Resubmitting PR #10929. Log farmer and harvester connection failures are errors instead of informational.

Connection errors from harvester and farmer should be logged as errors instead of info, so problems with farming are easier to identify as they are hidden by the default log level INFO.This is a pull request to test clvm_tools_rs 0.1.21 with the parallel tests on the CI.  In combination with the lockfile change talked about in another pr, it should make chia-blockchain checkouts on read-only fs work well.I started looking around this due to the example exception in https://github.com/Chia-Network/chia-blockchain/pull/12459.  Anyways, `.response_dict` was hinted with `Any` for values which caused the hinting in `._get()` to be roughly disabled in terms of the return value thus missing the fact the return type was lacking the `Optional` aspect.  I haven't dug through the remaining issues but instead just left them broken for the record in the build logs here, and copied below.

```
Jul 17 20:54:19 fullnode chia_wallet[1432335]: 2022-07-17T20:54:19.142 wallet chia.rpc.util              : WARNING  Error while handling message: Traceback (most recent call last):
Jul 17 20:54:19 fullnode chia_wallet[1432335]:   File "/farm/chia-blockchain/chia/rpc/wallet_rpc_api.py", line 221, in get_public_keys
Jul 17 20:54:19 fullnode chia_wallet[1432335]:     sk.get_g1().get_fingerprint() for (sk, seed) in await self.service.keychain_proxy.get_all_private_keys()
Jul 17 20:54:19 fullnode chia_wallet[1432335]:   File "/farm/chia-blockchain/chia/daemon/keychain_proxy.py", line 185, in get_all_private_keys
Jul 17 20:54:19 fullnode chia_wallet[1432335]:     response, success = await self.get_response_for_request("get_all_private_keys", {})
Jul 17 20:54:19 fullnode chia_wallet[1432335]:   File "/farm/chia-blockchain/chia/daemon/keychain_proxy.py", line 93, in get_response_for_request
Jul 17 20:54:19 fullnode chia_wallet[1432335]:     success = response["data"].get("success", False)
Jul 17 20:54:19 fullnode chia_wallet[1432335]: TypeError: 'NoneType' object is not subscriptable
Jul 17 20:54:19 fullnode chia_wallet[1432335]: The above exception was the direct cause of the following exception:
Jul 17 20:54:19 fullnode chia_wallet[1432335]: Traceback (most recent call last):
Jul 17 20:54:19 fullnode chia_wallet[1432335]:   File "/farm/chia-blockchain/chia/rpc/util.py", line 16, in inner
Jul 17 20:54:19 fullnode chia_wallet[1432335]:     res_object = await f(request_data)
Jul 17 20:54:19 fullnode chia_wallet[1432335]:   File "/farm/chia-blockchain/chia/rpc/wallet_rpc_api.py", line 226, in get_public_keys
Jul 17 20:54:19 fullnode chia_wallet[1432335]:     raise Exception(
Jul 17 20:54:19 fullnode chia_wallet[1432335]: Exception: Error while getting keys.  If the issue persists, restart all services.  Original error: TypeError: 'NoneType' object is not subscriptable
```

```
chia/daemon/client.py:94: error: Incompatible return value type (got "Optional[WsRpcMessage]", expected "WsRpcMessage")  [return-value]
chia/daemon/client.py:100: error: Incompatible return value type (got "Optional[WsRpcMessage]", expected "WsRpcMessage")  [return-value]
chia/daemon/client.py:106: error: Incompatible return value type (got "Optional[WsRpcMessage]", expected "WsRpcMessage")  [return-value]
chia/daemon/client.py:112: error: Value of type "Optional[WsRpcMessage]" is not indexable  [index]
chia/daemon/client.py:113: error: Value of type "Optional[WsRpcMessage]" is not indexable  [index]
chia/daemon/client.py:120: error: Value of type "Optional[WsRpcMessage]" is not indexable  [index]
chia/daemon/client.py:121: error: Value of type "Optional[WsRpcMessage]" is not indexable  [index]
chia/daemon/client.py:128: error: Incompatible return value type (got "Optional[WsRpcMessage]", expected "WsRpcMessage")  [return-value]
chia/daemon/client.py:133: error: Incompatible types in assignment (expression has type "Optional[WsRpcMessage]", variable has type "WsRpcMessage")  [assignment]
chia/daemon/client.py:139: error: Incompatible return value type (got "Optional[WsRpcMessage]", expected "WsRpcMessage")  [return-value]
chia/daemon/client.py:149: error: Incompatible return value type (got "Optional[WsRpcMessage]", expected "WsRpcMessage")  [return-value]
chia/daemon/keychain_proxy.py:93: error: Value of type "Optional[WsRpcMessage]" is not indexable  [index]
chia/daemon/keychain_proxy.py:94: error: Incompatible return value type (got "Tuple[Optional[WsRpcMessage], Any]", expected "Tuple[WsRpcMessage, bool]")  [return-value]
Found 13 errors in 2 files (checked 637 source files)
```

Draft for:
- [ ] Fixing the issues.Keep values representing IP ports as uint16 within our own code.

Note that `YAML` and `web.TCPSite` do not support uint16 for port values, so we use `int` in those cases.This is an exploration of a...  a not beautiful way to share workflow definition pieces among several workflows without having to copy paste all of the common bits nor keep them up to date.  Actions are great, but they can't be used to define your matrices as far as I know.  The basic design is to store the common bits in a non-workflow YAML file.  This file can leverage pyyaml supported features like anchors etc to further enable reuse without repetition.  The library data file is loaded in a pre-run workflow whose sole purpose is to provide the data as a workflow output serialized to JSON.  This allows other jobs and matrices to depend on this pre-job to get copies of the data, parse it from the JSON, and use pieces as needed.  Note that the library reusable workflow could exist in the actions repository for example to be shared not only among workflows in the blockchain repository but among all of our repositories.

Draft for:
- [ ] Being more than just an exploration
- [ ] Presumably the library would be in another repository such as the actions repository
- [ ] Consideration of how to version this so updates are easily deployed without just breaking everything that uses it regularlyDraft for:
- [x] Windows type hinting issues are being addressed in https://github.com/Chia-Network/chia-blockchain/pull/12287Feel free to close and re-open this at any time to trigger a test run of effectively what is in `main`.Draft for:
- [ ] Finding an example use
- [ ] More tests to verify the hints are actually identified correctly via `@streamable`
- [ ] Explicit tests of the new hint getter functioninstead of issuing `execute()` and `fetchall()` as separate calls into aiosqlite, combine them into a single round-trip to the DB thread by `execute_fetchall()`.

It's unclear whether this give a speed-up in practice (at least on M1 + SSD). My measurements are likely within the noise. I suspect it might be more relevant on something like a Raspberry PI, but I'm not in a position to test that right now.

So for now, the only benefit would be slight increased clarity of intention of the code.

| test | before | after | after / before |
| --- | --- | --- | --- |
| sync empty blocks | 13.25s | 13.04s | 0.984 |
| sync full blocks | 102.24s | 102.83s | 1.0058 |
| keep-up empty blocks | 81.02s | 80.83s | 0.9977 |first test version, created similar to `tests_db_conversion.py` and `tests_db_validation.py` like suggested [here](https://github.com/Chia-Network/chia-blockchain/pull/11787#pullrequestreview-996290922)

wasn't sure how to handle hints, so I spared them out for now.Addresses #11955 Draft for:
- [x] Based on https://github.com/Chia-Network/chia-blockchain/pull/11786
- [ ] Some continued work including review and verification of consistent coverage
- [ ] Can we tie back to the actual protocol definitions as a reference list to make sure we aren't missing anything?
- [ ] Address `TODO:`s
- [ ] Move `all_protocols.py` to testsThis give a slight speed-up when adding a new block. The sync test runs at about 7% of the original run-time.

sync test runtime (M1, SSD):

| DB sync | before | after | after / before |
| --- | --- | --- | --- |
| off | 109.85s | 102.36s | 0.932 |
| full | 116.16s | 108.02s | 0.930 |Draft for:
- [ ] Reconsideration of approach for collecting just classes with `struct` packing formats.
- [ ] Reconsider assertions about formats being not `None`.
- [ ] General self review of all existing testing being covered by new tests.Updated the CLI's `help` command outputs to be less ambiguous in terms of which wallet to use. Specifically the help commands for `plotnft claim`, `plotnft join` and `plotnft leave`

Also updated `wallet.py` `help` commands for consistency in the use of 'Id' vs 'ID'.Draft for:
- [x] Discussion about the APIs
- [x] Some manner of timeouts
- [x] ~Consider where `wait_for_coins_in_wallet()` and any other helper functions in `full_node_simulator.py` belong.  https://github.com/Chia-Network/chia-blockchain/pull/11535/files#r879554651~ this can just be a follow up API design PR.
- [x] Review added `TODO:`sDraft for:
- [ ] Bring back
```python
def test_message_types_match_serializations(all_protocol_serializations: SerializedProtocolData) -> None:
    from chia.protocols.protocol_message_types import ProtocolMessageTypes

    serialization_message_names = sorted(
        name
        for group_name, name_to_serialization in all_protocol_serializations.items()
        for name in name_to_serialization.keys()
    )

    assert serialization_message_names == sorted(type.name for type in ProtocolMessageTypes)
```Draft for:
- [x] Update other packages
  - https://github.com/Chia-Network/chiavdf/pull/119
  - https://github.com/Chia-Network/chiabip158/pull/16
  - https://github.com/Chia-Network/chiapos/pull/330
  - https://github.com/Chia-Network/chia_rs/pull/16
  - https://github.com/Chia-Network/clvm/pull/117
  - https://github.com/Chia-Network/clvm_tools/pull/87
  - https://github.com/Chia-Network/clvm_tools_rs/pull/24
  - https://github.com/Chia-Network/bls-signatures/pull/332
- [x] Release other projects (check mark indicates we are referencing a new enough version)
  - [x] https://github.com/Chia-Network/chiavdf/
  - [x] https://github.com/Chia-Network/chiabip158/
  - [x] https://github.com/Chia-Network/chiapos/commits/1.0.11
  - [x] https://github.com/Chia-Network/chia_rs/
  - [x] https://github.com/Chia-Network/clvm/
  - [x] https://github.com/Chia-Network/clvm_tools/
  - [x] https://github.com/Chia-Network/clvm_tools_rs/
  - [x] https://github.com/Chia-Network/bls-signatures/commits/1.0.16
- [ ] Upstream wheel releases
  - [x] frozenlist https://github.com/aio-libs/frozenlist/issues/342
  - [x] memory_profiler https://pypi.org/project/memory-profiler/0.61.0/
  - [x] multidict https://github.com/aio-libs/multidict/issues/778
  - [ ] psutil https://github.com/giampaolo/psutil/issues/2089 https://github.com/giampaolo/psutil/pull/2102
  - [ ] setproctitle https://github.com/dvarrazzo/py-setproctitle/pull/120
  - [x] yarl https://github.com/aio-libs/yarl/issues/781
  - [ ] zstd https://github.com/sergey-dryabzhinsky/python-zstd/issues/83 https://github.com/Chia-Network/build-wheels/pull/9
- [x] If still at a Python 3.11 pre-release, how to handle distributing pre-release wheels.
- [ ] However many fixes
  - [x] https://github.com/Chia-Network/chia-blockchain/pull/13848Draft for:
- [x] Figuring out what to do with lgtm
- [x] Testing
- [x] Reviewing changelogs for 8+ https://click.palletsprojects.com/en/8.1.x/changes/
- [x] Special consideration of changes to wildcard handling on Windows.
  - When taking arguments from sys.argv on Windows, glob patterns, user dir, and env vars are expanded. [#1096](https://github.com/pallets/click/issues/1096)
  - Maybe we can punt on handling this: Pass `windows_expand_args=False` when calling the main command to disable pattern expansion on Windows. There is no way to escape patterns in CMD, so if the program needs to pass them on as-is then expansion must be disabled. [#1901](https://github.com/pallets/click/issues/1901)
- [x] `version_option` uses `importlib.metadata` (or the `importlib_metadata` backport) instead of `pkg_resources`. The version is detected based on the package name, not the entry point name. The Python package name must match the installed package name, or be passed with `package_name=`. [#1582](https://github.com/pallets/click/issues/1582)
- [x] A flag option with `required=True` requires that the flag is passed instead of choosing the implicit default value. [#1978](https://github.com/pallets/click/issues/1978)
- [x] Rely on [PEP 538](https://peps.python.org/pep-0538/) and [PEP 540](https://peps.python.org/pep-0540/) to handle selecting UTF-8 encoding instead of ASCII. Click‚Äôs locale encoding detection is removed. [#2198](https://github.com/pallets/click/issues/2198)
  - [x] Maybe we can drop `monkey_patch_click()`?
  https://github.com/Chia-Network/chia-blockchain/blob/a691d3c4b2aad546b8d9058b6a3882416edaee9b/chia/cmds/chia.py#L33-L46
  - Monkey-patch click instead of forking. https://github.com/Chia-Network/chia-blockchain/commit/be4af4128cd7900666c1028ba1545dfa06ed7391
  - https://github.com/pallets/click/pull/2199/files
  - https://peps.python.org/pep-0538/
  - https://peps.python.org/pep-0540/
- [x] Maybe drop types-clickAllows syncing from an unsynced node, if this configuration flag is set. Useful in cases like syncing an offline cold wallet. With this enabled, and chia installed from the cli deb, or some other method, a backup DB can be provided to the node via USB or some other method, this configuration option enabled, and the wallet will sync up to the point of the DB provided. The immediate use of this RPC is to help end users understand the current state of their "stuck" transactions. For example, is it still being considered by the wallet for re-submission to other nodes, or has it been dropped?

There are so many ways to implement this - I started out making this a filter on the `get_transactions_between` call to the DB. But looking a little closer, we use a cache above the DB, and `get_unconfirmed_transactions` is what wallets actually call to determine if they have pending transactions, so I thought it would be better to wire this command to that method.For demo only**Do not merge**: This is only meant for testing so far.

Swaps the most `ProcessPoolExecutors` to `ThreadPoolExecutors` and drops (de)serialization which was required for the multiprocessing. There are more ways to improve this and the related parts in timelord code are still TBD but its a start at least :)Draft for:
- [ ] Some `TODO`s
- [ ] Lots of consideration
- [ ] Not being a preliminary exploration
- [x] Switch the artifact check to use poetry
- [x] miniupnpc extra
- [ ] ipython
- [ ] making lgtm ignore .venv
- [ ] figure out m1 trying to build `chiavdf` from source https://github.com/Chia-Network/chia-blockchain/runs/8059378328?check_suite_focus=true
- [x] handle automatic versioning
- [ ] catch up pre-version checking
- [ ] review details of automatic versioningDraft for:
- [x] This is presently an experiment with the [reusable workflows feature](https://docs.github.com/en/actions/using-workflows/reusing-workflows).
- [ ] How does this affect IPS automation?Propose including the net name, e.g. mainnet / testnet10 into the peers.dat filename, to peers_net.dat.

Lack of this has cost me hours of energy trying to switch from mainnet and sync up testnet10 and then go back.

Please test, as I haven't tested this.

Thank yee1. Avoid a copy
2. Avoid reiteration
3. Avoid continuing iteration when all remaining heights will be ignored
4. Avoid removal from a list which is O(n)
   - First it searches to find the item, then it has to shift the rest of the items after that down an index.

I have not profiled nor benchmarked anything.  This is an off the cuff optimization opportunity that I figured I would just write.  It may or may not be worth changing.Setting type hints for WalletStateManager instances uncovered some other issues. Please see those PRs here:

* Add get_name to WalletProtocol https://github.com/Chia-Network/chia-blockchain/pull/13995
* DID Wallet https://github.com/Chia-Network/chia-blockchain/pull/10932
* CAT Wallet https://github.com/Chia-Network/chia-blockchain/pull/10934
* RL Wallet https://github.com/Chia-Network/chia-blockchain/pull/10935
* Use `uint128` for wallet balances https://github.com/Chia-Network/chia-blockchain/pull/10936Draft for:
- [ ] Being more than an explorationThis is a small improvement.  Future checks could allow for a limited number of outliers that need not count towards the average etc.Removes the no longer needed `get_local_root` logic and fixes a leftover type checking issue.GitHub Actions does support IPv6.  From my glance at https://github.com/actions/virtual-environments/issues/668 it is about _external_ IPv6 connections, not localhost.  Trio and Twisted both test IPv6 as best as both I and they know.  Twisted goes so far as to _disable_ IPv6 entirely for a dedicated IPv4-only test job.  If you want to look at a trivial example of IPv6 seemingly working, see https://github.com/altendky/altendpy/pull/15.

Draft for:
- [ ] deal with localhost
  - Wikipedia says ["The name localhost normally resolves to the IPv4 loopback address 127.0.0.1, and to the IPv6 loopback address ::1."](https://en.wikipedia.org/wiki/Localhost#Loopback) but they cite [RFC 4291](https://datatracker.ietf.org/doc/html/rfc4291#section-2.5.3) which doesn't even mention `localhost` per my search.
  - On my laptop running Ubuntu 20.04, `localhost` does not resolve to an IPv6 unless I manually add it to `/etc/hosts`.  At least according to `nmap -6 -p 0-65535 localhost` which says `Warning: Hostname localhost resolves, but not to any IPv6 address. Try scanning without -6`.
- [ ] making this not a hack
- [ ] considering ux on the parallel `self_hostname` and `prefer_ipv6` configuration options
- [ ] learn what all `prefer_ipv6` affects
- [x] make a common ipv6 aware url builder (or `hyperlink`?)
- [ ] if listening on IPv6 should we allow v4 as well on the same socket?
- [ ] how do we want to setup tests for coverage with `prefer_ipv6` both true and false
- [ ] review all uses of `127.0.0.1` and `::1`Add a fallback into config to turn off the optimised operations.
Refactored and removed transactions
- Transactions with encode.io/databases require a context block or reference to the transaction object being used. Removed the `DBWrapper` global transaction functionality and refactored transactions that used it.
- Redundant transactions surrounding single queries were removed 

Int casting for mysql
- Casting `uint32` to int as `pymysql` produces errors when passed a `int32`, `uint64`, ect...

Changed order of `WHERE IN` sql queries
- Rearranged queries using `WHERE IN` clauses so the parameter placeholder used is the last parameter placeholder because when `sqlalchemy` compiles the query and maps the parameters values to their placeholders it puts the values of a parameter with multiple values last regardless of the order of the placeholders. This causes a mismatch if the multiple-value placeholder is not last.

Increased sleep times
- Increased `asincio.sleep` used in tests to avoid errors

Removed of `set_trace_callback`
- Removed code using `aiosqlite.set_trace_callback` as databases does not support this functionality.

New files

dialect_utils.py
- `dialect_utils` is a module that is used to resolve the differences in syntax between different sql dialects (`mysql`, `postgres`, `sqlite`)

temp_file_db.py
- `encode.io/databases` does not support `sqlite` in-memory databases. A pull request is open with encode.io to add this functionality. In-memory databases are replaced with a tempfile database using logic extracted from `db_connection.py`.

db_factory.py
- Returns a database connection from `encode.io/databases`

tests/db/docker-compose-{database}.yml and README.md
- `docker-compose` files for `mysql` and `postgres` demonstrating full node operation against these databasesHere is my rewritten dbv2 upgrade script as follow up to the discussion in  #9613.
The main focus was to reduce runtime on low-end hardware (RPi) or having the database on HDDs.

**Alternative upgrade parameters**

```
chia db upgrade_alt -h
Usage: chia db upgrade_alt [OPTIONS]

Options:
  --input PATH            specify input database file
  --output PATH           specify output database file
  --hdd                   select if database is located on HDD device.
                          (DEFAULT=false)

  --offline               select to upgrade database with no active full node.
                          (DEFAULT=false)

  --temp-store-path PATH  specify path used as temporary db destination (Linux
                          only)

  --check-only            specify to check only if enough disk space is
                          available for upgrade. (DEFAULT=false)

  --no-update-config      don't update config file to point to new database.
                          When specifying a custom output file, the config
                          will not be updated regardless

  -h, --help              Show this message and exit.
```

**Runtimes**

The upgrade runtime is reduced up to 50% compared to the original approach.
But this certainly needs some additional tests/comparisons. 

If not other stated, the following upgrade durations are from a database which was manually vacuumed a few days before the upgrade was executed.

System|DB-Device|update time|update_alt time|parameter
--|--|--|--|--
RPi4;8GB|SSD, Samsung 840 evo 1tb|130m30.365s|67m2.213s|offline
RPi4;8GB|SSD, Kingston A400 240GB|234m40.001s|108m57.520s|offline
RPi4;8GB|SSD, Kingston A400 240GB|274m46.893s|125m18.824s|online
i7-11700K;128GB|NVME-SSD, 3 x 1 TB RAID 0|11m40.183s|8m5.468s|offline
i7-11700K;128GB|USB3-HDD, 2 TB|aborted after<br>261m*|15m48.932s|offline, hdd
i7-11700K;128GB|USB3-HDD, 2 TB|n/a|16m9.359s|online, hdd

\* ... at the end only 1866k coins were upgraded with a rate of 89.8 coins/s (avg ~186 coins/s), total of coins is > 43000k. full_blocks migration was finished after ~93m

**The upgrade is split into the following steps**

1. create database_version table and save version
2. create current_peak table and save current peak
3. create empty target v2 tables
  decided to don't source these statements from block_store.py, ... to not load LRU caches or such       
4. convert full_blocks to v2 and load data to target v2 tables
5. create full_blocks indexes on v2 tables
decided to create indexes right after table data migration to get possible use of data in fs cache
6. convert coin_store tables to temp sqlite db file
decided to use this approach and disconnect/recoonect sqlite sessions to get use of mmap
7. convert sub_epoch tables to temp sqlite db file
8. migrate coin_store temp data to target v2 sqlite file
9. create Indexes on coin_store tables
10. migrate sub_epoch tables to target v2 sqlite file
11. convert and migrate hints table to target v2 sqlite file
12. create indexes on hints table
13. finally update the database version to 2

I tried to adress the reasons for the changes in script comments, but here is an overview.

**Change Overview**
- added check_db function to check for sufficient disk space
- added connect_to_db function
- `chia db upgrade` click menu
   - added --check-only menu switch to check without starting upgrade
   - added --hdd menu switch to use slightly different migration approch for probably better performance if db is on HDD dev
   - added --offline switch to start the migration using an offline source database
   - added --temp-store-path to let the user specify a temp directory
- replaced aiosqlite by sqlite3 module
- added psutil module to check for disk usage and virtual memory
- changed migration method to 
   - use `attach database ...` 
   - reconnect after succesfull migration of 1 table to get new mmap
   - use vacuum-like method (`INSERT INTO ... SELECT * FROM ...`) only for certain tables and ignore indexes
   - use cursor arraysize with fetchmany
   - use recursive CTE to migrate main chain path only
   - create indexes directly after table
   - prepared two scenarios, one for migration having less than 3.5 GiB of available memory and one with more
   - for some inserts, added `order by <PRIMARY KEY>` for better insert performance on tables with PK
- prepared page_size change
- prepared mem shrink rate
- moved all table/index definitions out of other files into the main migration script (suboptimal but has less memory footprint)

**Known Issues**
- ETA and rate is not working

**Follow-up Questions**
- What is the table sub_epoch_segments_v3 used for?
   - This table would imo benefit from the largest possible page size of 64k, due to the big size of its rows (on avg ~600k).
   - It would probably be a good idea to move this table into a separate sqlite db file.
   - The data is scattered over the whole sqlite file.
      Statement to check:
```sql
select (pageno - pageno%100000) as modpageno, count(1) as pagecount from dbstat where name = 'sub_epoch_segments_v3' group by modpageno;
```
- Are there plans to change the db page_size for other tables?
   - According to [this information](https://github.com/Chia-Network/chia-blockchain/pull/9613#issuecomment-1013798743) I'd try out a page size of 16k. But this certainly needs to be tested to find the best sizing.
This is a possible alternative to https://github.com/Chia-Network/chia-blockchain/pull/9906.

Draft for:
- [ ] Actually completing the work and making the implementations of `BlockchainInterface` actually properly implement it.Draft for:
- [ ] This applies multiple places so there should probably be a method or some other mechanism for sharing of the check and message.Draft for:
- [ ] Continued developmentEmpty ones or such with only ignored stuff inside. It's just annoying if you have a branch which adds a new directory with new files and you switch to a branch which doesn't have those new files, running `pre-commit` always adds the init files in the new directory from the other branch because the folder from the other branch stays there and is empty.- [x] un-revert revert of chiavdf PR 87 (see revert PR 104)


Smaller proof format using compressed vdf outputs

Include proofs only in sampled segments

uses 140 sub epoch samples vs the older 20

interactive proving using local salt and peak hash

Added Wp capabilities in handshake to support both versions
so node will try using new version if peer is capable old version if not

added wp  cmd to cli to init Segment V2 database and checking if v2 db exists 

using V2 is opt in for nodes that are upgrading and True for new installations
 
this is opt in for running nodes

size of proofs:
   old version 13.0797 with 20 sub epochs sampled             
   new version - 10.4372 mb with 140 sub epochs sampled
  
validation times:
    old version: 20.8 sec
    new version: 60 sec

serialisation from bytes times:
   old version 1.3 sec
   new version 1.1 sec

creating V2 segments:
  10 sec for non blueboxed sub epochs
  1.5 sec for blueboxed (this is the same as  old version)
Since `Message` is frozen we can permanently identify the `.id` attribute type by the initially passed initializer.

Draft for:
- [ ] `Streamable` can't handle the use of the `Generic` or `TypeVar` or something.I could be swayed, but I chose `.secret()` to refer to the `secrets` module being used as opposed to `.random()` which would relate to the `random` module.  Maybe `.token()` would be better?  I don't necessarily know the implications of these words in the field, as opposed to just in Python.

Draft for:
- [x] Needs https://github.com/Chia-Network/chia-blockchain/pull/9457 merged for green CI
- [ ] Reconsideration based on commentsDraft for:
- [x] Needs https://github.com/Chia-Network/chia-blockchain/pull/9457 merged for green CI
- [ ] Seeing if this causes trouble.
  - Do we know if tests cover this?
- [ ] ~~Consider tweaking the library to indicate acceptance of `bytes` objects.  Something says it wants a `Union[List[int], List[List[int]]]` (IIRC) but it works with `bytearray`...  so maybe it really just needs an iterable of 0-255 integers rather than explicitly a list?  If so, we could then pass the `bytes32` in directly.~~
  - I think I would rather take this on separately.This is presently here as an example of what https://github.com/Chia-Network/chia-blockchain/pull/9364 looks like applied elsewhere.Draft for:
- [ ] Self testinghttps://github.com/Chia-Network/chia-blockchain/pull/9371 is intended to exclusively ignore the hinting issues.  This PR follows up to fix them.  It is being developed before the ignores are merged so we can avoid having to roll multiple clvm releases for hint corrections.

Draft for:
- [ ] This PR includes https://github.com/Chia-Network/chia-blockchain/pull/9371 and should only be merged afterIf you are reviewing this PR, please considering reading https://gist.github.com/altendky/8393dad3e4a44adf8bf5cc19636d15a0 as tooling can make the review much easier.

---

See https://github.com/Chia-Network/chia-blockchain/pull/9369#issue-1061919096 for an explanation of this approach.  Fixes for these hinting issues are being explored in https://github.com/Chia-Network/chia-blockchain/pull/9387.

Draft for:
- [ ] Finishing it up
- [ ] New clvm being released at least with https://github.com/Chia-Network/clvm/pull/102
- [ ] Updating branch-pinned dependency on clvm in `setup.py` to the new released version> benchmark for coin store runs faster when database is located on SSD (129.9s vs 194.3s)
> benchmark for coin store also runs faster when database is located on SPINDLE (2135.5s vs 2546.2s)
> the coin store benchmark application was slightly improved to allow SQL logging, tracking total exec time and seeding the random
> using a partial index on block_records(is_peak) allows for a much smaller index -> less IO

This is achieved by
> using memory for temp tables
> using bulk insert from temp table instead of single rows into the coin store
> using a single update statement to change the spent index and flag of many coins at the same time


`#SSD original code
Building database
78.3017s, MOSTLY ADDITIONS additions: 400400 removals: 20000
9.2151s, MOSTLY REMOVALS additions: 600 removals: 140000
85.1686s, FULLBLOCKS additions: 400400 removals: 400000
1.4034s, GET RECORDS BY NAMES with spent 200 lookups found 40000 coins in total
1.6274s, GET RECORDS BY NAMES without spent 200 lookups found 20669 coins in total
18.5551s, GET COINS REMOVED AT HEIGHT 800 blocks, found 580000 coins in total
all tests completed in 194.2713s
`

`
#SSD bulk insert and mass update
Building database
45.6112s, MOSTLY ADDITIONS additions: 400400 removals: 20000
5.4808s, MOSTLY REMOVALS additions: 600 removals: 140000
57.1782s, FULLBLOCKS additions: 400400 removals: 400000
1.4021s, GET RECORDS BY NAMES with spent 200 lookups found 40000 coins in total
0.9622s, GET RECORDS BY NAMES without spent 200 lookups found 20669 coins in total
19.2544s, GET COINS REMOVED AT HEIGHT 800 blocks, found 580000 coins in total
all tests completed in 129.8889s`


`#SPINDLE original code
Building database
917.1889s, MOSTLY ADDITIONS additions: 400400 removals: 20000
325.2917s, MOSTLY REMOVALS additions: 600 removals: 140000
1281.8812s, FULLBLOCKS additions: 400400 removals: 400000
1.3874s, GET RECORDS BY NAMES with spent 200 lookups found 40000 coins in total
0.8687s, GET RECORDS BY NAMES without spent 200 lookups found 20669 coins in total
19.5532s, GET COINS REMOVED AT HEIGHT 800 blocks, found 580000 coins in total
all tests completed in 2546.1711s`

`#SPINDLE bulk insert and mass update
Building database
720.6202s, MOSTLY ADDITIONS additions: 400400 removals: 20000
305.5275s, MOSTLY REMOVALS additions: 600 removals: 140000
1087.8906s, FULLBLOCKS additions: 400400 removals: 400000
1.3928s, GET RECORDS BY NAMES with spent 200 lookups found 40000 coins in total
0.7278s, GET RECORDS BY NAMES without spent 200 lookups found 20669 coins in total
19.3454s, GET COINS REMOVED AT HEIGHT 800 blocks, found 580000 coins in total
all tests completed in 2135.5043s
`



Over in https://github.com/Chia-Network/chia-blockchain/pull/9249 (https://github.com/Chia-Network/chia-blockchain/runs/4194463207?check_suite_focus=true) I ran into a time-based failure on this test.

```
>       assert run_time < 2.5
E       assert 2.8586108684539795 < 2.5
```

Let's just let it retry since I think the most useful thing given the inconsistent nature of CI VMs is to just make sure it's possible for it to be quick.  If we decide to handle it differently in the future, even if we've done this with many tests, we will have a mark on all the flaky tests that needed this help.  In the mean time, maybe we can reduce the knee jerk reaction to just retry any failed CI jobs.

Draft for:
- [ ] Not compatible with `@pytest.mark.asyncio`?
  https://github.com/pytest-dev/pytest-rerunfailures/issues/154
- [ ] Needs to actually get installed in CI.
  https://github.com/Chia-Network/chia-blockchain/pull/9251
- [ ] Only retry on 'timeout' errors somehow.Improves some RPCs to help developers:

1. Add header_hashes, these were not needed in python because we can always calculate them on the fly, but the client might not support that.
2. Same for coin ids, coin records will now come with a coin id. 
3. Get puzzle and solution now returns the response twice, once with the old key `coin_solutions` and once with the new key `coin_spends` which we have renamed. The old one should be removed eventually. 
4. For some reason `get_puzzle_and_solution` took in height as well as coin id. Do you know why @Yostra? I made it optional here. 

Draft for:
- [x] Full blocks should also include header hash
- [ ] Self review, testingThe existing numbers were insufficient to guarantee exceeding the limit in the case where the test spans a reset boundary for the rate limiting.  It would be nice to make the test agnostic to this alignment, but this should at least avoid (rare) flakes.

https://github.com/Chia-Network/chia-blockchain/runs/4154993776?check_suite_focus=true
```
=================================== FAILURES ===================================
____________________ TestRateLimits.test_too_many_messages _____________________

self = <test_rate_limits.TestRateLimits object at 0x7f1df617b7c0>

    @pytest.mark.asyncio
    async def test_too_many_messages(self):
        # Too many messages
        r = RateLimiter(incoming=True)
        new_tx_message = make_msg(ProtocolMessageTypes.new_transaction, bytes([1] * 40))
        for i in range(3000):
            assert r.process_msg_and_check(new_tx_message)
    
        saw_disconnect = False
        for i in range(3000):
            response = r.process_msg_and_check(new_tx_message)
            if not response:
                saw_disconnect = True
>       assert saw_disconnect
E       assert False

tests/core/server/test_rate_limits.py:34: AssertionError
```

Draft for:
- [ ] Addressing comments
- [ ] Considering https://github.com/Chia-Network/chia-blockchain/pull/8861#issuecomment-974702335### Overview
When Madmax is invoked to create multiple plots (`-n` >1 || `-n` -1), it honors the `--waitforcopy` CLI option, which if enabled, waits for the plot file to be copied/renamed to the `--finaldir` before starting the next plotting task. If the waitforcopy flag is not set (the default behavior), the next plotting task begins as soon as the current plotting task starts copying the plot to its final destination.

### Problem
When plotting with the Chia GUI, plotting tasks are handled by invoking the plotter one-at-a-time -- that is, the `-n` parameter is effectively always set to `1`. When running Madmax in this manner, we implicitly apply the `--waitforcopy` behavior because we only create a single plot and we wait for the plotter to indicate completion (via log message matching). If we were to expose the option to toggle `--waitforcopy` in the GUI, we would need a way to emulate the no-wait behavior.

### Solution
This change introduces a new PlotState.COPYING state for the copying phase. When Madmax emits the message "Started copy to", we'll update the task's state to COPYING and attempt to start the next plot while the current task will continue until the copy completes.

### TODO
- [x] Expose the `--waitforcopy` toggle in the GUI.

### Testing

- [ ] Tested with a copy across different volumes.
- [ ] Test the move/rename case
- [ ] Test the case where tmpdir == finaldirWe use `asyncio.as_completed()` to walk through possibly multiple simultaneous challenge lookups that need completed.  If any of them have an error, or possibly there's an error in some other nearby spot, we leave the not-yet-handled lookups un-awaited.  This PR makes an effort to handle as many lookups as possible and report as much error context as we can.

User reported getting:

\<transcribed from a screenshot...\>

```
/usr/lib/python3.8/threading.py:233: RuntimeWarning: coroutine 'HarvesterAPI.new_signage_point_harvester.<locals>.lookup_challenge' was never awaited
  self._release_save = lock._release_save
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/lib/python3.8/threading.py:250: RuntimeWarning: coroutine 'HarvesterAPI.new_signage_point_harvester.<locals>.lookup_challenge' was never awaited
  return self._lock.__exit__(*args)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
/usr/lib/python3.8/concurrent/futures/_base.py:3: RuntimeWarning: coroutine 'harvesterAPI.new_signage_point_harvester.<locals>.lookup_challenge' was never awaited
  self._condition = threading.Condition()
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
```

I guess the warnings are maybe getting mixed with a threading traceback when exiting.

Draft for:
- [ ] Self review and testingDraft for:
- [ ] https://github.com/Chia-Network/chia-blockchain/pull/9134 being merged to build on itDraft for:
- [ ] Self review, especially https://github.com/Chia-Network/chia-blockchain/pull/9122/files#diff-716d7e61fa0f866099ee199413b0b62600c98a97acf3ff370f561d7fdc4fc47cR41-R43Subscribing to common shared phs has no utility. (resource waste)https://en.wikipedia.org/wiki/ISO_8601

```
Existing: 2021-10-16T22:50:30.453 full_node full_node_server        : INFO
New     : 2021-10-16T22:49:25.210-04:00 full_node full_node_server        : INFO
```

Closes https://github.com/Chia-Network/chia-blockchain/issues/8802.Add new daemon service and RPC for viewing log file.

Steps to use:
- connect to daemon 
- send `register_service` with new service name `daemon_logs`
- send `get_logfile` command to this service 
- The response to `get_logfile` will contain the contents (up to 25Mib) of the log file
- The daemon will send out unsolicited `log_update` commands every 5s with additional log data (if present) as long as the socket remains connected
- closing the socket ends the messagescurrently None api responses cause the waiting peer to wait until the request timeout passed, this adds the ability for the receiving peer to receive the None response and not wait for the timeoutSome codes from [pool-reference](https://github.com/Chia-Network/pool-reference.git).

- `get_pool_launcher`: Query initial state by `launcher_id`
- `get_pool_singleton_states`: Return join pool change history
- `get_pool_singleton_state`: Query last pool state by `launcher_id`
- `create_pool_absorb_tx`: Create absorb transaction.Tested only on Ubuntu 20.04.2 LTS. Imports 'socket' which maybe an issue for some distros. 

I keep track of my remote harvesters by hostname and do not know the IP. This makes it easy.Domain name resolution should be performed again when reconnectingThis adds an `inventory` command to `chia plots`

This is useful for determining which of your plots won when given the plot_public_key (which currently is not available in the CLI)

It also adds the internal plot_id in case filenames have been mangled.

I imagine this would be extended to include the type of plot (OG or poolable format) as well.

I wanted to have all of the information on one line so grep/awk can process them.  I'm thinking eventually of allowing the formatting of the output to be handled via an option `-o PATH,PLOT_PUBLIC_KEY` (a. la. `lsblk` if that is all the caller is interested in).

I have no idea if the plot ID code is performant or appropriate.  I looked at `chiapos` to see that it contains the ID and and using that.

I'm not a python programmer so I appreciate any feedback on the code or where to add tests.

Examples:

## Search for a given plot_public_key (as well as using the existing -g grep_string)
```
chia plots inventory -g 2021-05-18-06 -p 82f00342ce8820db5
2021-05-31T13:49:38.753  chia.plotting.inventory_plots    : INFO     Loading plots in config.yaml using plot_tools loading code

2021-05-31T13:49:38.780  chia.plotting.plot_tools         : INFO     Searching directories ['redacted']
2021-05-31T13:49:38.810  chia.plotting.plot_tools         : INFO     Only loading plots that contain "2021-05-18-06" in the file or directory name
...usual found_plots logs...
2021-05-31T13:49:38.828  chia.plotting.plot_tools         : INFO     Loaded a total of 1 plots of size 0.09898991970385396 TiB, in 0.06671667098999023 seconds
2021-05-31T13:49:38.828  chia.plotting.inventory_plots    : INFO     Only looking for plot with a public key containing any of the following strings ('82f00342ce8820db5',) 
2021-05-31T13:49:38.837  chia.plotting.inventory_plots    : INFO     Inventory: path=/redacted/chia_plots/plot-k32-2021-05-18-06-47-428b2d54de58491cf0352083c3111359cb726670bfe61df16333f26ee512abec.plot k=32 pool_public_key=b...redacted...b plot_public_key=82...redacted...f60b8ec93 plot_id=428b2d54de58491cf0352083c3111359cb726670bfe61df16333f26ee512abec
```

## Just inventory everything
```
chia plots inventory
```

## Search for a few different plot_public_key strings
```
chia plots inventory -p string1 -p string2
```

## Get help

```
chia plots inventory -h                                      
Usage: chia plots inventory [OPTIONS]

Options:
  -g, --grep_string TEXT      Shows only plots that contain the string in the
                              filename or directory name

  -p, --plot_public_key TEXT  Shows only plots that contain the string in
                              their plot_public_key.  Can be specified
                              multiple times.

  -h, --help                  Show this message and exit.
```The average time to win can bounce around a lot if you are a small time farmer even if your percentage of the total netspace is stable.  I figure it is better to use the average daily block count instead of the last 500 blocks if on average you will win less than once per day.when running inside containers with CPU limits python's
multiprocessing.cpu_count() will return total number of CPU's
available on the machine. However in reality the process and its
children will not be able to be scheduled on all CPUs.
This issue is most pronounced with taskset/cpuset is set for the process.
Causing scheduling contention over limited number of CPU's.

In case of CFS cpu limits, its similar, but due to bursty nature, at least
in a short timeframe the processes will be able to be scheduled on all CPUs.
The overall efficiency however will be reduced still.

There is no straightforward way to read the CPU shares assigned via CFS.
So just handling simple case when affinity is explicitly set should be a good startA script, create-docker-test-image.py is added which wraps up installs of chia-blockchain into conda environments corresponding to python 3.8 and 3.9 runtimes, and uses build-workflows.py to generate a series of docker-compose yaml files which allow slices of the tests to be run quickly in an isolated environment and provides an environment variable to turn on profiling easily.

Because asynchronous python can have a poor user experience at the command line, running in docker may have some benefit to developers if questions exist about the reliability of test runs or there is need to abort or restart tests.

A few places, CHIATEST is checked in install.sh and install-timelord.sh to deal with the environment in the docker container.  I think these changes aren't that intrusive but don't actually have a strong opinion.

The chia-blockchain directory is mounted as /app in the docker image so the user's current working state is used when running tests in docker.The basic issue is that `WebSocketServer.connections` is a `Dict[str, Union[subprocess.Popen, List[subprocess.Popen]]]` but `kill_process()` was not setup to handle the `List[subprocess.Popen]` case of the `Union` so the traceback below is created on shutdown with active plotting processes.  The list is used for the plotting "service" where instead of having a single service managing subprocesses, the daemon in this case is instead expected to handle all of the plotting processes directly.  Hence a list.

This PR at present eliminates the `Union` aspect and just makes all cases a `List[subprocess.Popen]`.  This removes the need to special case the plotting "service".

It could certainly be argued that going the other way would be better.  To add an actual plotting service that manages the plotting processes instead of having the daemon itself do that.  Then we could collapse the `Union` to just the `subprocess.Popen` case.  That's a bit bigger change though.  But, if that direction is preferred then the minimal fix that instead adds plotting service special case awarenss to `kill_process()` is available in commit https://github.com/Chia-Network/chia-blockchain/pull/3954/commits/eff18cccf7f41450182636f653f1658a592b368c.

```python-traceback
2021-05-06T07:31:41.595 full_node full_node_server        : ERROR    Exception , exception Stack: Traceback (most recent call last):
  File "chia\server\server.py", line 356, in start_client
  File "aiohttp\client.py", line 763, in _ws_connect
  File "aiohttp\client.py", line 521, in _request
  File "aiohttp\connector.py", line 535, in connect
  File "aiohttp\connector.py", line 892, in _create_connection
  File "aiohttp\connector.py", line 1032, in _create_direct_connection
  File "aiohttp\connector.py", line 969, in _wrap_create_connection
  File "asyncio\base_events.py", line 949, in create_connection
  File "asyncio\selector_events.py", line 473, in sock_connect
concurrent.futures._base.CancelledError

2021-05-06T07:31:45.016 daemon asyncio                    : ERROR    Task exception was never retrieved
future: <Task finished coro=<kill_service() done, defined at chia\daemon\server.py:833> exception=AttributeError("'list' object has no attribute 'pid'")>
Traceback (most recent call last):
  File "chia\daemon\server.py", line 841, in kill_service
  File "chia\daemon\server.py", line 805, in kill_process
AttributeError: 'list' object has no attribute 'pid'
2021-05-06T07:32:09.965 full_node full_node_server        : ERROR    Exception:  <class 'concurrent.futures._base.CancelledError'>, closing connection None. Traceback (most recent call last):
  File "chia\server\server.py", line 531, in api_call
  File "asyncio\tasks.py", line 435, in wait_for
concurrent.futures._base.CancelledError

2021-05-06T07:33:20.573 full_node full_node_server        : ERROR    Exception , exception Stack: Traceback (most recent call last):
  File "chia\server\server.py", line 356, in start_client
  File "aiohttp\client.py", line 763, in _ws_connect
  File "aiohttp\client.py", line 521, in _request
  File "aiohttp\connector.py", line 535, in connect
  File "aiohttp\connector.py", line 892, in _create_connection
  File "aiohttp\connector.py", line 1032, in _create_direct_connection
  File "aiohttp\connector.py", line 969, in _wrap_create_connection
```Issue #3475When a farmer is behind a dyndns domain, remote harvesters will not try to re-translate the hostname and attempt reconnecting only to the out-of-date IP. The same happens for other entities (node, wallet, etc.), I assume.
This forces a retranslation of hostname on every reconnect attempt. This fixed the issue for remote harvesting in a test on my setup.
This fixes issue [#2147](https://github.com/Chia-Network/chia-blockchain/issues/2147)